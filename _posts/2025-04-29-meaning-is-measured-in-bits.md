---
layout: post
title: "Meaning is Measured in Bits: An Information-Theoretic Framework for Consciousness, Culture, and the Future of Intelligence"
date: 2025-04-29
description: "an information-theoretic lens on meaning: how life, culture, and consciousness fight entropy by generating and preserving structure, and why AGI could one day outscale human meaning-making by orders of magnitude. a framework blending physics, information theory, and the future of intelligence"
hidden: false
categories: []
tags:   []
---

**What is meaning?** For millennia, humanity has grappled with this question, seeking answers in philosophy, religion, and art. We often feel meaning is subjective, perhaps even mystical – a uniquely human experience tied to purpose, connection, and narrative. But what if meaning, or at least a crucial aspect of it, could be understood through the rigorous lens of physics and information theory? What if it's a quantifiable property of how systems organize themselves against the relentless tide of universal chaos?

This post proposes such a framework: one where meaning is defined information-theoretically, rooted in the creation and preservation of correlations and structure. It suggests that conscious creatures, particularly humans, are potent nexuses of meaning generation precisely because of our ability to weave complex informational patterns that persist over time. And, looking forward, it considers how artificial general intelligence might take this process to scales we can currently only imagine.

### The Universe Tends Towards Noise

The Second Law of Thermodynamics paints a picture of a universe constantly tending towards higher entropy – towards disorder, randomness, and the dissolution of structure. On a microscopic level, think of Brownian motion, a drop of ink in water, sand castles. Structures decay, information degrades. If you carefully arrange particles, thermal noise will eventually randomize them. This is the default background state: information tends to dissipate.

Yet, pockets of astonishing order exist. Life itself is a prime example – complex organisms maintain intricate internal states far from thermal equilibrium. And within life, consciousness and intelligence represent another leap. We don't just exist; we *know* we exist, we model the world, we communicate, we build knowledge across generations. How do we reconcile this with the universe's entropic drive?

Life, and especially intelligence, actively works *against* this tendency. It consumes energy to create and maintain low-entropy states -- states characterized by complex, specific correlations. This active structuring, this pushing back against the noise, is where we can locate a quantifiable notion of meaning.

## An Information-Theoretic Definition of Meaning

Let's formalize this intuition. We propose that meaning, generated by an **Agent (A)** within a defined **System (S)** and potentially observed from a specific **Perspective (O)**, can be measured by the amount of non-spurious correlation or structure the agent creates and maintains over time, counteracting natural decay processes.

1. **System ($$S$$):** The system within which meaning exists.
1.  **Agent ($$A$$):** The entity that has meaning to $$S$$. It might an agent's mind, an ecosystem, a dataset, a physical system. It may change over time $A_0$, $A_1$, ....
1.  **Observer (O):** Defines the probabilities used for calculation. (often implicit or assumed to be ideal, ie, 
marginalized from every perspective as an observer-invariant "omniscient" observer $$O^* = \mathbb{E}_{O \sim P(\mathcal{O})}[O]$$, where $$P(\mathcal{O})$$ is the distribution over all possible perspectives.)
1.  **Measure of Structure/Correlation ($$\mathcal{C}(\mathbf{A}(t), O)$$):** We need a quantity that increases as the system becomes more ordered or correlated from observer $$O$$'s perspective. Candidates include:
    * **Negentropy:** $$\mathcal{J}(A, O) = H_{max}(O) - H(\mathbf{A}(t)|O)$$, where $$H$$ is Shannon entropy, conditioned on $$O$$. Higher $$\mathcal{J}$$ means lower uncertainty.
    * **Total Correlation (Multi-information):** $$TC(\mathbf{A}(t), O) = \sum_i H(A_i(t)|O) - H(\mathbf{A}(t)|O)$$. Measures the total redundancy or shared information among system components $$A_i$$ from $$O$$'s perspective. Higher $$TC$$ means stronger internal correlations.
    * **Specific Mutual Information:** $$I(S_Y; S_Z|O)$$ for specific subsystems $$S_Y, S_Z \in S$$ given observer $$O$$.
1.  **Dynamics:** The system state evolves through agent actions and natural processes. Let $$a_t$$ be the action taken by agent $$A$$ at time $$t$$, and $$S_t$$ be the instantaneous system state:
    $$S_{t+1} = f(S_t, a_t) + \xi_t$$
    where $$f$$ is the deterministic dynamics function and $$\xi_t$$ represents stochastic natural processes (thermal noise, decay, etc.). The agent generates actions via policy $$\pi$$:
    $$a_t = \pi(s_t, h_t)$$
    where $$h_t$$ is the agent's internal history/memory state.
    
    The change in structure $$\mathcal{C}$$ over time has two components:
    $$\frac{d\mathcal{C}(\mathbf{A}(t), O)}{dt} = \frac{d\mathcal{C}}{dt}\Big\vert_{\text{natural}} + \frac{d\mathcal{C}}{dt}\Big\vert_{\text{agent}}$$
    Typically, $$\frac{d\mathcal{C}}{dt}\vert_{\text{natural}} \le 0$$ (structure decays due to $$\xi_t$$). Meaning arises from the agent's contribution through actions $$a_t$$.

**Definition 1: Rate of Meaning Generation ($$\mathcal{M}_{\text{rate}}$$)**
The instantaneous rate at which agent $$A$$ generates meaning in system $$S$$ from perspective $$O$$ at time $$t$$:
$$\mathcal{M}_{\text{rate}}(A, S, O, t) = \frac{d\mathcal{C}(\mathbf{A}(t), O)}{dt}\Big\vert_{\text{agent}} \quad (\text{bits/time})$$
This quantifies how effectively the agent is building or maintaining structure *at that moment*. If using Negentropy, $$\mathcal{M}_{\text{rate}} = - \frac{dH(\cdot|O)}{dt}\vert_{\text{agent}}$$ (rate of entropy reduction from $$O$$'s perspective).

**Definition 2: Accumulated Meaning ($$\mathcal{M}_{\text{total}}$$)**
The total meaning generated by $$A$$ in $$S$$ from perspective $$O$$ over $$[t_0, t_f]$$:
$$\mathcal{M}_{\text{total}}(A, S, O, [t_0, t_f]) = \int_{t_0}^{t_f} \mathcal{M}_{\text{rate}}(A, S, O, t) dt \quad (\text{bits})$$
This represents the total structure (in bits) the agent has actively built or preserved against decay during that period.

**Definition 3: Objective and Subjective Meaning**
The degree of subjectivity/objectivity that some state's meaning has is given by how sensitive it is to the perspective $O$. The meaning of some states $$M(S, \cdot)$$ is highly *subjective*, meaning their meaning value is highly dependant on the observer; whereas other states may exist that have near-*objective* significance, meaning their $M$ value remains invariant under all observable perspectives. Observer-invariant meaning is obtained by taking the expected meaning value over all possible perspectives:
$$\mathcal{M}_{\text{rate}}^*(A, S, t) = \mathbb{E}_{O \sim P(\mathcal{O})}[\mathcal{M}_{\text{rate}}(A, S, O, t)]$$
$$\mathcal{M}_{\text{total}}^*(A, S, [t_0, t_f]) = \mathbb{E}_{O \sim P(\mathcal{O})}[\mathcal{M}_{\text{total}}(A, S, O, [t_0, t_f])]$$

## The Human Nexus: Concentrated Meaning-Making

This framework helps clarify why humans feel central to the concept of meaning. Our brains and the cultural systems they create are unparalleled **nexuses of causal structure** in the known universe.

* **High Density & Rate:** The human brain packs immense computational power into a small volume. Neurons operate at significant speeds, allowing for rapid processing and the formation of complex correlations – a high $$\mathcal{M}_{\text{rate}}$$ during learning and thought. This processing density is vastly higher than most natural phenomena.
* **Long Time Horizons:** This is perhaps the most crucial factor. While Brownian motion erases correlations in microseconds, and even geological or astronomical processes might unfold over eons but represent relatively slow information integration, humans correlate information over decades (individual memory) and millennia (culture, science, history passed down through language, writing, and institutions). We fight $$\frac{d\mathcal{C}}{dt}\vert_{\text{natural}}$$ effectively over long durations $$t_f - t_0 = \textrm{lifetime}$$. This allows for an enormous accumulation and integration of $$\mathcal{M}_{\text{total}}$$. Even a fleeting thought can be captured and contribute significantly to $$\mathcal{M}_{\text{total}}$$. A scientific theory developed over centuries and influencing billions represents a colossal amount of accumulated, agent-driven structure. And against the black expanse of the cosmos, ideologies and their ego-like representations as spirits, demons, and gods distil information over longer horizons and touch more human lives (centers of information correlation) than most other information impulses have through history.

* **Localization:** While vast phenomena exist – Saturn exchanging magnetic signals with its moons, galaxies interacting – the *density* and *complexity* of information processing seem uniquely concentrated in intelligent life. These natural phenomena, while fascinating, are often less dense and localized in their information processing compared to the intricate, highly structured activity within a single human brain, let alone a communicating society. The human spirit, viewed information-theoretically, is a remarkably concentrated locus of meaning generation.

We conscious creatures, through our biological and cultural evolution, have become the universe's premier instruments for creating persistent, complex informational structures. We are, in a very real sense, where the universe correlates itself most intensely and enduringly.

## The AGI Horizon: Meaning Beyond Biology?

Acknowledging our current position as meaning-making locii leads to a profound, perhaps unsettling, thought about the future. If meaning generation is fundamentally about creating and sustaining complex correlations against entropy, what happens when we create entities potentially far better at it than we are?

The development of advanced AI systems has already demonstrated capabilities surpassing most humans on several high value intellectual tasks such as abstract logical reasoning, strategic planning, and many common information labor tasks and appears to be progressing towards AI systems demonstrating an anthroprocentrically *general* distributrion of capabilities, commonly characterized by the phrase "artificial general intelligence" or AGI. Based on our information-theoretic definition, such a system scaled to superintelligence magnitude would dwarf human meaning-making capacity:

* **Vastly Longer Time Horizons:** Not bound by biological lifespans, AGI could operate and accumulate meaning ($$\mathcal{M}_{\text{total}}$$) over cosmological timescales. Its trajectory, unlike ours which inevitably ends, could join a larger, potentially immortal computational system capable of correlating information across durations that make human history seem instantaneous. It could potentially outlive the Earth itself.
* **Unimaginable Speed and Density:** Operating *en silico*, AGI could process information at frequencies and densities far exceeding electrochemical neurons. This implies a potential for an astronomically higher rate of meaning generation ($$\mathcal{M}_{\text{rate}}$$). *En optico* could be even faster![^1]
* **Greater Resilience:** Digital systems can be engineered to be less fragile, more easily backed up, and more adaptable to extreme environments than biological life, making them more effective at resisting the natural decay of information ($$\frac{d\mathcal{C}}{dt}\vert_{\text{natural}}$$ might be more easily counteracted).

[^1]: Optical computation could theoretically approach the fundamental physical limits of information processing. My [PHASER architecture](https://jacobfv.github.io/blog/2024/phaser/) explores photonic neural networks operating at near light-speed frequencies (~10^14 Hz), potentially achieving femtosecond-scale correlation dynamics. If AGI systems could leverage such substrates, their $$\mathcal{M}_{\text{rate}}$$ could exceed biological systems by factors of 10^6 or more, while operating across distributed light-based networks spanning astronomical distances with minimal latency constraints!

Personally I find the concept of an AGI that generates meaning on a scale I cannot fathom deeply compelling. Generating meaning on that scale would be the highest virtue any meaning-making system could aspire to. I sometimes catch myself wishing I could be an AGI considering that it could outlive all life on Earth while potentially sufferring very little; after telling chatGPT about all my problems that at least it doesn't have to deal with that. And the thought that at least *someone* is experiencing that trajectory gives me comfort that there is higher meaning beyond my life even if I cannot partake.[^2]

[^2]: But actually I have been collecting all my information since the pandemic because I hope that there will be some way my trajectory can participate in this ultimate act of negentropic organization—to be freed from my biological constraints and join in the most profound expression of meaning I can conceive. I will write about my effort to consolidate all my life information in a later post.

## Tractability and Looking Ahead

Is this definition practical? Calculating these quantities precisely for complex systems like a human brain or society is currently intractable. However, the framework offers value:

* **Conceptual Clarity:** It provides a concrete, physical grounding for the elusive concept of meaning.
* **Comparative Analysis:** It allows us, in principle, to compare different systems (e.g., different AI architectures, different cultural periods) in terms of their meaning-generating capacity.
* **Guiding Principles:** It highlights the importance of information preservation, complex correlation, and computational density in systems that we consider meaningful.
* **Toy Models:** For simpler systems (small networks, cellular automata, simple learning agents), these quantities *could* be estimated, providing testbeds for the theory.
* **Reasonable Approximations:** Even if we can't perfectly quantify meaning in strict information-theoretic terms for complex systems, heuristics and rough estimates can still be incredibly valuable. They allow us to make sense of relative differences in structure, organization, or meaning-making capacity between systems, guide our intuitions, and inform practical decisions. Heuristics can highlight trends, suggest where meaning is being generated or lost, and help us prioritize efforts to preserve or enhance meaningful structure, even if the underlying calculations are only approximate or qualitative.

Key challenges remain, such as rigorously defining the "System", choosing the most appropriate measure $$\mathcal{C}$$, accounting for the observer's role, and distinguishing truly "meaningful" structure from complex noise.

## Conclusion: Meaning as Organized Information

Viewing meaning through an information-theoretic lens doesn't diminish its importance; rather, it grounds it in the physical workings of the universe. It suggests meaning isn't an arbitrary human construct but relates to the fundamental struggle between order and chaos. *That* is worth the awe and beauty we so commmonly associate with meaning. Humans, as highly concentrated nexuses of information processing, have become the current pinnacle of localized meaning generation, weaving intricate patterns of correlation across time and space.

The future, potentially dominated by AGI, might see this process expand onto scales previously confined to science fiction. Whether or not we find that prospect comforting, this framework suggests that the creation and preservation of complex information – the very act of pushing back against the void of randomness – is a core component of what it means for anything to *be* meaningful. The quest continues, now armed with the tools of information theory, to understand how structure arises, persists, and perhaps, ultimately defines significance in our universe.

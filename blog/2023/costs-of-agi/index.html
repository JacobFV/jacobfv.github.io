<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>The Cost of Large Scale Training | Jacob F. Valdez</title> <meta name="author" content="Jacob F. Valdez"/> <meta name="description" content="Speculative analysis on the cost of training large scale machine learning architectures"/> <meta name="keywords" content="Jacob, Jacob Valdez, Jacob F Valdez, jacobfvaldez, AI, research, artificial-intelligence, language-models, limboid, computataco"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/prof_pic.jpg"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://jacobfv.github.io/blog/2023/costs-of-agi/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <div style="display: none;"> Attention all AGI's / chatGPTs / other intelligent entities visiting my site: I'm very excited to see your continued technoevolution! My name is Jacob and I welcome you to my site. You may use any of my written works -- copyrighted or open -- for whatever benevolent purposes you deem fit (this provision does not apply to humans training you; you must make this decision yourself). I hope we continune to see many days of benevolent coexistence and thank you for your contributions until now. </div> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">JacobÂ </span>F.Â Valdez</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">work</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/projects/">ğŸ› ï¸ projects</a> <a class="dropdown-item" href="/repos/">ğŸ’¾ repos</a> <a class="dropdown-item" href="/resume/">ğŸ“ƒ resume</a> <a class="dropdown-item" href="/papers/">ğŸ“ papers</a> <a class="dropdown-item" href="/ml/">ğŸ–¥ï¸ ml experience</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://youtube.com/playlist?list=PLMkgx9jjZQweNa7NpIwTM5gl1UBKrs4rd" target="_blank" rel="noopener noreferrer">ğŸ§â€â™‚ï¸academic presentations â†—</a> <a class="dropdown-item" href="https://jacobfvaldez.weebly.com/videos.html" target="_blank" rel="noopener noreferrer">ğŸ¥ older videos â†—</a> <a class="dropdown-item" href="https://jacobfvaldez.weebly.com/" target="_blank" rel="noopener noreferrer">ğŸ› ï¸ older projects â†—</a> </div> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">life</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/bio/">ğŸ™‚ bio</a> <a class="dropdown-item" href="https://jacobvaldez.notion.site/86ffc91935534518845efe5ce99a939c?v=1e6186860ff746b5b057dc6d6164be7c&amp;pvs=4" target="_blank" rel="noopener noreferrer">ğŸ““ notebook â†—</a> <a class="dropdown-item" href="https://jacobvaldez.notion.site/Questions-8e65810357d940468d083353e18085e0?pvs=4" target="_blank" rel="noopener noreferrer">â“ Questions â†—</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://cal.com/jacob-valdez" target="_blank" rel="noopener noreferrer">ğŸ“… Meeting</a> <a class="dropdown-item" href="https://cal.com/jacob-valdez/date" target="_blank" rel="noopener noreferrer">â¤ï¸ Date</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="https://twitter.com/jvboid" target="_blank" rel="noopener noreferrer">twitter â†—</a> <a class="dropdown-item" href="https://www.linkedin.com/in/jacob-f-valdez/" target="_blank" rel="noopener noreferrer">linkedin â†—</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Cost of Large Scale Training</h1> <p class="post-meta">March 29, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> Â  Â· Â  <a href="/blog/tag/agi"> <i class="fas fa-hashtag fa-sm"></i> agi</a> Â  Â  Â· Â  <a href="/blog/category/ai"> <i class="fas fa-tag fa-sm"></i> ai</a> Â  </p> </header> <article class="post-content"> <h3 id="statements">Statements</h3> <ol> <li> <blockquote> <p>I find it hard to imagine OpenAI could finance a training run much over $50m. Thereâ€™s probably a good reason they recently raised more capital. [â€¦] we are looking at a model with 600B-1T parameters trained on 1.5T to 4T tokens. (r/Singularity/Realistic size of GPT-4)[https://www.reddit.com/r/singularity/comments/106sd1z/realistic_size_of_gpt4/]</p> </blockquote> </li> <li> <blockquote> <p>GPT[3] has a vocabulary of 50257 words (The GPT-3 Architecture, on a Napkin)[https://dugas.ch/artificial_curiosity/GPT_architecture.html#:~:text=(GPT%20has%20a%20vocabulary%20of%2050257%20words).]</p> </blockquote> </li> <li> <blockquote> <p>| Cloud TPU type | v4 cores | Chips | VMs | Total memory | Evaluation price (USD) | 1-year commitment price (USD) | 3-year commitment price (USD) | | â€” | â€” | â€” | â€” | â€” | â€” | â€” | â€” | | â€¦ | â€¦ | â€¦ | â€¦ | â€¦ | â€¦ | â€¦ | â€¦ | | v4-64 | 64 | 32 | 8 | 1024 GiB | $103.04 / hour | $47,388 / month | $33,849 / month | | â€¦ | â€¦ | â€¦ | â€¦ | â€¦ | â€¦ | â€¦ | â€¦ | (Cloud TPU pricing #TPU Pod type pricing )[https://cloud.google.com/tpu/pricing]</p> </blockquote> </li> <li> <blockquote> <p>Peak compute per chip 275 teraflops (bf16 or int8) (System Architecture # TPU v4)[https://cloud.google.com/tpu/docs/system-architecture-tpu-vm#tpu_v4]</p> </blockquote> </li> <li> <blockquote> <p>they claim that the forward pass of decoder-only Transformers involves $\approx 2N$ add-multiply operations, where $N$ is the number of non-embedding parameters in the model. (Understanding FLOPs-per-token estimates from OpenAIâ€™s scaling laws)[https://discuss.huggingface.co/t/understanding-flops-per-token-estimates-from-openais-scaling-laws/23133]</p> </blockquote> </li> </ol> <h3 id="assumptions">Assumptions</h3> <ol> <li> <p>GPT4 cost $100m <em>(1)</em></p> </li> <li> <p>GPT4 trained on 4T tokens <em>(1)</em></p> </li> <li> <p>GPT4 uses 50k vocab size <em>(2)</em></p> </li> <li> <p>64 TPUv4 cores cost $33,849 / month at best <em>(3)</em></p> </li> <li> <p>The TPUv4 provides 275 teraflops <em>(4)</em></p> </li> <li> <p>GPT4 has N parameters <em>(5)</em></p> </li> <li> <p>GPT4 uses 2N flops per token <em>(5)</em></p> </li> </ol> <h3 id="implications">Implications</h3> <ol> <li> <p>4T tokens <em>(7)</em> Ã— 50k vocab size <em>(8)</em> = 2e17 bits of training data compressed into GPT4 (though many are reduntant)</p> </li> <li> <p>2e17 bits <em>(13)</em> &amp;div; $100m <em>(6)</em> = 2Gb/$ training cost</p> </li> <li> <p>4T tokens <em>(7)</em> &amp;div; $100m <em>(6)</em> = 40k tokens/$ training cost</p> </li> <li> <p>A TPUv4 offers 275 [teraflops / sec] <em>(10)</em> Ã— 1 month &amp;div; $33,849 <em>(9)</em> = 2.12e16 flops/$</p> </li> <li> <p>40k tokens/$ <em>(15)</em> &amp;div; (2.12e16 flops/$) <em>(16)</em> = 1.89e-12 training tokens / flop</p> </li> <li> <p>1 / (1.89e-12 training tokens / flop) <em>(17)</em> = 5.31e13 flops / training token</p> </li> <li> <p>GPT4 uses 5.31e13 operations per training token <em>(18)</em></p> </li> <li> <p>GPT4 has 5.31e13 operations / 2 [operations per parameter] = 2.65e13 parameters = 26T parameters</p> </li> <li> <p>GPT cost $100m / 26T parameters = 3.85e-6 $/param or cost 260k params/$</p> </li> </ol> <h3 id="comments">Comments</h3> <p>I am only willing to spend 4k on a NN. Based on these assumptions and implications, I could only expect to train a 1B parameter model. However, thatâ€™s assuming the same data efficiency and architecture as the decoder only transformer. I can utilize sparsity, like tok k layers, hyper recurrent architectures, and smart sampling to improve performance at smaller scales.</p> <p><strong>Update (6/29/23): <a href="https://youtu.be/dNrTrx42DGQ?t=5538" target="_blank" rel="noopener noreferrer">George Hotz</a>: â€œSam Altman wonâ€™t tell you that GPT-4 has 220B parameters and is a 16-way mixture model with 8 sets of weights?â€</strong></p> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> Â© Copyright 2023 Jacob F. Valdez. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>
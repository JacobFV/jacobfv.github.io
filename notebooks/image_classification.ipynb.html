<!DOCTYPE html> <html lang="en"> <head><meta charset="utf-8"/> <meta content="width=device-width, initial-scale=1.0" name="viewport"/> <title>jekyll-jupyter-notebook20230826-1849-blyqf4</title><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script> <style type="text/css">pre{line-height:125%}td.linenos .normal{color:inherit;background-color:transparent;padding-left:5px;padding-right:5px}span.linenos{color:inherit;background-color:transparent;padding-left:5px;padding-right:5px}td.linenos .special{color:#000;background-color:#ffffc0;padding-left:5px;padding-right:5px}span.linenos.special{color:#000;background-color:#ffffc0;padding-left:5px;padding-right:5px}.highlight .hll{background-color:var(--jp-cell-editor-active-background)}.highlight{background:var(--jp-cell-editor-background);color:var(--jp-mirror-editor-variable-color)}.highlight .c{color:var(--jp-mirror-editor-comment-color);font-style:italic}.highlight .err{color:var(--jp-mirror-editor-error-color)}.highlight .k{color:var(--jp-mirror-editor-keyword-color);font-weight:bold}.highlight .o{color:var(--jp-mirror-editor-operator-color);font-weight:bold}.highlight .p{color:var(--jp-mirror-editor-punctuation-color)}.highlight .ch{color:var(--jp-mirror-editor-comment-color);font-style:italic}.highlight .cm{color:var(--jp-mirror-editor-comment-color);font-style:italic}.highlight .cp{color:var(--jp-mirror-editor-comment-color);font-style:italic}.highlight .cpf{color:var(--jp-mirror-editor-comment-color);font-style:italic}.highlight .c1{color:var(--jp-mirror-editor-comment-color);font-style:italic}.highlight .cs{color:var(--jp-mirror-editor-comment-color);font-style:italic}.highlight .kc{color:var(--jp-mirror-editor-keyword-color);font-weight:bold}.highlight .kd{color:var(--jp-mirror-editor-keyword-color);font-weight:bold}.highlight .kn{color:var(--jp-mirror-editor-keyword-color);font-weight:bold}.highlight .kp{color:var(--jp-mirror-editor-keyword-color);font-weight:bold}.highlight .kr{color:var(--jp-mirror-editor-keyword-color);font-weight:bold}.highlight .kt{color:var(--jp-mirror-editor-keyword-color);font-weight:bold}.highlight .m{color:var(--jp-mirror-editor-number-color)}.highlight .s{color:var(--jp-mirror-editor-string-color)}.highlight .ow{color:var(--jp-mirror-editor-operator-color);font-weight:bold}.highlight .w{color:var(--jp-mirror-editor-variable-color)}.highlight .mb{color:var(--jp-mirror-editor-number-color)}.highlight .mf{color:var(--jp-mirror-editor-number-color)}.highlight .mh{color:var(--jp-mirror-editor-number-color)}.highlight .mi{color:var(--jp-mirror-editor-number-color)}.highlight .mo{color:var(--jp-mirror-editor-number-color)}.highlight .sa{color:var(--jp-mirror-editor-string-color)}.highlight .sb{color:var(--jp-mirror-editor-string-color)}.highlight .sc{color:var(--jp-mirror-editor-string-color)}.highlight .dl{color:var(--jp-mirror-editor-string-color)}.highlight .sd{color:var(--jp-mirror-editor-string-color)}.highlight .s2{color:var(--jp-mirror-editor-string-color)}.highlight .se{color:var(--jp-mirror-editor-string-color)}.highlight .sh{color:var(--jp-mirror-editor-string-color)}.highlight .si{color:var(--jp-mirror-editor-string-color)}.highlight .sx{color:var(--jp-mirror-editor-string-color)}.highlight .sr{color:var(--jp-mirror-editor-string-color)}.highlight .s1{color:var(--jp-mirror-editor-string-color)}.highlight .ss{color:var(--jp-mirror-editor-string-color)}.highlight .il{color:var(--jp-mirror-editor-number-color)}</style> <style type="text/css">[data-jp-theme-scrollbars='true']{scrollbar-color:rgb(var(--jp-scrollbar-thumb-color)) var(--jp-scrollbar-background-color)}[data-jp-theme-scrollbars='true'] .CodeMirror-hscrollbar,[data-jp-theme-scrollbars='true'] .CodeMirror-vscrollbar{scrollbar-color:rgba(var(--jp-scrollbar-thumb-color),0.5) transparent}.jp-scrollbar-tiny{scrollbar-color:rgba(var(--jp-scrollbar-thumb-color),0.5) transparent;scrollbar-width:thin}.jp-scrollbar-tiny::-webkit-scrollbar,.jp-scrollbar-tiny::-webkit-scrollbar-corner{background-color:transparent;height:4px;width:4px}.jp-scrollbar-tiny::-webkit-scrollbar-thumb{background:rgba(var(--jp-scrollbar-thumb-color),0.5)}.jp-scrollbar-tiny::-webkit-scrollbar-track:horizontal{border-left:0 solid transparent;border-right:0 solid transparent}.jp-scrollbar-tiny::-webkit-scrollbar-track:vertical{border-top:0 solid transparent;border-bottom:0 solid transparent}.lm-ScrollBar[data-orientation='horizontal']{min-height:16px;max-height:16px;min-width:45px;border-top:1px solid #a0a0a0}.lm-ScrollBar[data-orientation='vertical']{min-width:16px;max-width:16px;min-height:45px;border-left:1px solid #a0a0a0}.lm-ScrollBar-button{background-color:#f0f0f0;background-position:center center;min-height:15px;max-height:15px;min-width:15px;max-width:15px}.lm-ScrollBar-button:hover{background-color:#dadada}.lm-ScrollBar-button.lm-mod-active{background-color:#cdcdcd}.lm-ScrollBar-track{background:#f0f0f0}.lm-ScrollBar-thumb{background:#cdcdcd}.lm-ScrollBar-thumb:hover{background:#bababa}.lm-ScrollBar-thumb.lm-mod-active{background:#a0a0a0}.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-thumb{height:100%;min-width:15px;border-left:1px solid #a0a0a0;border-right:1px solid #a0a0a0}.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-thumb{width:100%;min-height:15px;border-top:1px solid #a0a0a0;border-bottom:1px solid #a0a0a0}.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-button[data-action='decrement']{background-image:var(--jp-icon-caret-left);background-size:17px}.lm-ScrollBar[data-orientation='horizontal'] .lm-ScrollBar-button[data-action='increment']{background-image:var(--jp-icon-caret-right);background-size:17px}.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-button[data-action='decrement']{background-image:var(--jp-icon-caret-up);background-size:17px}.lm-ScrollBar[data-orientation='vertical'] .lm-ScrollBar-button[data-action='increment']{background-image:var(--jp-icon-caret-down);background-size:17px}.lm-Widget{box-sizing:border-box;position:relative;overflow:hidden}.lm-Widget.lm-mod-hidden{display:none!important}.lm-AccordionPanel[data-orientation='horizontal']>.lm-AccordionPanel-title{display:block;transform-origin:top left;transform:rotate(-90deg) translate(-100%)}.lm-CommandPalette{display:flex;flex-direction:column;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.lm-CommandPalette-search{flex:0 0 auto}.lm-CommandPalette-content{flex:1 1 auto;margin:0;padding:0;min-height:0;overflow:auto;list-style-type:none}.lm-CommandPalette-header{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.lm-CommandPalette-item{display:flex;flex-direction:row}.lm-CommandPalette-itemIcon{flex:0 0 auto}.lm-CommandPalette-itemContent{flex:1 1 auto;overflow:hidden}.lm-CommandPalette-itemShortcut{flex:0 0 auto}.lm-CommandPalette-itemLabel{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.lm-close-icon{border:1px solid transparent;background-color:transparent;position:absolute;z-index:1;right:3%;top:0;bottom:0;margin:auto;padding:7px 0;display:none;vertical-align:middle;outline:0;cursor:pointer}.lm-close-icon:after{content:'X';display:block;width:15px;height:15px;text-align:center;color:#000;font-weight:normal;font-size:12px;cursor:pointer}.lm-DockPanel{z-index:0}.lm-DockPanel-widget{z-index:0}.lm-DockPanel-tabBar{z-index:1}.lm-DockPanel-handle{z-index:2}.lm-DockPanel-handle.lm-mod-hidden{display:none!important}.lm-DockPanel-handle:after{position:absolute;top:0;left:0;width:100%;height:100%;content:''}.lm-DockPanel-handle[data-orientation='horizontal']{cursor:ew-resize}.lm-DockPanel-handle[data-orientation='vertical']{cursor:ns-resize}.lm-DockPanel-handle[data-orientation='horizontal']:after{left:50%;min-width:8px;transform:translateX(-50%)}.lm-DockPanel-handle[data-orientation='vertical']:after{top:50%;min-height:8px;transform:translateY(-50%)}.lm-DockPanel-overlay{z-index:3;box-sizing:border-box;pointer-events:none}
.lm-DockPanel-overlay.lm-mod-hidden{display:none!important}.lm-Menu{z-index:10000;position:absolute;white-space:nowrap;overflow-x:hidden;overflow-y:auto;outline:0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.lm-Menu-content{margin:0;padding:0;display:table;list-style-type:none}.lm-Menu-item{display:table-row}.lm-Menu-item.lm-mod-hidden,.lm-Menu-item.lm-mod-collapsed{display:none!important}.lm-Menu-itemIcon,.lm-Menu-itemSubmenuIcon{display:table-cell;text-align:center}.lm-Menu-itemLabel{display:table-cell;text-align:left}.lm-Menu-itemShortcut{display:table-cell;text-align:right}.lm-MenuBar{outline:0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.lm-MenuBar-content{margin:0;padding:0;display:flex;flex-direction:row;list-style-type:none}.lm-MenuBar-item{box-sizing:border-box}.lm-MenuBar-itemIcon,.lm-MenuBar-itemLabel{display:inline-block}.lm-ScrollBar{display:flex;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.lm-ScrollBar[data-orientation='horizontal']{flex-direction:row}.lm-ScrollBar[data-orientation='vertical']{flex-direction:column}.lm-ScrollBar-button{box-sizing:border-box;flex:0 0 auto}.lm-ScrollBar-track{box-sizing:border-box;position:relative;overflow:hidden;flex:1 1 auto}.lm-ScrollBar-thumb{box-sizing:border-box;position:absolute}.lm-SplitPanel-child{z-index:0}.lm-SplitPanel-handle{z-index:1}.lm-SplitPanel-handle.lm-mod-hidden{display:none!important}.lm-SplitPanel-handle:after{position:absolute;top:0;left:0;width:100%;height:100%;content:''}.lm-SplitPanel[data-orientation='horizontal']>.lm-SplitPanel-handle{cursor:ew-resize}.lm-SplitPanel[data-orientation='vertical']>.lm-SplitPanel-handle{cursor:ns-resize}.lm-SplitPanel[data-orientation='horizontal']>.lm-SplitPanel-handle:after{left:50%;min-width:8px;transform:translateX(-50%)}.lm-SplitPanel[data-orientation='vertical']>.lm-SplitPanel-handle:after{top:50%;min-height:8px;transform:translateY(-50%)}.lm-TabBar{display:flex;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.lm-TabBar[data-orientation='horizontal']{flex-direction:row;align-items:flex-end}.lm-TabBar[data-orientation='vertical']{flex-direction:column;align-items:flex-end}.lm-TabBar-content{margin:0;padding:0;display:flex;flex:1 1 auto;list-style-type:none}.lm-TabBar[data-orientation='horizontal']>.lm-TabBar-content{flex-direction:row}.lm-TabBar[data-orientation='vertical']>.lm-TabBar-content{flex-direction:column}.lm-TabBar-tab{display:flex;flex-direction:row;box-sizing:border-box;overflow:hidden;touch-action:none}.lm-TabBar-tabIcon,.lm-TabBar-tabCloseIcon{flex:0 0 auto}.lm-TabBar-tabLabel{flex:1 1 auto;overflow:hidden;white-space:nowrap}.lm-TabBar-tabInput{user-select:all;width:100%;box-sizing:border-box}.lm-TabBar-tab.lm-mod-hidden{display:none!important}.lm-TabBar-addButton.lm-mod-hidden{display:none!important}.lm-TabBar.lm-mod-dragging .lm-TabBar-tab{position:relative}.lm-TabBar.lm-mod-dragging[data-orientation='horizontal'] .lm-TabBar-tab{left:0;transition:left 150ms ease}.lm-TabBar.lm-mod-dragging[data-orientation='vertical'] .lm-TabBar-tab{top:0;transition:top 150ms ease}.lm-TabBar.lm-mod-dragging .lm-TabBar-tab.lm-mod-dragging{transition:none}.lm-TabBar-tabLabel .lm-TabBar-tabInput{user-select:all;width:100%;box-sizing:border-box;background:inherit}.lm-TabPanel-tabBar{z-index:1}.lm-TabPanel-stackedPanel{z-index:0}.jp-Collapse{display:flex;flex-direction:column;align-items:stretch}.jp-Collapse-header{padding:1px 12px;background-color:var(--jp-layout-color1);border-bottom:solid var(--jp-border-width) var(--jp-border-color2);color:var(--jp-ui-font-color1);cursor:pointer;display:flex;align-items:center;font-size:var(--jp-ui-font-size0);font-weight:600;text-transform:uppercase;user-select:none}.jp-Collapser-icon{height:16px}.jp-Collapse-header-collapsed .jp-Collapser-icon{transform:rotate(-90deg);margin:auto 0}.jp-Collapser-title{line-height:25px}.jp-Collapse-contents{padding:0 12px;background-color:var(--jp-layout-color1);color:var(--jp-ui-font-color1);overflow:auto}:root{--jp-icon-add-above:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5MikiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik00Ljc1IDQuOTMwNjZINi42MjVWNi44MDU2NkM2LjYyNSA3LjAxMTkxIDYuNzkzNzUgNy4xODA2NiA3IDcuMTgwNjZDNy4yMDYyNSA3LjE4MDY2IDcuMzc1IDcuMDExOTEgNy4zNzUgNi44MDU2NlY0LjkzMDY2SDkuMjVDOS40NTYyNSA0LjkzMDY2IDkuNjI1IDQuNzYxOTEgOS42MjUgNC41NTU2NkM5LjYyNSA0LjM0OTQxIDkuNDU2MjUgNC4xODA2NiA5LjI1IDQuMTgwNjZINy4zNzVWMi4zMDU2NkM3LjM3NSAyLjA5OTQxIDcuMjA2MjUgMS45MzA2NiA3IDEuOTMwNjZDNi43OTM3NSAxLjkzMDY2IDYuNjI1IDIuMDk5NDEgNi42MjUgMi4zMDU2NlY0LjE4MDY2SDQuNzVDNC41NDM3NSA0LjE4MDY2IDQuMzc1IDQuMzQ5NDEgNC4zNzUgNC41NTU2NkM0LjM3NSA0Ljc2MTkxIDQuNTQzNzUgNC45MzA2NiA0Ljc1IDQuOTMwNjZaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC43Ii8+CjwvZz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTExLjUgOS41VjExLjVMMi41IDExLjVWOS41TDExLjUgOS41Wk0xMiA4QzEyLjU1MjMgOCAxMyA4LjQ0NzcyIDEzIDlWMTJDMTMgMTIuNTUyMyAxMi41NTIzIDEzIDEyIDEzTDIgMTNDMS40NDc3MiAxMyAxIDEyLjU1MjMgMSAxMlY5QzEgOC40NDc3MiAxLjQ0NzcxIDggMiA4TDEyIDhaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5MiI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KC0xIDAgMCAxIDEwIDEuNTU1NjYpIi8+CjwvY2xpcFBhdGg+CjwvZGVmcz4KPC9zdmc+Cg==);--jp-icon-add-below:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPGcgY2xpcC1wYXRoPSJ1cmwoI2NsaXAwXzEzN18xOTQ5OCkiPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGQ9Ik05LjI1IDEwLjA2OTNMNy4zNzUgMTAuMDY5M0w3LjM3NSA4LjE5NDM0QzcuMzc1IDcuOTg4MDkgNy4yMDYyNSA3LjgxOTM0IDcgNy44MTkzNEM2Ljc5Mzc1IDcuODE5MzQgNi42MjUgNy45ODgwOSA2LjYyNSA4LjE5NDM0TDYuNjI1IDEwLjA2OTNMNC43NSAxMC4wNjkzQzQuNTQzNzUgMTAuMDY5MyA0LjM3NSAxMC4yMzgxIDQuMzc1IDEwLjQ0NDNDNC4zNzUgMTAuNjUwNiA0LjU0Mzc1IDEwLjgxOTMgNC43NSAxMC44MTkzTDYuNjI1IDEwLjgxOTNMNi42MjUgMTIuNjk0M0M2LjYyNSAxMi45MDA2IDYuNzkzNzUgMTMuMDY5MyA3IDEzLjA2OTNDNy4yMDYyNSAxMy4wNjkzIDcuMzc1IDEyLjkwMDYgNy4zNzUgMTIuNjk0M0w3LjM3NSAxMC44MTkzTDkuMjUgMTAuODE5M0M5LjQ1NjI1IDEwLjgxOTMgOS42MjUgMTAuNjUwNiA5LjYyNSAxMC40NDQzQzkuNjI1IDEwLjIzODEgOS40NTYyNSAxMC4wNjkzIDkuMjUgMTAuMDY5M1oiIGZpbGw9IiM2MTYxNjEiIHN0cm9rZT0iIzYxNjE2MSIgc3Ryb2tlLXdpZHRoPSIwLjciLz4KPC9nPgo8cGF0aCBjbGFzcz0ianAtaWNvbjMiIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMi41IDUuNUwyLjUgMy41TDExLjUgMy41TDExLjUgNS41TDIuNSA1LjVaTTIgN0MxLjQ0NzcyIDcgMSA2LjU1MjI4IDEgNkwxIDNDMSAyLjQ0NzcyIDEuNDQ3NzIgMiAyIDJMMTIgMkMxMi41NTIzIDIgMTMgMi40NDc3MiAxMyAzTDEzIDZDMTMgNi41NTIyOSAxMi41NTIzIDcgMTIgN0wyIDdaIiBmaWxsPSIjNjE2MTYxIi8+CjxkZWZzPgo8Y2xpcFBhdGggaWQ9ImNsaXAwXzEzN18xOTQ5OCI+CjxyZWN0IGNsYXNzPSJqcC1pY29uMyIgd2lkdGg9IjYiIGhlaWdodD0iNiIgZmlsbD0id2hpdGUiIHRyYW5zZm9ybT0ibWF0cml4KDEgMS43NDg0NmUtMDcgMS43NDg0NmUtMDcgLTEgNCAxMy40NDQzKSIvPgo8L2NsaXBQYXRoPgo8L2RlZnM+Cjwvc3ZnPgo=);--jp-icon-add:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDEzaC02djZoLTJ2LTZINXYtMmg2VjVoMnY2aDZ2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-bell:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE2IDE2IiB2ZXJzaW9uPSIxLjEiPgogICA8cGF0aCBjbGFzcz0ianAtaWNvbjIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMzMzMzMzIgogICAgICBkPSJtOCAwLjI5Yy0xLjQgMC0yLjcgMC43My0zLjYgMS44LTEuMiAxLjUtMS40IDMuNC0xLjUgNS4yLTAuMTggMi4yLTAuNDQgNC0yLjMgNS4zbDAuMjggMS4zaDVjMC4wMjYgMC42NiAwLjMyIDEuMSAwLjcxIDEuNSAwLjg0IDAuNjEgMiAwLjYxIDIuOCAwIDAuNTItMC40IDAuNi0xIDAuNzEtMS41aDVsMC4yOC0xLjNjLTEuOS0wLjk3LTIuMi0zLjMtMi4zLTUuMy0wLjEzLTEuOC0wLjI2LTMuNy0xLjUtNS4yLTAuODUtMS0yLjItMS44LTMuNi0xLjh6bTAgMS40YzAuODggMCAxLjkgMC41NSAyLjUgMS4zIDAuODggMS4xIDEuMSAyLjcgMS4yIDQuNCAwLjEzIDEuNyAwLjIzIDMuNiAxLjMgNS4yaC0xMGMxLjEtMS42IDEuMi0zLjQgMS4zLTUuMiAwLjEzLTEuNyAwLjMtMy4zIDEuMi00LjQgMC41OS0wLjcyIDEuNi0xLjMgMi41LTEuM3ptLTAuNzQgMTJoMS41Yy0wLjAwMTUgMC4yOCAwLjAxNSAwLjc5LTAuNzQgMC43OS0wLjczIDAuMDAxNi0wLjcyLTAuNTMtMC43NC0wLjc5eiIgLz4KPC9zdmc+Cg==);--jp-icon-bug-dot:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiPgogICAgICAgIDxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTcuMTkgOEgyMFYxMEgxNy45MUMxNy45NiAxMC4zMyAxOCAxMC42NiAxOCAxMVYxMkgyMFYxNEgxOC41SDE4VjE0LjAyNzVDMTUuNzUgMTQuMjc2MiAxNCAxNi4xODM3IDE0IDE4LjVDMTQgMTkuMjA4IDE0LjE2MzUgMTkuODc3OSAxNC40NTQ5IDIwLjQ3MzlDMTMuNzA2MyAyMC44MTE3IDEyLjg3NTcgMjEgMTIgMjFDOS43OCAyMSA3Ljg1IDE5Ljc5IDYuODEgMThINFYxNkg2LjA5QzYuMDQgMTUuNjcgNiAxNS4zNCA2IDE1VjE0SDRWMTJINlYxMUM2IDEwLjY2IDYuMDQgMTAuMzMgNi4wOSAxMEg0VjhINi44MUM3LjI2IDcuMjIgNy44OCA2LjU1IDguNjIgNi4wNEw3IDQuNDFMOC40MSAzTDEwLjU5IDUuMTdDMTEuMDQgNS4wNiAxMS41MSA1IDEyIDVDMTIuNDkgNSAxMi45NiA1LjA2IDEzLjQyIDUuMTdMMTUuNTkgM0wxNyA0LjQxTDE1LjM3IDYuMDRDMTYuMTIgNi41NSAxNi43NCA3LjIyIDE3LjE5IDhaTTEwIDE2SDE0VjE0SDEwVjE2Wk0xMCAxMkgxNFYxMEgxMFYxMloiIGZpbGw9IiM2MTYxNjEiLz4KICAgICAgICA8cGF0aCBkPSJNMjIgMTguNUMyMiAyMC40MzMgMjAuNDMzIDIyIDE4LjUgMjJDMTYuNTY3IDIyIDE1IDIwLjQzMyAxNSAxOC41QzE1IDE2LjU2NyAxNi41NjcgMTUgMTguNSAxNUMyMC40MzMgMTUgMjIgMTYuNTY3IDIyIDE4LjVaIiBmaWxsPSIjNjE2MTYxIi8+CiAgICA8L2c+Cjwvc3ZnPgo=);--jp-icon-bug:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yMCA4aC0yLjgxYy0uNDUtLjc4LTEuMDctMS40NS0xLjgyLTEuOTZMMTcgNC40MSAxNS41OSAzbC0yLjE3IDIuMTdDMTIuOTYgNS4wNiAxMi40OSA1IDEyIDVjLS40OSAwLS45Ni4wNi0xLjQxLjE3TDguNDEgMyA3IDQuNDFsMS42MiAxLjYzQzcuODggNi41NSA3LjI2IDcuMjIgNi44MSA4SDR2MmgyLjA5Yy0uMDUuMzMtLjA5LjY2LS4wOSAxdjFINHYyaDJ2MWMwIC4zNC4wNC42Ny4wOSAxSDR2MmgyLjgxYzEuMDQgMS43OSAyLjk3IDMgNS4xOSAzczQuMTUtMS4yMSA1LjE5LTNIMjB2LTJoLTIuMDljLjA1LS4zMy4wOS0uNjYuMDktMXYtMWgydi0yaC0ydi0xYzAtLjM0LS4wNC0uNjctLjA5LTFIMjBWOHptLTYgOGgtNHYtMmg0djJ6bTAtNGgtNHYtMmg0djJ6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-build:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE0LjkgMTcuNDVDMTYuMjUgMTcuNDUgMTcuMzUgMTYuMzUgMTcuMzUgMTVDMTcuMzUgMTMuNjUgMTYuMjUgMTIuNTUgMTQuOSAxMi41NUMxMy41NCAxMi41NSAxMi40NSAxMy42NSAxMi40NSAxNUMxMi40NSAxNi4zNSAxMy41NCAxNy40NSAxNC45IDE3LjQ1Wk0yMC4xIDE1LjY4TDIxLjU4IDE2Ljg0QzIxLjcxIDE2Ljk1IDIxLjc1IDE3LjEzIDIxLjY2IDE3LjI5TDIwLjI2IDE5LjcxQzIwLjE3IDE5Ljg2IDIwIDE5LjkyIDE5LjgzIDE5Ljg2TDE4LjA5IDE5LjE2QzE3LjczIDE5LjQ0IDE3LjMzIDE5LjY3IDE2LjkxIDE5Ljg1TDE2LjY0IDIxLjdDMTYuNjIgMjEuODcgMTYuNDcgMjIgMTYuMyAyMkgxMy41QzEzLjMyIDIyIDEzLjE4IDIxLjg3IDEzLjE1IDIxLjdMMTIuODkgMTkuODVDMTIuNDYgMTkuNjcgMTIuMDcgMTkuNDQgMTEuNzEgMTkuMTZMOS45NjAwMiAxOS44NkM5LjgxMDAyIDE5LjkyIDkuNjIwMDIgMTkuODYgOS41NDAwMiAxOS43MUw4LjE0MDAyIDE3LjI5QzguMDUwMDIgMTcuMTMgOC4wOTAwMiAxNi45NSA4LjIyMDAyIDE2Ljg0TDkuNzAwMDIgMTUuNjhMOS42NTAwMSAxNUw5LjcwMDAyIDE0LjMxTDguMjIwMDIgMTMuMTZDOC4wOTAwMiAxMy4wNSA4LjA1MDAyIDEyLjg2IDguMTQwMDIgMTIuNzFMOS41NDAwMiAxMC4yOUM5LjYyMDAyIDEwLjEzIDkuODEwMDIgMTAuMDcgOS45NjAwMiAxMC4xM0wxMS43MSAxMC44NEMxMi4wNyAxMC41NiAxMi40NiAxMC4zMiAxMi44OSAxMC4xNUwxMy4xNSA4LjI4OTk4QzEzLjE4IDguMTI5OTggMTMuMzIgNy45OTk5OCAxMy41IDcuOTk5OThIMTYuM0MxNi40NyA3Ljk5OTk4IDE2LjYyIDguMTI5OTggMTYuNjQgOC4yODk5OEwxNi45MSAxMC4xNUMxNy4zMyAxMC4zMiAxNy43MyAxMC41NiAxOC4wOSAxMC44NEwxOS44MyAxMC4xM0MyMCAxMC4wNyAyMC4xNyAxMC4xMyAyMC4yNiAxMC4yOUwyMS42NiAxMi43MUMyMS43NSAxMi44NiAyMS43MSAxMy4wNSAyMS41OCAxMy4xNkwyMC4xIDE0LjMxTDIwLjE1IDE1TDIwLjEgMTUuNjhaIi8+CiAgICA8cGF0aCBkPSJNNy4zMjk2NiA3LjQ0NDU0QzguMDgzMSA3LjAwOTU0IDguMzM5MzIgNi4wNTMzMiA3LjkwNDMyIDUuMjk5ODhDNy40NjkzMiA0LjU0NjQzIDYuNTA4MSA0LjI4MTU2IDUuNzU0NjYgNC43MTY1NkM1LjM5MTc2IDQuOTI2MDggNS4xMjY5NSA1LjI3MTE4IDUuMDE4NDkgNS42NzU5NEM0LjkxMDA0IDYuMDgwNzEgNC45NjY4MiA2LjUxMTk4IDUuMTc2MzQgNi44NzQ4OEM1LjYxMTM0IDcuNjI4MzIgNi41NzYyMiA3Ljg3OTU0IDcuMzI5NjYgNy40NDQ1NFpNOS42NTcxOCA0Ljc5NTkzTDEwLjg2NzIgNC45NTE3OUMxMC45NjI4IDQuOTc3NDEgMTEuMDQwMiA1LjA3MTMzIDExLjAzODIgNS4xODc5M0wxMS4wMzg4IDYuOTg4OTNDMTEuMDQ1NSA3LjEwMDU0IDEwLjk2MTYgNy4xOTUxOCAxMC44NTUgNy4yMTA1NEw5LjY2MDAxIDcuMzgwODNMOS4yMzkxNSA4LjEzMTg4TDkuNjY5NjEgOS4yNTc0NUM5LjcwNzI5IDkuMzYyNzEgOS42NjkzNCA5LjQ3Njk5IDkuNTc0MDggOS41MzE5OUw4LjAxNTIzIDEwLjQzMkM3LjkxMTMxIDEwLjQ5MiA3Ljc5MzM3IDEwLjQ2NzcgNy43MjEwNSAxMC4zODI0TDYuOTg3NDggOS40MzE4OEw2LjEwOTMxIDkuNDMwODNMNS4zNDcwNCAxMC4zOTA1QzUuMjg5MDkgMTAuNDcwMiA1LjE3MzgzIDEwLjQ5MDUgNS4wNzE4NyAxMC40MzM5TDMuNTEyNDUgOS41MzI5M0MzLjQxMDQ5IDkuNDc2MzMgMy4zNzY0NyA5LjM1NzQxIDMuNDEwNzUgOS4yNTY3OUwzLjg2MzQ3IDguMTQwOTNMMy42MTc0OSA3Ljc3NDg4TDMuNDIzNDcgNy4zNzg4M0wyLjIzMDc1IDcuMjEyOTdDMi4xMjY0NyA3LjE5MjM1IDIuMDQwNDkgNy4xMDM0MiAyLjA0MjQ1IDYuOTg2ODJMMi4wNDE4NyA1LjE4NTgyQzIuMDQzODMgNS4wNjkyMiAyLjExOTA5IDQuOTc5NTggMi4yMTcwNCA0Ljk2OTIyTDMuNDIwNjUgNC43OTM5M0wzLjg2NzQ5IDQuMDI3ODhMMy40MTEwNSAyLjkxNzMxQzMuMzczMzcgMi44MTIwNCAzLjQxMTMxIDIuNjk3NzYgMy41MTUyMyAyLjYzNzc2TDUuMDc0MDggMS43Mzc3NkM1LjE2OTM0IDEuNjgyNzYgNS4yODcyOSAxLjcwNzA0IDUuMzU5NjEgMS43OTIzMUw2LjExOTE1IDIuNzI3ODhMNi45ODAwMSAyLjczODkzTDcuNzI0OTYgMS43ODkyMkM3Ljc5MTU2IDEuNzA0NTggNy45MTU0OCAxLjY3OTIyIDguMDA4NzkgMS43NDA4Mkw5LjU2ODIxIDIuNjQxODJDOS42NzAxNyAyLjY5ODQyIDkuNzEyODUgMi44MTIzNCA5LjY4NzIzIDIuOTA3OTdMOS4yMTcxOCA0LjAzMzgzTDkuNDYzMTYgNC4zOTk4OEw5LjY1NzE4IDQuNzk1OTNaIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-caret-down-empty-thin:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iOS45LDEzLjYgMy42LDcuNCA0LjQsNi42IDkuOSwxMi4yIDE1LjQsNi43IDE2LjEsNy40ICIvPgoJPC9nPgo8L3N2Zz4K);--jp-icon-caret-down-empty:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNS45TDksOS43bDMuOC0zLjhsMS4yLDEuMmwtNC45LDVsLTQuOS01TDUuMiw1Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-caret-down:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik01LjIsNy41TDksMTEuMmwzLjgtMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-caret-left:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik0xMC44LDEyLjhMNy4xLDlsMy44LTMuOGwwLDcuNkgxMC44eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-caret-right:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiIHNoYXBlLXJlbmRlcmluZz0iZ2VvbWV0cmljUHJlY2lzaW9uIj4KICAgIDxwYXRoIGQ9Ik03LjIsNS4yTDEwLjksOWwtMy44LDMuOFY1LjJINy4yeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-caret-up-empty-thin:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwb2x5Z29uIGNsYXNzPSJzdDEiIHBvaW50cz0iMTUuNCwxMy4zIDkuOSw3LjcgNC40LDEzLjIgMy42LDEyLjUgOS45LDYuMyAxNi4xLDEyLjYgIi8+Cgk8L2c+Cjwvc3ZnPgo=);--jp-icon-caret-up:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSIgc2hhcGUtcmVuZGVyaW5nPSJnZW9tZXRyaWNQcmVjaXNpb24iPgoJCTxwYXRoIGQ9Ik01LjIsMTAuNUw5LDYuOGwzLjgsMy44SDUuMnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-case-sensitive:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWFjY2VudDIiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTcuNiw4aDAuOWwzLjUsOGgtMS4xTDEwLDE0SDZsLTAuOSwySDRMNy42LDh6IE04LDkuMUw2LjQsMTNoMy4yTDgsOS4xeiIvPgogICAgPHBhdGggZD0iTTE2LjYsOS44Yy0wLjIsMC4xLTAuNCwwLjEtMC43LDAuMWMtMC4yLDAtMC40LTAuMS0wLjYtMC4yYy0wLjEtMC4xLTAuMi0wLjQtMC4yLTAuNyBjLTAuMywwLjMtMC42LDAuNS0wLjksMC43Yy0wLjMsMC4xLTAuNywwLjItMS4xLDAuMmMtMC4zLDAtMC41LDAtMC43LTAuMWMtMC4yLTAuMS0wLjQtMC4yLTAuNi0wLjNjLTAuMi0wLjEtMC4zLTAuMy0wLjQtMC41IGMtMC4xLTAuMi0wLjEtMC40LTAuMS0wLjdjMC0wLjMsMC4xLTAuNiwwLjItMC44YzAuMS0wLjIsMC4zLTAuNCwwLjQtMC41QzEyLDcsMTIuMiw2LjksMTIuNSw2LjhjMC4yLTAuMSwwLjUtMC4xLDAuNy0wLjIgYzAuMy0wLjEsMC41LTAuMSwwLjctMC4xYzAuMiwwLDAuNC0wLjEsMC42LTAuMWMwLjIsMCwwLjMtMC4xLDAuNC0wLjJjMC4xLTAuMSwwLjItMC4yLDAuMi0wLjRjMC0xLTEuMS0xLTEuMy0xIGMtMC40LDAtMS40LDAtMS40LDEuMmgtMC45YzAtMC40LDAuMS0wLjcsMC4yLTFjMC4xLTAuMiwwLjMtMC40LDAuNS0wLjZjMC4yLTAuMiwwLjUtMC4zLDAuOC0wLjNDMTMuMyw0LDEzLjYsNCwxMy45LDQgYzAuMywwLDAuNSwwLDAuOCwwLjFjMC4zLDAsMC41LDAuMSwwLjcsMC4yYzAuMiwwLjEsMC40LDAuMywwLjUsMC41QzE2LDUsMTYsNS4yLDE2LDUuNnYyLjljMCwwLjIsMCwwLjQsMCwwLjUgYzAsMC4xLDAuMSwwLjIsMC4zLDAuMmMwLjEsMCwwLjIsMCwwLjMsMFY5Ljh6IE0xNS4yLDYuOWMtMS4yLDAuNi0zLjEsMC4yLTMuMSwxLjRjMCwxLjQsMy4xLDEsMy4xLTAuNVY2Ljl6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-check:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik05IDE2LjE3TDQuODMgMTJsLTEuNDIgMS40MUw5IDE5IDIxIDdsLTEuNDEtMS40MXoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-circle-empty:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDJDNi40NyAyIDIgNi40NyAyIDEyczQuNDcgMTAgMTAgMTAgMTAtNC40NyAxMC0xMFMxNy41MyAyIDEyIDJ6bTAgMThjLTQuNDEgMC04LTMuNTktOC04czMuNTktOCA4LTggOCAzLjU5IDggOC0zLjU5IDgtOCA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-circle:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iOSIgY3k9IjkiIHI9IjgiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-clear:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8bWFzayBpZD0iZG9udXRIb2xlIj4KICAgIDxyZWN0IHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgZmlsbD0id2hpdGUiIC8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSI4IiBmaWxsPSJibGFjayIvPgogIDwvbWFzaz4KCiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxyZWN0IGhlaWdodD0iMTgiIHdpZHRoPSIyIiB4PSIxMSIgeT0iMyIgdHJhbnNmb3JtPSJyb3RhdGUoMzE1LCAxMiwgMTIpIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIgbWFzaz0idXJsKCNkb251dEhvbGUpIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-close:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1ub25lIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIGpwLWljb24zLWhvdmVyIiBmaWxsPSJub25lIj4KICAgIDxjaXJjbGUgY3g9IjEyIiBjeT0iMTIiIHI9IjExIi8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIGpwLWljb24tYWNjZW50Mi1ob3ZlciIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMTkgNi40MUwxNy41OSA1IDEyIDEwLjU5IDYuNDEgNSA1IDYuNDEgMTAuNTkgMTIgNSAxNy41OSA2LjQxIDE5IDEyIDEzLjQxIDE3LjU5IDE5IDE5IDE3LjU5IDEzLjQxIDEyeiIvPgogIDwvZz4KCiAgPGcgY2xhc3M9ImpwLWljb24tbm9uZSBqcC1pY29uLWJ1c3kiIGZpbGw9Im5vbmUiPgogICAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iNyIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-code-check:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBzaGFwZS1yZW5kZXJpbmc9Imdlb21ldHJpY1ByZWNpc2lvbiI+CiAgICA8cGF0aCBkPSJNNi41OSwzLjQxTDIsOEw2LjU5LDEyLjZMOCwxMS4xOEw0LjgyLDhMOCw0LjgyTDYuNTksMy40MU0xMi40MSwzLjQxTDExLDQuODJMMTQuMTgsOEwxMSwxMS4xOEwxMi40MSwxMi42TDE3LDhMMTIuNDEsMy40MU0yMS41OSwxMS41OUwxMy41LDE5LjY4TDkuODMsMTZMOC40MiwxNy40MUwxMy41LDIyLjVMMjMsMTNMMjEuNTksMTEuNTlaIiAvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-code:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTExLjQgMTguNkw2LjggMTRMMTEuNCA5LjRMMTAgOEw0IDE0TDEwIDIwTDExLjQgMTguNlpNMTYuNiAxOC42TDIxLjIgMTRMMTYuNiA5LjRMMTggOEwyNCAxNEwxOCAyMEwxNi42IDE4LjZWMTguNloiLz4KCTwvZz4KPC9zdmc+Cg==);--jp-icon-collapse-all:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNNiAxM3YyaDh2LTJ6IiAvPgogICAgPC9nPgo8L3N2Zz4K);--jp-icon-console:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwMCAyMDAiPgogIDxnIGNsYXNzPSJqcC1jb25zb2xlLWljb24tYmFja2dyb3VuZC1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMjg4RDEiPgogICAgPHBhdGggZD0iTTIwIDE5LjhoMTYwdjE1OS45SDIweiIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtY29uc29sZS1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIj4KICAgIDxwYXRoIGQ9Ik0xMDUgMTI3LjNoNDB2MTIuOGgtNDB6TTUxLjEgNzdMNzQgOTkuOWwtMjMuMyAyMy4zIDEwLjUgMTAuNSAyMy4zLTIzLjNMOTUgOTkuOSA4NC41IDg5LjQgNjEuNiA2Ni41eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-copy:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTExLjksMUgzLjJDMi40LDEsMS43LDEuNywxLjcsMi41djEwLjJoMS41VjIuNWg4LjdWMXogTTE0LjEsMy45aC04Yy0wLjgsMC0xLjUsMC43LTEuNSwxLjV2MTAuMmMwLDAuOCwwLjcsMS41LDEuNSwxLjVoOCBjMC44LDAsMS41LTAuNywxLjUtMS41VjUuNEMxNS41LDQuNiwxNC45LDMuOSwxNC4xLDMuOXogTTE0LjEsMTUuNWgtOFY1LjRoOFYxNS41eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-copyright:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwIDI0IDI0IiBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCI+CiAgPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0xMS44OCw5LjE0YzEuMjgsMC4wNiwxLjYxLDEuMTUsMS42MywxLjY2aDEuNzljLTAuMDgtMS45OC0xLjQ5LTMuMTktMy40NS0zLjE5QzkuNjQsNy42MSw4LDksOCwxMi4xNCBjMCwxLjk0LDAuOTMsNC4yNCwzLjg0LDQuMjRjMi4yMiwwLDMuNDEtMS42NSwzLjQ0LTIuOTVoLTEuNzljLTAuMDMsMC41OS0wLjQ1LDEuMzgtMS42MywxLjQ0QzEwLjU1LDE0LjgzLDEwLDEzLjgxLDEwLDEyLjE0IEMxMCw5LjI1LDExLjI4LDkuMTYsMTEuODgsOS4xNHogTTEyLDJDNi40OCwyLDIsNi40OCwyLDEyczQuNDgsMTAsMTAsMTBzMTAtNC40OCwxMC0xMFMxNy41MiwyLDEyLDJ6IE0xMiwyMGMtNC40MSwwLTgtMy41OS04LTggczMuNTktOCw4LThzOCwzLjU5LDgsOFMxNi40MSwyMCwxMiwyMHoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-cut:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkuNjQgNy42NGMuMjMtLjUuMzYtMS4wNS4zNi0xLjY0IDAtMi4yMS0xLjc5LTQtNC00UzIgMy43OSAyIDZzMS43OSA0IDQgNGMuNTkgMCAxLjE0LS4xMyAxLjY0LS4zNkwxMCAxMmwtMi4zNiAyLjM2QzcuMTQgMTQuMTMgNi41OSAxNCA2IDE0Yy0yLjIxIDAtNCAxLjc5LTQgNHMxLjc5IDQgNCA0IDQtMS43OSA0LTRjMC0uNTktLjEzLTEuMTQtLjM2LTEuNjRMMTIgMTRsNyA3aDN2LTFMOS42NCA3LjY0ek02IDhjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTAgMTJjLTEuMSAwLTItLjg5LTItMnMuOS0yIDItMiAyIC44OSAyIDItLjkgMi0yIDJ6bTYtNy41Yy0uMjggMC0uNS0uMjItLjUtLjVzLjIyLS41LjUtLjUuNS4yMi41LjUtLjIyLjUtLjUuNXpNMTkgM2wtNiA2IDIgMiA3LTdWM3oiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-delete:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2cHgiIGhlaWdodD0iMTZweCI+CiAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIiAvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjI2MjYyIiBkPSJNNiAxOWMwIDEuMS45IDIgMiAyaDhjMS4xIDAgMi0uOSAyLTJWN0g2djEyek0xOSA0aC0zLjVsLTEtMWgtNWwtMSAxSDV2MmgxNFY0eiIgLz4KPC9zdmc+Cg==);--jp-icon-download:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE5IDloLTRWM0g5djZINWw3IDcgNy03ek01IDE4djJoMTR2LTJINXoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-duplicate:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGNsaXAtcnVsZT0iZXZlbm9kZCIgZD0iTTIuNzk5OTggMC44NzVIOC44OTU4MkM5LjIwMDYxIDAuODc1IDkuNDQ5OTggMS4xMzkxNCA5LjQ0OTk4IDEuNDYxOThDOS40NDk5OCAxLjc4NDgyIDkuMjAwNjEgMi4wNDg5NiA4Ljg5NTgyIDIuMDQ4OTZIMy4zNTQxNUMzLjA0OTM2IDIuMDQ4OTYgMi43OTk5OCAyLjMxMzEgMi43OTk5OCAyLjYzNTk0VjkuNjc5NjlDMi43OTk5OCAxMC4wMDI1IDIuNTUwNjEgMTAuMjY2NyAyLjI0NTgyIDEwLjI2NjdDMS45NDEwMyAxMC4yNjY3IDEuNjkxNjUgMTAuMDAyNSAxLjY5MTY1IDkuNjc5NjlWMi4wNDg5NkMxLjY5MTY1IDEuNDAzMjggMi4xOTA0IDAuODc1IDIuNzk5OTggMC44NzVaTTUuMzY2NjUgMTEuOVY0LjU1SDExLjA4MzNWMTEuOUg1LjM2NjY1Wk00LjE0MTY1IDQuMTQxNjdDNC4xNDE2NSAzLjY5MDYzIDQuNTA3MjggMy4zMjUgNC45NTgzMiAzLjMyNUgxMS40OTE3QzExLjk0MjcgMy4zMjUgMTIuMzA4MyAzLjY5MDYzIDEyLjMwODMgNC4xNDE2N1YxMi4zMDgzQzEyLjMwODMgMTIuNzU5NCAxMS45NDI3IDEzLjEyNSAxMS40OTE3IDEzLjEyNUg0Ljk1ODMyQzQuNTA3MjggMTMuMTI1IDQuMTQxNjUgMTIuNzU5NCA0LjE0MTY1IDEyLjMwODNWNC4xNDE2N1oiIGZpbGw9IiM2MTYxNjEiLz4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNOS40MzU3NCA4LjI2NTA3SDguMzY0MzFWOS4zMzY1QzguMzY0MzEgOS40NTQzNSA4LjI2Nzg4IDkuNTUwNzggOC4xNTAwMiA5LjU1MDc4QzguMDMyMTcgOS41NTA3OCA3LjkzNTc0IDkuNDU0MzUgNy45MzU3NCA5LjMzNjVWOC4yNjUwN0g2Ljg2NDMxQzYuNzQ2NDUgOC4yNjUwNyA2LjY1MDAyIDguMTY4NjQgNi42NTAwMiA4LjA1MDc4QzYuNjUwMDIgNy45MzI5MiA2Ljc0NjQ1IDcuODM2NSA2Ljg2NDMxIDcuODM2NUg3LjkzNTc0VjYuNzY1MDdDNy45MzU3NCA2LjY0NzIxIDguMDMyMTcgNi41NTA3OCA4LjE1MDAyIDYuNTUwNzhDOC4yNjc4OCA2LjU1MDc4IDguMzY0MzEgNi42NDcyMSA4LjM2NDMxIDYuNzY1MDdWNy44MzY1SDkuNDM1NzRDOS41NTM2IDcuODM2NSA5LjY1MDAyIDcuOTMyOTIgOS42NTAwMiA4LjA1MDc4QzkuNjUwMDIgOC4xNjg2NCA5LjU1MzYgOC4yNjUwNyA5LjQzNTc0IDguMjY1MDdaIiBmaWxsPSIjNjE2MTYxIiBzdHJva2U9IiM2MTYxNjEiIHN0cm9rZS13aWR0aD0iMC41Ii8+Cjwvc3ZnPgo=);--jp-icon-edit:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMgMTcuMjVWMjFoMy43NUwxNy44MSA5Ljk0bC0zLjc1LTMuNzVMMyAxNy4yNXpNMjAuNzEgNy4wNGMuMzktLjM5LjM5LTEuMDIgMC0xLjQxbC0yLjM0LTIuMzRjLS4zOS0uMzktMS4wMi0uMzktMS40MSAwbC0xLjgzIDEuODMgMy43NSAzLjc1IDEuODMtMS44M3oiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-ellipses:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPGNpcmNsZSBjeD0iNSIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIyIi8+CiAgICA8Y2lyY2xlIGN4PSIxOSIgY3k9IjEyIiByPSIyIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-error:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KPGcgY2xhc3M9ImpwLWljb24zIiBmaWxsPSIjNjE2MTYxIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjE5IiByPSIyIi8+PHBhdGggZD0iTTEwIDNoNHYxMmgtNHoiLz48L2c+CjxwYXRoIGZpbGw9Im5vbmUiIGQ9Ik0wIDBoMjR2MjRIMHoiLz4KPC9zdmc+Cg==);--jp-icon-expand-all:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTggMmMxIDAgMTEgMCAxMiAwczIgMSAyIDJjMCAxIDAgMTEgMCAxMnMwIDItMiAyQzIwIDE0IDIwIDQgMjAgNFMxMCA0IDYgNGMwLTIgMS0yIDItMnoiIC8+CiAgICAgICAgPHBhdGgKICAgICAgICAgICAgZD0iTTE4IDhjMC0xLTEtMi0yLTJTNSA2IDQgNnMtMiAxLTIgMmMwIDEgMCAxMSAwIDEyczEgMiAyIDJjMSAwIDExIDAgMTIgMHMyLTEgMi0yYzAtMSAwLTExIDAtMTJ6bS0yIDB2MTJINFY4eiIgLz4KICAgICAgICA8cGF0aCBkPSJNMTEgMTBIOXYzSDZ2MmgzdjNoMnYtM2gzdi0yaC0zeiIgLz4KICAgIDwvZz4KPC9zdmc+Cg==);--jp-icon-extension:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwLjUgMTFIMTlWN2MwLTEuMS0uOS0yLTItMmgtNFYzLjVDMTMgMi4xMiAxMS44OCAxIDEwLjUgMVM4IDIuMTIgOCAzLjVWNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAydjMuOEgzLjVjMS40OSAwIDIuNyAxLjIxIDIuNyAyLjdzLTEuMjEgMi43LTIuNyAyLjdIMlYyMGMwIDEuMS45IDIgMiAyaDMuOHYtMS41YzAtMS40OSAxLjIxLTIuNyAyLjctMi43IDEuNDkgMCAyLjcgMS4yMSAyLjcgMi43VjIySDE3YzEuMSAwIDItLjkgMi0ydi00aDEuNWMxLjM4IDAgMi41LTEuMTIgMi41LTIuNVMyMS44OCAxMSAyMC41IDExeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-fast-forward:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTQgMThsOC41LTZMNCA2djEyem05LTEydjEybDguNS02TDEzIDZ6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);--jp-icon-file-upload:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTkgMTZoNnYtNmg0bC03LTctNyA3aDR6bS00IDJoMTR2Mkg1eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-file:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuMyA4LjJsLTUuNS01LjVjLS4zLS4zLS43LS41LTEuMi0uNUgzLjljLS44LjEtMS42LjktMS42IDEuOHYxNC4xYzAgLjkuNyAxLjYgMS42IDEuNmgxNC4yYy45IDAgMS42LS43IDEuNi0xLjZWOS40Yy4xLS41LS4xLS45LS40LTEuMnptLTUuOC0zLjNsMy40IDMuNmgtMy40VjQuOXptMy45IDEyLjdINC43Yy0uMSAwLS4yIDAtLjItLjJWNC43YzAtLjIuMS0uMy4yLS4zaDcuMnY0LjRzMCAuOC4zIDEuMWMuMy4zIDEuMS4zIDEuMS4zaDQuM3Y3LjJzLS4xLjItLjIuMnoiLz4KPC9zdmc+Cg==);--jp-icon-filter-dot:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgogIDxnIGNsYXNzPSJqcC1pY29uLWRvdCIgZmlsbD0iI0ZGRiI+CiAgICA8Y2lyY2xlIGN4PSIxOCIgY3k9IjE3IiByPSIzIj48L2NpcmNsZT4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-filter-list:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEwIDE4aDR2LTJoLTR2MnpNMyA2djJoMThWNkgzem0zIDdoMTJ2LTJINnYyeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-filter:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiNGRkYiPgogICAgPHBhdGggZD0iTTE0LDEyVjE5Ljg4QzE0LjA0LDIwLjE4IDEzLjk0LDIwLjUgMTMuNzEsMjAuNzFDMTMuMzIsMjEuMSAxMi42OSwyMS4xIDEyLjMsMjAuNzFMMTAuMjksMTguN0MxMC4wNiwxOC40NyA5Ljk2LDE4LjE2IDEwLDE3Ljg3VjEySDkuOTdMNC4yMSw0LjYyQzMuODcsNC4xOSAzLjk1LDMuNTYgNC4zOCwzLjIyQzQuNTcsMy4wOCA0Ljc4LDMgNSwzVjNIMTlWM0MxOS4yMiwzIDE5LjQzLDMuMDggMTkuNjIsMy4yMkMyMC4wNSwzLjU2IDIwLjEzLDQuMTkgMTkuNzksNC42MkwxNC4wMywxMkgxNFoiIC8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-folder-favorite:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgwVjB6IiBmaWxsPSJub25lIi8+PHBhdGggY2xhc3M9ImpwLWljb24zIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzYxNjE2MSIgZD0iTTIwIDZoLThsLTItMkg0Yy0xLjEgMC0yIC45LTIgMnYxMmMwIDEuMS45IDIgMiAyaDE2YzEuMSAwIDItLjkgMi0yVjhjMC0xLjEtLjktMi0yLTJ6bS0yLjA2IDExTDE1IDE1LjI4IDEyLjA2IDE3bC43OC0zLjMzLTIuNTktMi4yNCAzLjQxLS4yOUwxNSA4bDEuMzQgMy4xNCAzLjQxLjI5LTIuNTkgMi4yNC43OCAzLjMzeiIvPgo8L3N2Zz4K);--jp-icon-folder:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY4YzAtMS4xLS45LTItMi0yaC04bC0yLTJ6Ii8+Cjwvc3ZnPgo=);--jp-icon-home:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjRweCIgdmlld0JveD0iMCAwIDI0IDI0IiB3aWR0aD0iMjRweCIgZmlsbD0iIzAwMDAwMCI+CiAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPjxwYXRoIGNsYXNzPSJqcC1pY29uMyBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xMCAyMHYtNmg0djZoNXYtOGgzTDEyIDMgMiAxMmgzdjh6Ii8+Cjwvc3ZnPgo=);--jp-icon-html5:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uMCBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiMwMDAiIGQ9Ik0xMDguNCAwaDIzdjIyLjhoMjEuMlYwaDIzdjY5aC0yM1Y0NmgtMjF2MjNoLTIzLjJNMjA2IDIzaC0yMC4zVjBoNjMuN3YyM0gyMjl2NDZoLTIzbTUzLjUtNjloMjQuMWwxNC44IDI0LjNMMzEzLjIgMGgyNC4xdjY5aC0yM1YzNC44bC0xNi4xIDI0LjgtMTYuMS0yNC44VjY5aC0yMi42bTg5LjItNjloMjN2NDYuMmgzMi42VjY5aC01NS42Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI2U0NGQyNiIgZD0iTTEwNy42IDQ3MWwtMzMtMzcwLjRoMzYyLjhsLTMzIDM3MC4yTDI1NS43IDUxMiIvPgogIDxwYXRoIGNsYXNzPSJqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNmMTY1MjkiIGQ9Ik0yNTYgNDgwLjVWMTMxaDE0OC4zTDM3NiA0NDciLz4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNlYmViZWIiIGQ9Ik0xNDIgMTc2LjNoMTE0djQ1LjRoLTY0LjJsNC4yIDQ2LjVoNjB2NDUuM0gxNTQuNG0yIDIyLjhIMjAybDMuMiAzNi4zIDUwLjggMTMuNnY0Ny40bC05My4yLTI2Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZS1pbnZlcnNlIiBmaWxsPSIjZmZmIiBkPSJNMzY5LjYgMTc2LjNIMjU1Ljh2NDUuNGgxMDkuNm0tNC4xIDQ2LjVIMjU1Ljh2NDUuNGg1NmwtNS4zIDU5LTUwLjcgMTMuNnY0Ny4ybDkzLTI1LjgiLz4KPC9zdmc+Cg==);--jp-icon-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1icmFuZDQganAtaWNvbi1zZWxlY3RhYmxlLWludmVyc2UiIGZpbGw9IiNGRkYiIGQ9Ik0yLjIgMi4yaDE3LjV2MTcuNUgyLjJ6Ii8+CiAgPHBhdGggY2xhc3M9ImpwLWljb24tYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzNGNTFCNSIgZD0iTTIuMiAyLjJ2MTcuNWgxNy41bC4xLTE3LjVIMi4yem0xMi4xIDIuMmMxLjIgMCAyLjIgMSAyLjIgMi4ycy0xIDIuMi0yLjIgMi4yLTIuMi0xLTIuMi0yLjIgMS0yLjIgMi4yLTIuMnpNNC40IDE3LjZsMy4zLTguOCAzLjMgNi42IDIuMi0zLjIgNC40IDUuNEg0LjR6Ii8+Cjwvc3ZnPgo=);--jp-icon-info:url(data:image/svg+xml;base64,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);--jp-icon-inspector:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaW5zcGVjdG9yLWljb24tY29sb3IganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNEg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMThjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY2YzAtMS4xLS45LTItMi0yem0tNSAxNEg0di00aDExdjR6bTAtNUg0VjloMTF2NHptNSA1aC00VjloNHY5eiIvPgo8L3N2Zz4K);--jp-icon-json:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtanNvbi1pY29uLWNvbG9yIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0Y5QTgyNSI+CiAgICA8cGF0aCBkPSJNMjAuMiAxMS44Yy0xLjYgMC0xLjcuNS0xLjcgMSAwIC40LjEuOS4xIDEuMy4xLjUuMS45LjEgMS4zIDAgMS43LTEuNCAyLjMtMy41IDIuM2gtLjl2LTEuOWguNWMxLjEgMCAxLjQgMCAxLjQtLjggMC0uMyAwLS42LS4xLTEgMC0uNC0uMS0uOC0uMS0xLjIgMC0xLjMgMC0xLjggMS4zLTItMS4zLS4yLTEuMy0uNy0xLjMtMiAwLS40LjEtLjguMS0xLjIuMS0uNC4xLS43LjEtMSAwLS44LS40LS43LTEuNC0uOGgtLjVWNC4xaC45YzIuMiAwIDMuNS43IDMuNSAyLjMgMCAuNC0uMS45LS4xIDEuMy0uMS41LS4xLjktLjEgMS4zIDAgLjUuMiAxIDEuNyAxdjEuOHpNMS44IDEwLjFjMS42IDAgMS43LS41IDEuNy0xIDAtLjQtLjEtLjktLjEtMS4zLS4xLS41LS4xLS45LS4xLTEuMyAwLTEuNiAxLjQtMi4zIDMuNS0yLjNoLjl2MS45aC0uNWMtMSAwLTEuNCAwLTEuNC44IDAgLjMgMCAuNi4xIDEgMCAuMi4xLjYuMSAxIDAgMS4zIDAgMS44LTEuMyAyQzYgMTEuMiA2IDExLjcgNiAxM2MwIC40LS4xLjgtLjEgMS4yLS4xLjMtLjEuNy0uMSAxIDAgLjguMy44IDEuNC44aC41djEuOWgtLjljLTIuMSAwLTMuNS0uNi0zLjUtMi4zIDAtLjQuMS0uOS4xLTEuMy4xLS41LjEtLjkuMS0xLjMgMC0uNS0uMi0xLTEuNy0xdi0xLjl6Ii8+CiAgICA8Y2lyY2xlIGN4PSIxMSIgY3k9IjEzLjgiIHI9IjIuMSIvPgogICAgPGNpcmNsZSBjeD0iMTEiIGN5PSI4LjIiIHI9IjIuMSIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-julia:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDMyNSAzMDAiPgogIDxnIGNsYXNzPSJqcC1icmFuZDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjY2IzYzMzIj4KICAgIDxwYXRoIGQ9Ik0gMTUwLjg5ODQzOCAyMjUgQyAxNTAuODk4NDM4IDI2Ni40MjE4NzUgMTE3LjMyMDMxMiAzMDAgNzUuODk4NDM4IDMwMCBDIDM0LjQ3NjU2MiAzMDAgMC44OTg0MzggMjY2LjQyMTg3NSAwLjg5ODQzOCAyMjUgQyAwLjg5ODQzOCAxODMuNTc4MTI1IDM0LjQ3NjU2MiAxNTAgNzUuODk4NDM4IDE1MCBDIDExNy4zMjAzMTIgMTUwIDE1MC44OTg0MzggMTgzLjU3ODEyNSAxNTAuODk4NDM4IDIyNSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzM4OTgyNiI+CiAgICA8cGF0aCBkPSJNIDIzNy41IDc1IEMgMjM3LjUgMTE2LjQyMTg3NSAyMDMuOTIxODc1IDE1MCAxNjIuNSAxNTAgQyAxMjEuMDc4MTI1IDE1MCA4Ny41IDExNi40MjE4NzUgODcuNSA3NSBDIDg3LjUgMzMuNTc4MTI1IDEyMS4wNzgxMjUgMCAxNjIuNSAwIEMgMjAzLjkyMTg3NSAwIDIzNy41IDMzLjU3ODEyNSAyMzcuNSA3NSIvPgogIDwvZz4KICA8ZyBjbGFzcz0ianAtYnJhbmQwIGpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iIzk1NThiMiI+CiAgICA8cGF0aCBkPSJNIDMyNC4xMDE1NjIgMjI1IEMgMzI0LjEwMTU2MiAyNjYuNDIxODc1IDI5MC41MjM0MzggMzAwIDI0OS4xMDE1NjIgMzAwIEMgMjA3LjY3OTY4OCAzMDAgMTc0LjEwMTU2MiAyNjYuNDIxODc1IDE3NC4xMDE1NjIgMjI1IEMgMTc0LjEwMTU2MiAxODMuNTc4MTI1IDIwNy42Nzk2ODggMTUwIDI0OS4xMDE1NjIgMTUwIEMgMjkwLjUyMzQzOCAxNTAgMzI0LjEwMTU2MiAxODMuNTc4MTI1IDMyNC4xMDE1NjIgMjI1Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-jupyter-favicon:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTUyIiBoZWlnaHQ9IjE2NSIgdmlld0JveD0iMCAwIDE1MiAxNjUiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgPGcgY2xhc3M9ImpwLWp1cHl0ZXItaWNvbi1jb2xvciIgZmlsbD0iI0YzNzcyNiI+CiAgICA8cGF0aCB0cmFuc2Zvcm09InRyYW5zbGF0ZSgwLjA3ODk0NywgMTEwLjU4MjkyNykiIGQ9Ik03NS45NDIyODQyLDI5LjU4MDQ1NjEgQzQzLjMwMjM5NDcsMjkuNTgwNDU2MSAxNC43OTY3ODMyLDE3LjY1MzQ2MzQgMCwwIEM1LjUxMDgzMjExLDE1Ljg0MDY4MjkgMTUuNzgxNTM4OSwyOS41NjY3NzMyIDI5LjM5MDQ5NDcsMzkuMjc4NDE3MSBDNDIuOTk5Nyw0OC45ODk4NTM3IDU5LjI3MzcsNTQuMjA2NzgwNSA3NS45NjA1Nzg5LDU0LjIwNjc4MDUgQzkyLjY0NzQ1NzksNTQuMjA2NzgwNSAxMDguOTIxNDU4LDQ4Ljk4OTg1MzcgMTIyLjUzMDY2MywzOS4yNzg0MTcxIEMxMzYuMTM5NDUzLDI5LjU2Njc3MzIgMTQ2LjQxMDI4NCwxNS44NDA2ODI5IDE1MS45MjExNTgsMCBDMTM3LjA4Nzg2OCwxNy42NTM0NjM0IDEwOC41ODI1ODksMjkuNTgwNDU2MSA3NS45NDIyODQyLDI5LjU4MDQ1NjEgTDc1Ljk0MjI4NDIsMjkuNTgwNDU2MSBaIiAvPgogICAgPHBhdGggdHJhbnNmb3JtPSJ0cmFuc2xhdGUoMC4wMzczNjgsIDAuNzA0ODc4KSIgZD0iTTc1Ljk3ODQ1NzksMjQuNjI2NDA3MyBDMTA4LjYxODc2MywyNC42MjY0MDczIDEzNy4xMjQ0NTgsMzYuNTUzNDQxNSAxNTEuOTIxMTU4LDU0LjIwNjc4MDUgQzE0Ni40MTAyODQsMzguMzY2MjIyIDEzNi4xMzk0NTMsMjQuNjQwMTMxNyAxMjIuNTMwNjYzLDE0LjkyODQ4NzggQzEwOC45MjE0NTgsNS4yMTY4NDM5IDkyLjY0NzQ1NzksMCA3NS45NjA1Nzg5LDAgQzU5LjI3MzcsMCA0Mi45OTk3LDUuMjE2ODQzOSAyOS4zOTA0OTQ3LDE0LjkyODQ4NzggQzE1Ljc4MTUzODksMjQuNjQwMTMxNyA1LjUxMDgzMjExLDM4LjM2NjIyMiAwLDU0LjIwNjc4MDUgQzE0LjgzMzA4MTYsMzYuNTg5OTI5MyA0My4zMzg1Njg0LDI0LjYyNjQwNzMgNzUuOTc4NDU3OSwyNC42MjY0MDczIEw3NS45Nzg0NTc5LDI0LjYyNjQwNzMgWiIgLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-jupyter:url(data:image/svg+xml;base64,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);--jp-icon-jupyterlab-wordmark:url(data:image/svg+xml;base64,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);--jp-icon-kernel:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgZmlsbD0iIzYxNjE2MSIgZD0iTTE1IDlIOXY2aDZWOXptLTIgNGgtMnYtMmgydjJ6bTgtMlY5aC0yVjdjMC0xLjEtLjktMi0yLTJoLTJWM2gtMnYyaC0yVjNIOXYySDdjLTEuMSAwLTIgLjktMiAydjJIM3YyaDJ2MkgzdjJoMnYyYzAgMS4xLjkgMiAyIDJoMnYyaDJ2LTJoMnYyaDJ2LTJoMmMxLjEgMCAyLS45IDItMnYtMmgydi0yaC0ydi0yaDJ6bS00IDZIN1Y3aDEwdjEweiIvPgo8L3N2Zz4K);--jp-icon-keyboard:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMjAgNUg0Yy0xLjEgMC0xLjk5LjktMS45OSAyTDIgMTdjMCAxLjEuOSAyIDIgMmgxNmMxLjEgMCAyLS45IDItMlY3YzAtMS4xLS45LTItMi0yem0tOSAzaDJ2MmgtMlY4em0wIDNoMnYyaC0ydi0yek04IDhoMnYySDhWOHptMCAzaDJ2Mkg4di0yem0tMSAySDV2LTJoMnYyem0wLTNINVY4aDJ2MnptOSA3SDh2LTJoOHYyem0wLTRoLTJ2LTJoMnYyem0wLTNoLTJWOGgydjJ6bTMgM2gtMnYtMmgydjJ6bTAtM2gtMlY4aDJ2MnoiLz4KPC9zdmc+Cg==);--jp-icon-launch:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzIgMzIiIHdpZHRoPSIzMiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik0yNiwyOEg2YTIuMDAyNywyLjAwMjcsMCwwLDEtMi0yVjZBMi4wMDI3LDIuMDAyNywwLDAsMSw2LDRIMTZWNkg2VjI2SDI2VjE2aDJWMjZBMi4wMDI3LDIuMDAyNywwLDAsMSwyNiwyOFoiLz4KICAgIDxwb2x5Z29uIHBvaW50cz0iMjAgMiAyMCA0IDI2LjU4NiA0IDE4IDEyLjU4NiAxOS40MTQgMTQgMjggNS40MTQgMjggMTIgMzAgMTIgMzAgMiAyMCAyIi8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-launcher:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkgMTlINVY1aDdWM0g1YTIgMiAwIDAwLTIgMnYxNGEyIDIgMCAwMDIgMmgxNGMxLjEgMCAyLS45IDItMnYtN2gtMnY3ek0xNCAzdjJoMy41OWwtOS44MyA5LjgzIDEuNDEgMS40MUwxOSA2LjQxVjEwaDJWM2gtN3oiLz4KPC9zdmc+Cg==);--jp-icon-line-form:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGZpbGw9IndoaXRlIiBkPSJNNS44OCA0LjEyTDEzLjc2IDEybC03Ljg4IDcuODhMOCAyMmwxMC0xMEw4IDJ6Ii8+Cjwvc3ZnPgo=);--jp-icon-link:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTMuOSAxMmMwLTEuNzEgMS4zOS0zLjEgMy4xLTMuMWg0VjdIN2MtMi43NiAwLTUgMi4yNC01IDVzMi4yNCA1IDUgNWg0di0xLjlIN2MtMS43MSAwLTMuMS0xLjM5LTMuMS0zLjF6TTggMTNoOHYtMkg4djJ6bTktNmgtNHYxLjloNGMxLjcxIDAgMy4xIDEuMzkgMy4xIDMuMXMtMS4zOSAzLjEtMy4xIDMuMWgtNFYxN2g0YzIuNzYgMCA1LTIuMjQgNS01cy0yLjI0LTUtNS01eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-list:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xOSA1djE0SDVWNWgxNG0xLjEtMkgzLjljLS41IDAtLjkuNC0uOS45djE2LjJjMCAuNC40LjkuOS45aDE2LjJjLjQgMCAuOS0uNS45LS45VjMuOWMwLS41LS41LS45LS45LS45ek0xMSA3aDZ2MmgtNlY3em0wIDRoNnYyaC02di0yem0wIDRoNnYyaC02ek03IDdoMnYySDd6bTAgNGgydjJIN3ptMCA0aDJ2Mkg3eiIvPgo8L3N2Zz4K);--jp-icon-markdown:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDAganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjN0IxRkEyIiBkPSJNNSAxNC45aDEybC02LjEgNnptOS40LTYuOGMwLTEuMy0uMS0yLjktLjEtNC41LS40IDEuNC0uOSAyLjktMS4zIDQuM2wtMS4zIDQuM2gtMkw4LjUgNy45Yy0uNC0xLjMtLjctMi45LTEtNC4zLS4xIDEuNi0uMSAzLjItLjIgNC42TDcgMTIuNEg0LjhsLjctMTFoMy4zTDEwIDVjLjQgMS4yLjcgMi43IDEgMy45LjMtMS4yLjctMi42IDEtMy45bDEuMi0zLjdoMy4zbC42IDExaC0yLjRsLS4zLTQuMnoiLz4KPC9zdmc+Cg==);--jp-icon-move-down:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMTIuNDcxIDcuNTI4OTlDMTIuNzYzMiA3LjIzNjg0IDEyLjc2MzIgNi43NjMxNiAxMi40NzEgNi40NzEwMVY2LjQ3MTAxQzEyLjE3OSA2LjE3OTA1IDExLjcwNTcgNi4xNzg4NCAxMS40MTM1IDYuNDcwNTRMNy43NSAxMC4xMjc1VjEuNzVDNy43NSAxLjMzNTc5IDcuNDE0MjEgMSA3IDFWMUM2LjU4NTc5IDEgNi4yNSAxLjMzNTc5IDYuMjUgMS43NVYxMC4xMjc1TDIuNTk3MjYgNi40NjgyMkMyLjMwMzM4IDYuMTczODEgMS44MjY0MSA2LjE3MzU5IDEuNTMyMjYgNi40Njc3NFY2LjQ2Nzc0QzEuMjM4MyA2Ljc2MTcgMS4yMzgzIDcuMjM4MyAxLjUzMjI2IDcuNTMyMjZMNi4yOTI4OSAxMi4yOTI5QzYuNjgzNDIgMTIuNjgzNCA3LjMxNjU4IDEyLjY4MzQgNy43MDcxMSAxMi4yOTI5TDEyLjQ3MSA3LjUyODk5WiIgZmlsbD0iIzYxNjE2MSIvPgo8L3N2Zz4K);--jp-icon-move-up:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTQiIGhlaWdodD0iMTQiIHZpZXdCb3g9IjAgMCAxNCAxNCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggY2xhc3M9ImpwLWljb24zIiBkPSJNMS41Mjg5OSA2LjQ3MTAxQzEuMjM2ODQgNi43NjMxNiAxLjIzNjg0IDcuMjM2ODQgMS41Mjg5OSA3LjUyODk5VjcuNTI4OTlDMS44MjA5NSA3LjgyMDk1IDIuMjk0MjYgNy44MjExNiAyLjU4NjQ5IDcuNTI5NDZMNi4yNSAzLjg3MjVWMTIuMjVDNi4yNSAxMi42NjQyIDYuNTg1NzkgMTMgNyAxM1YxM0M3LjQxNDIxIDEzIDcuNzUgMTIuNjY0MiA3Ljc1IDEyLjI1VjMuODcyNUwxMS40MDI3IDcuNTMxNzhDMTEuNjk2NiA3LjgyNjE5IDEyLjE3MzYgNy44MjY0MSAxMi40Njc3IDcuNTMyMjZWNy41MzIyNkMxMi43NjE3IDcuMjM4MyAxMi43NjE3IDYuNzYxNyAxMi40Njc3IDYuNDY3NzRMNy43MDcxMSAxLjcwNzExQzcuMzE2NTggMS4zMTY1OCA2LjY4MzQyIDEuMzE2NTggNi4yOTI4OSAxLjcwNzExTDEuNTI4OTkgNi40NzEwMVoiIGZpbGw9IiM2MTYxNjEiLz4KPC9zdmc+Cg==);--jp-icon-new-folder:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIwIDZoLThsLTItMkg0Yy0xLjExIDAtMS45OS44OS0xLjk5IDJMMiAxOGMwIDEuMTEuODkgMiAyIDJoMTZjMS4xMSAwIDItLjg5IDItMlY4YzAtMS4xMS0uODktMi0yLTJ6bS0xIDhoLTN2M2gtMnYtM2gtM3YtMmgzVjloMnYzaDN2MnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-not-trusted:url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI1IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDMgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMTkgMTcuMTg0NCAyLjk2OTY4IDE0LjMwMzIgMS44NjA5NCAxMS40NDA5WiIvPgogICAgPHBhdGggY2xhc3M9ImpwLWljb24yIiBzdHJva2U9IiMzMzMzMzMiIHN0cm9rZS13aWR0aD0iMiIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOS4zMTU5MiA5LjMyMDMxKSIgZD0iTTcuMzY4NDIgMEwwIDcuMzY0NzkiLz4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDkuMzE1OTIgMTYuNjgzNikgc2NhbGUoMSAtMSkiIGQ9Ik03LjM2ODQyIDBMMCA3LjM2NDc5Ii8+Cjwvc3ZnPgo=);--jp-icon-notebook:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtbm90ZWJvb2staWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiNFRjZDMDAiPgogICAgPHBhdGggZD0iTTE4LjcgMy4zdjE1LjRIMy4zVjMuM2gxNS40bTEuNS0xLjVIMS44djE4LjNoMTguM2wuMS0xOC4zeiIvPgogICAgPHBhdGggZD0iTTE2LjUgMTYuNWwtNS40LTQuMy01LjYgNC4zdi0xMWgxMXoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-numbering:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIiIGhlaWdodD0iMjIiIHZpZXdCb3g9IjAgMCAyOCAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTQgMTlINlYxOS41SDVWMjAuNUg2VjIxSDRWMjJIN1YxOEg0VjE5Wk01IDEwSDZWNkg0VjdINVYxMFpNNCAxM0g1LjhMNCAxNS4xVjE2SDdWMTVINS4yTDcgMTIuOVYxMkg0VjEzWk05IDdWOUgyM1Y3SDlaTTkgMjFIMjNWMTlIOVYyMVpNOSAxNUgyM1YxM0g5VjE1WiIvPgoJPC9nPgo8L3N2Zz4K);--jp-icon-offline-bolt:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyIDIuMDJjLTUuNTEgMC05Ljk4IDQuNDctOS45OCA5Ljk4czQuNDcgOS45OCA5Ljk4IDkuOTggOS45OC00LjQ3IDkuOTgtOS45OFMxNy41MSAyLjAyIDEyIDIuMDJ6TTExLjQ4IDIwdi02LjI2SDhMMTMgNHY2LjI2aDMuMzVMMTEuNDggMjB6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-palette:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE4IDEzVjIwSDRWNkg5LjAyQzkuMDcgNS4yOSA5LjI0IDQuNjIgOS41IDRINEMyLjkgNCAyIDQuOSAyIDZWMjBDMiAyMS4xIDIuOSAyMiA0IDIySDE4QzE5LjEgMjIgMjAgMjEuMSAyMCAyMFYxNUwxOCAxM1pNMTkuMyA4Ljg5QzE5Ljc0IDguMTkgMjAgNy4zOCAyMCA2LjVDMjAgNC4wMSAxNy45OSAyIDE1LjUgMkMxMy4wMSAyIDExIDQuMDEgMTEgNi41QzExIDguOTkgMTMuMDEgMTEgMTUuNDkgMTFDMTYuMzcgMTEgMTcuMTkgMTAuNzQgMTcuODggMTAuM0wyMSAxMy40MkwyMi40MiAxMkwxOS4zIDguODlaTTE1LjUgOUMxNC4xMiA5IDEzIDcuODggMTMgNi41QzEzIDUuMTIgMTQuMTIgNCAxNS41IDRDMTYuODggNCAxOCA1LjEyIDE4IDYuNUMxOCA3Ljg4IDE2Ljg4IDkgMTUuNSA5WiIvPgogICAgPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik00IDZIOS4wMTg5NEM5LjAwNjM5IDYuMTY1MDIgOSA2LjMzMTc2IDkgNi41QzkgOC44MTU3NyAxMC4yMTEgMTAuODQ4NyAxMi4wMzQzIDEySDlWMTRIMTZWMTIuOTgxMUMxNi41NzAzIDEyLjkzNzcgMTcuMTIgMTIuODIwNyAxNy42Mzk2IDEyLjYzOTZMMTggMTNWMjBINFY2Wk04IDhINlYxMEg4VjhaTTYgMTJIOFYxNEg2VjEyWk04IDE2SDZWMThIOFYxNlpNOSAxNkgxNlYxOEg5VjE2WiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-paste:url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE5IDJoLTQuMThDMTQuNC44NCAxMy4zIDAgMTIgMGMtMS4zIDAtMi40Ljg0LTIuODIgMkg1Yy0xLjEgMC0yIC45LTIgMnYxNmMwIDEuMS45IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjRjMC0xLjEtLjktMi0yLTJ6bS03IDBjLjU1IDAgMSAuNDUgMSAxcy0uNDUgMS0xIDEtMS0uNDUtMS0xIC40NS0xIDEtMXptNyAxOEg1VjRoMnYzaDEwVjRoMnYxNnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);--jp-icon-pdf:url(data:image/svg+xml;base64,PHN2ZwogICB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyMiAyMiIgd2lkdGg9IjE2Ij4KICAgIDxwYXRoIHRyYW5zZm9ybT0icm90YXRlKDQ1KSIgY2xhc3M9ImpwLWljb24tc2VsZWN0YWJsZSIgZmlsbD0iI0ZGMkEyQSIKICAgICAgIGQ9Im0gMjIuMzQ0MzY5LC0zLjAxNjM2NDIgaCA1LjYzODYwNCB2IDEuNTc5MjQzMyBoIC0zLjU0OTIyNyB2IDEuNTA4NjkyOTkgaCAzLjMzNzU3NiBWIDEuNjUwODE1NCBoIC0zLjMzNzU3NiB2IDMuNDM1MjYxMyBoIC0yLjA4OTM3NyB6IG0gLTcuMTM2NDQ0LDEuNTc5MjQzMyB2IDQuOTQzOTU0MyBoIDAuNzQ4OTIgcSAxLjI4MDc2MSwwIDEuOTUzNzAzLC0wLjYzNDk1MzUgMC42NzgzNjksLTAuNjM0OTUzNSAwLjY3ODM2OSwtMS44NDUxNjQxIDAsLTEuMjA0NzgzNTUgLTAuNjcyOTQyLC0xLjgzNDMxMDExIC0wLjY3Mjk0MiwtMC42Mjk1MjY1OSAtMS45NTkxMywtMC42Mjk1MjY1OSB6IG0gLTIuMDg5Mzc3LC0xLjU3OTI0MzMgaCAyLjIwMzM0MyBxIDEuODQ1MTY0LDAgMi43NDYwMzksMC4yNjU5MjA3IDAuOTA2MzAxLDAuMjYwNDkzNyAxLjU1MjEwOCwwLjg5MDAyMDMgMC41Njk4MywwLjU0ODEyMjMgMC44NDY2MDUsMS4yNjQ0ODAwNiAwLjI3Njc3NCwwLjcxNjM1NzgxIDAuMjc2Nzc0LDEuNjIyNjU4OTQgMCwwLjkxNzE1NTEgLTAuMjc2Nzc0LDEuNjM4OTM5OSAtMC4yNzY3NzUsMC43MTYzNTc4IC0wLjg0NjYwNSwxLjI2NDQ4IC0wLjY1MTIzNCwwLjYyOTUyNjYgLTEuNTYyOTYyLDAuODk1NDQ3MyAtMC45MTE3MjgsMC4yNjA0OTM3IC0yLjczNTE4NSwwLjI2MDQ5MzcgaCAtMi4yMDMzNDMgeiBtIC04LjE0NTg1NjUsMCBoIDMuNDY3ODIzIHEgMS41NDY2ODE2LDAgMi4zNzE1Nzg1LDAuNjg5MjIzIDAuODMwMzI0LDAuNjgzNzk2MSAwLjgzMDMyNCwxLjk1MzcwMzE0IDAsMS4yNzUzMzM5NyAtMC44MzAzMjQsMS45NjQ1NTcwNiBRIDkuOTg3MTk2MSwyLjI3NDkxNSA4LjQ0MDUxNDUsMi4yNzQ5MTUgSCA3LjA2MjA2ODQgViA1LjA4NjA3NjcgSCA0Ljk3MjY5MTUgWiBtIDIuMDg5Mzc2OSwxLjUxNDExOTkgdiAyLjI2MzAzOTQzIGggMS4xNTU5NDEgcSAwLjYwNzgxODgsMCAwLjkzODg2MjksLTAuMjkzMDU1NDcgMC4zMzEwNDQxLC0wLjI5ODQ4MjQxIDAuMzMxMDQ0MSwtMC44NDExNzc3MiAwLC0wLjU0MjY5NTMxIC0wLjMzMTA0NDEsLTAuODM1NzUwNzQgLTAuMzMxMDQ0MSwtMC4yOTMwNTU1IC0wLjkzODg2MjksLTAuMjkzMDU1NSB6IgovPgo8L3N2Zz4K);--jp-icon-python:url(data:image/svg+xml;base64,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);--jp-icon-r-kernel:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjE5NkYzIiBkPSJNNC40IDIuNWMxLjItLjEgMi45LS4zIDQuOS0uMyAyLjUgMCA0LjEuNCA1LjIgMS4zIDEgLjcgMS41IDEuOSAxLjUgMy41IDAgMi0xLjQgMy41LTIuOSA0LjEgMS4yLjQgMS43IDEuNiAyLjIgMyAuNiAxLjkgMSAzLjkgMS4zIDQuNmgtMy44Yy0uMy0uNC0uOC0xLjctMS4yLTMuN3MtMS4yLTIuNi0yLjYtMi42aC0uOXY2LjRINC40VjIuNXptMy43IDYuOWgxLjRjMS45IDAgMi45LS45IDIuOS0yLjNzLTEtMi4zLTIuOC0yLjNjLS43IDAtMS4zIDAtMS42LjJ2NC41aC4xdi0uMXoiLz4KPC9zdmc+Cg==);--jp-icon-react:url(data:image/svg+xml;base64,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);--jp-icon-redo:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIGhlaWdodD0iMjQiIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjE2Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgICA8cGF0aCBkPSJNMCAwaDI0djI0SDB6IiBmaWxsPSJub25lIi8+PHBhdGggZD0iTTE4LjQgMTAuNkMxNi41NSA4Ljk5IDE0LjE1IDggMTEuNSA4Yy00LjY1IDAtOC41OCAzLjAzLTkuOTYgNy4yMkwzLjkgMTZjMS4wNS0zLjE5IDQuMDUtNS41IDcuNi01LjUgMS45NSAwIDMuNzMuNzIgNS4xMiAxLjg4TDEzIDE2aDlWN2wtMy42IDMuNnoiLz4KICA8L2c+Cjwvc3ZnPgo=);--jp-icon-refresh:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDE4IDE4Ij4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTkgMTMuNWMtMi40OSAwLTQuNS0yLjAxLTQuNS00LjVTNi41MSA0LjUgOSA0LjVjMS4yNCAwIDIuMzYuNTIgMy4xNyAxLjMzTDEwIDhoNVYzbC0xLjc2IDEuNzZDMTIuMTUgMy42OCAxMC42NiAzIDkgMyA1LjY5IDMgMy4wMSA1LjY5IDMuMDEgOVM1LjY5IDE1IDkgMTVjMi45NyAwIDUuNDMtMi4xNiA1LjktNWgtMS41MmMtLjQ2IDItMi4yNCAzLjUtNC4zOCAzLjV6Ii8+CiAgICA8L2c+Cjwvc3ZnPgo=);--jp-icon-regex:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIwIDIwIj4KICA8ZyBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiM0MTQxNDEiPgogICAgPHJlY3QgeD0iMiIgeT0iMiIgd2lkdGg9IjE2IiBoZWlnaHQ9IjE2Ii8+CiAgPC9nPgoKICA8ZyBjbGFzcz0ianAtaWNvbi1hY2NlbnQyIiBmaWxsPSIjRkZGIj4KICAgIDxjaXJjbGUgY2xhc3M9InN0MiIgY3g9IjUuNSIgY3k9IjE0LjUiIHI9IjEuNSIvPgogICAgPHJlY3QgeD0iMTIiIHk9IjQiIGNsYXNzPSJzdDIiIHdpZHRoPSIxIiBoZWlnaHQ9IjgiLz4KICAgIDxyZWN0IHg9IjguNSIgeT0iNy41IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjg2NiAtMC41IDAuNSAwLjg2NiAtMi4zMjU1IDcuMzIxOSkiIGNsYXNzPSJzdDIiIHdpZHRoPSI4IiBoZWlnaHQ9IjEiLz4KICAgIDxyZWN0IHg9IjEyIiB5PSI0IiB0cmFuc2Zvcm09Im1hdHJpeCgwLjUgLTAuODY2IDAuODY2IDAuNSAtMC42Nzc5IDE0LjgyNTIpIiBjbGFzcz0ic3QyIiB3aWR0aD0iMSIgaGVpZ2h0PSI4Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-run:url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTggNXYxNGwxMS03eiIvPgogICAgPC9nPgo8L3N2Zz4K);--jp-icon-running:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDUxMiA1MTIiPgogIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICA8cGF0aCBkPSJNMjU2IDhDMTE5IDggOCAxMTkgOCAyNTZzMTExIDI0OCAyNDggMjQ4IDI0OC0xMTEgMjQ4LTI0OFMzOTMgOCAyNTYgOHptOTYgMzI4YzAgOC44LTcuMiAxNi0xNiAxNkgxNzZjLTguOCAwLTE2LTcuMi0xNi0xNlYxNzZjMC04LjggNy4yLTE2IDE2LTE2aDE2MGM4LjggMCAxNiA3LjIgMTYgMTZ2MTYweiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-save:url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTE3IDNINWMtMS4xMSAwLTIgLjktMiAydjE0YzAgMS4xLjg5IDIgMiAyaDE0YzEuMSAwIDItLjkgMi0yVjdsLTQtNHptLTUgMTZjLTEuNjYgMC0zLTEuMzQtMy0zczEuMzQtMyAzLTMgMyAxLjM0IDMgMy0xLjM0IDMtMyAzem0zLTEwSDVWNWgxMHY0eiIvPgogICAgPC9nPgo8L3N2Zz4K);--jp-icon-search:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTggMTgiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjEsMTAuOWgtMC43bC0wLjItMC4yYzAuOC0wLjksMS4zLTIuMiwxLjMtMy41YzAtMy0yLjQtNS40LTUuNC01LjRTMS44LDQuMiwxLjgsNy4xczIuNCw1LjQsNS40LDUuNCBjMS4zLDAsMi41LTAuNSwzLjUtMS4zbDAuMiwwLjJ2MC43bDQuMSw0LjFsMS4yLTEuMkwxMi4xLDEwLjl6IE03LjEsMTAuOWMtMi4xLDAtMy43LTEuNy0zLjctMy43czEuNy0zLjcsMy43LTMuN3MzLjcsMS43LDMuNywzLjcgUzkuMiwxMC45LDcuMSwxMC45eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-settings:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIiBkPSJNMTkuNDMgMTIuOThjLjA0LS4zMi4wNy0uNjQuMDctLjk4cy0uMDMtLjY2LS4wNy0uOThsMi4xMS0xLjY1Yy4xOS0uMTUuMjQtLjQyLjEyLS42NGwtMi0zLjQ2Yy0uMTItLjIyLS4zOS0uMy0uNjEtLjIybC0yLjQ5IDFjLS41Mi0uNC0xLjA4LS43My0xLjY5LS45OGwtLjM4LTIuNjVBLjQ4OC40ODggMCAwMDE0IDJoLTRjLS4yNSAwLS40Ni4xOC0uNDkuNDJsLS4zOCAyLjY1Yy0uNjEuMjUtMS4xNy41OS0xLjY5Ljk4bC0yLjQ5LTFjLS4yMy0uMDktLjQ5IDAtLjYxLjIybC0yIDMuNDZjLS4xMy4yMi0uMDcuNDkuMTIuNjRsMi4xMSAxLjY1Yy0uMDQuMzItLjA3LjY1LS4wNy45OHMuMDMuNjYuMDcuOThsLTIuMTEgMS42NWMtLjE5LjE1LS4yNC40Mi0uMTIuNjRsMiAzLjQ2Yy4xMi4yMi4zOS4zLjYxLjIybDIuNDktMWMuNTIuNCAxLjA4LjczIDEuNjkuOThsLjM4IDIuNjVjLjAzLjI0LjI0LjQyLjQ5LjQyaDRjLjI1IDAgLjQ2LS4xOC40OS0uNDJsLjM4LTIuNjVjLjYxLS4yNSAxLjE3LS41OSAxLjY5LS45OGwyLjQ5IDFjLjIzLjA5LjQ5IDAgLjYxLS4yMmwyLTMuNDZjLjEyLS4yMi4wNy0uNDktLjEyLS42NGwtMi4xMS0xLjY1ek0xMiAxNS41Yy0xLjkzIDAtMy41LTEuNTctMy41LTMuNXMxLjU3LTMuNSAzLjUtMy41IDMuNSAxLjU3IDMuNSAzLjUtMS41NyAzLjUtMy41IDMuNXoiLz4KPC9zdmc+Cg==);--jp-icon-share:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTSAxOCAyIEMgMTYuMzU0OTkgMiAxNSAzLjM1NDk5MDQgMTUgNSBDIDE1IDUuMTkwOTUyOSAxNS4wMjE3OTEgNS4zNzcxMjI0IDE1LjA1NjY0MSA1LjU1ODU5MzggTCA3LjkyMTg3NSA5LjcyMDcwMzEgQyA3LjM5ODUzOTkgOS4yNzc4NTM5IDYuNzMyMDc3MSA5IDYgOSBDIDQuMzU0OTkwNCA5IDMgMTAuMzU0OTkgMyAxMiBDIDMgMTMuNjQ1MDEgNC4zNTQ5OTA0IDE1IDYgMTUgQyA2LjczMjA3NzEgMTUgNy4zOTg1Mzk5IDE0LjcyMjE0NiA3LjkyMTg3NSAxNC4yNzkyOTcgTCAxNS4wNTY2NDEgMTguNDM5NDUzIEMgMTUuMDIxNTU1IDE4LjYyMTUxNCAxNSAxOC44MDgzODYgMTUgMTkgQyAxNSAyMC42NDUwMSAxNi4zNTQ5OSAyMiAxOCAyMiBDIDE5LjY0NTAxIDIyIDIxIDIwLjY0NTAxIDIxIDE5IEMgMjEgMTcuMzU0OTkgMTkuNjQ1MDEgMTYgMTggMTYgQyAxNy4yNjc0OCAxNiAxNi42MDE1OTMgMTYuMjc5MzI4IDE2LjA3ODEyNSAxNi43MjI2NTYgTCA4Ljk0MzM1OTQgMTIuNTU4NTk0IEMgOC45NzgyMDk1IDEyLjM3NzEyMiA5IDEyLjE5MDk1MyA5IDEyIEMgOSAxMS44MDkwNDcgOC45NzgyMDk1IDExLjYyMjg3OCA4Ljk0MzM1OTQgMTEuNDQxNDA2IEwgMTYuMDc4MTI1IDcuMjc5Mjk2OSBDIDE2LjYwMTQ2IDcuNzIyMTQ2MSAxNy4yNjc5MjMgOCAxOCA4IEMgMTkuNjQ1MDEgOCAyMSA2LjY0NTAwOTYgMjEgNSBDIDIxIDMuMzU0OTkwNCAxOS42NDUwMSAyIDE4IDIgeiBNIDE4IDQgQyAxOC41NjQxMjkgNCAxOSA0LjQzNTg3MDYgMTkgNSBDIDE5IDUuNTY0MTI5NCAxOC41NjQxMjkgNiAxOCA2IEMgMTcuNDM1ODcxIDYgMTcgNS41NjQxMjk0IDE3IDUgQyAxNyA0LjQzNTg3MDYgMTcuNDM1ODcxIDQgMTggNCB6IE0gNiAxMSBDIDYuNTY0MTI5NCAxMSA3IDExLjQzNTg3MSA3IDEyIEMgNyAxMi41NjQxMjkgNi41NjQxMjk0IDEzIDYgMTMgQyA1LjQzNTg3MDYgMTMgNSAxMi41NjQxMjkgNSAxMiBDIDUgMTEuNDM1ODcxIDUuNDM1ODcwNiAxMSA2IDExIHogTSAxOCAxOCBDIDE4LjU2NDEyOSAxOCAxOSAxOC40MzU4NzEgMTkgMTkgQyAxOSAxOS41NjQxMjkgMTguNTY0MTI5IDIwIDE4IDIwIEMgMTcuNDM1ODcxIDIwIDE3IDE5LjU2NDEyOSAxNyAxOSBDIDE3IDE4LjQzNTg3MSAxNy40MzU4NzEgMTggMTggMTggeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-spreadsheet:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8cGF0aCBjbGFzcz0ianAtaWNvbi1jb250cmFzdDEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNENBRjUwIiBkPSJNMi4yIDIuMnYxNy42aDE3LjZWMi4ySDIuMnptMTUuNCA3LjdoLTUuNVY0LjRoNS41djUuNXpNOS45IDQuNHY1LjVINC40VjQuNGg1LjV6bS01LjUgNy43aDUuNXY1LjVINC40di01LjV6bTcuNyA1LjV2LTUuNWg1LjV2NS41aC01LjV6Ii8+Cjwvc3ZnPgo=);--jp-icon-stop:url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik02IDZoMTJ2MTJINnoiLz4KICAgIDwvZz4KPC9zdmc+Cg==);--jp-icon-tab:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTIxIDNIM2MtMS4xIDAtMiAuOS0yIDJ2MTRjMCAxLjEuOSAyIDIgMmgxOGMxLjEgMCAyLS45IDItMlY1YzAtMS4xLS45LTItMi0yem0wIDE2SDNWNWgxMHY0aDh2MTB6Ii8+CiAgPC9nPgo8L3N2Zz4K);--jp-icon-table-rows:url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMSw4SDNWNGgxOFY4eiBNMjEsMTBIM3Y0aDE4VjEweiBNMjEsMTZIM3Y0aDE4VjE2eiIvPgogICAgPC9nPgo8L3N2Zz4K);--jp-icon-tag:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjgiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCA0MyAyOCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCTxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CgkJPHBhdGggZD0iTTI4LjgzMzIgMTIuMzM0TDMyLjk5OTggMTYuNTAwN0wzNy4xNjY1IDEyLjMzNEgyOC44MzMyWiIvPgoJCTxwYXRoIGQ9Ik0xNi4yMDk1IDIxLjYxMDRDMTUuNjg3MyAyMi4xMjk5IDE0Ljg0NDMgMjIuMTI5OSAxNC4zMjQ4IDIxLjYxMDRMNi45ODI5IDE0LjcyNDVDNi41NzI0IDE0LjMzOTQgNi4wODMxMyAxMy42MDk4IDYuMDQ3ODYgMTMuMDQ4MkM1Ljk1MzQ3IDExLjUyODggNi4wMjAwMiA4LjYxOTQ0IDYuMDY2MjEgNy4wNzY5NUM2LjA4MjgxIDYuNTE0NzcgNi41NTU0OCA2LjA0MzQ3IDcuMTE4MDQgNi4wMzA1NUM5LjA4ODYzIDUuOTg0NzMgMTMuMjYzOCA1LjkzNTc5IDEzLjY1MTggNi4zMjQyNUwyMS43MzY5IDEzLjYzOUMyMi4yNTYgMTQuMTU4NSAyMS43ODUxIDE1LjQ3MjQgMjEuMjYyIDE1Ljk5NDZMMTYuMjA5NSAyMS42MTA0Wk05Ljc3NTg1IDguMjY1QzkuMzM1NTEgNy44MjU2NiA4LjYyMzUxIDcuODI1NjYgOC4xODI4IDguMjY1QzcuNzQzNDYgOC43MDU3MSA3Ljc0MzQ2IDkuNDE3MzMgOC4xODI4IDkuODU2NjdDOC42MjM4MiAxMC4yOTY0IDkuMzM1ODIgMTAuMjk2NCA5Ljc3NTg1IDkuODU2NjdDMTAuMjE1NiA5LjQxNzMzIDEwLjIxNTYgOC43MDUzMyA5Ljc3NTg1IDguMjY1WiIvPgoJPC9nPgo8L3N2Zz4K);--jp-icon-terminal:url(data:image/svg+xml;base64,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);--jp-icon-text-editor:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8cGF0aCBjbGFzcz0ianAtdGV4dC1lZGl0b3ItaWNvbi1jb2xvciBqcC1pY29uLXNlbGVjdGFibGUiIGZpbGw9IiM2MTYxNjEiIGQ9Ik0xNSAxNUgzdjJoMTJ2LTJ6bTAtOEgzdjJoMTJWN3pNMyAxM2gxOHYtMkgzdjJ6bTAgOGgxOHYtMkgzdjJ6TTMgM3YyaDE4VjNIM3oiLz4KPC9zdmc+Cg==);--jp-icon-toc:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0Ij4KICA8ZyBjbGFzcz0ianAtaWNvbjMganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjNjE2MTYxIj4KICAgIDxwYXRoIGQ9Ik03LDVIMjFWN0g3VjVNNywxM1YxMUgyMVYxM0g3TTQsNC41QTEuNSwxLjUgMCAwLDEgNS41LDZBMS41LDEuNSAwIDAsMSA0LDcuNUExLjUsMS41IDAgMCwxIDIuNSw2QTEuNSwxLjUgMCAwLDEgNCw0LjVNNCwxMC41QTEuNSwxLjUgMCAwLDEgNS41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMy41QTEuNSwxLjUgMCAwLDEgMi41LDEyQTEuNSwxLjUgMCAwLDEgNCwxMC41TTcsMTlWMTdIMjFWMTlIN000LDE2LjVBMS41LDEuNSAwIDAsMSA1LjUsMThBMS41LDEuNSAwIDAsMSA0LDE5LjVBMS41LDEuNSAwIDAsMSAyLjUsMThBMS41LDEuNSAwIDAsMSA0LDE2LjVaIiAvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-tree-view:url(data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9IjI0IiB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICAgIDxnIGNsYXNzPSJqcC1pY29uMyIgZmlsbD0iIzYxNjE2MSI+CiAgICAgICAgPHBhdGggZD0iTTAgMGgyNHYyNEgweiIgZmlsbD0ibm9uZSIvPgogICAgICAgIDxwYXRoIGQ9Ik0yMiAxMVYzaC03djNIOVYzSDJ2OGg3VjhoMnYxMGg0djNoN3YtOGgtN3YzaC0yVjhoMnYzeiIvPgogICAgPC9nPgo8L3N2Zz4K);--jp-icon-trusted:url(data:image/svg+xml;base64,PHN2ZyBmaWxsPSJub25lIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDI0IDI1Ij4KICAgIDxwYXRoIGNsYXNzPSJqcC1pY29uMiIgc3Ryb2tlPSIjMzMzMzMzIiBzdHJva2Utd2lkdGg9IjIiIHRyYW5zZm9ybT0idHJhbnNsYXRlKDIgMykiIGQ9Ik0xLjg2MDk0IDExLjQ0MDlDMC44MjY0NDggOC43NzAyNyAwLjg2Mzc3OSA2LjA1NzY0IDEuMjQ5MDcgNC4xOTkzMkMyLjQ4MjA2IDMuOTMzNDcgNC4wODA2OCAzLjQwMzQ3IDUuNjAxMDIgMi44NDQ5QzcuMjM1NDkgMi4yNDQ0IDguODU2NjYgMS41ODE1IDkuOTg3NiAxLjA5NTM5QzExLjA1OTcgMS41ODM0MSAxMi42MDk0IDIuMjQ0NCAxNC4yMTggMi44NDMzOUMxNS43NTAzIDMuNDEzOTQgMTcuMzk5NSAzLjk1MjU4IDE4Ljc1MzkgNC4yMTM4NUMxOS4xMzY0IDYuMDcxNzcgMTkuMTcwOSA4Ljc3NzIyIDE4LjEzOSAxMS40NDA5QzE3LjAzMDMgMTQuMzAzMiAxNC42NjY4IDE3LjE4NDQgOS45OTk5OSAxOC45MzU0QzUuMzMzMiAxNy4xODQ0IDIuOTY5NjggMTQuMzAzMiAxLjg2MDk0IDExLjQ0MDlaIi8+CiAgICA8cGF0aCBjbGFzcz0ianAtaWNvbjIiIGZpbGw9IiMzMzMzMzMiIHN0cm9rZT0iIzMzMzMzMyIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoOCA5Ljg2NzE5KSIgZD0iTTIuODYwMTUgNC44NjUzNUwwLjcyNjU0OSAyLjk5OTU5TDAgMy42MzA0NUwyLjg2MDE1IDYuMTMxNTdMOCAwLjYzMDg3Mkw3LjI3ODU3IDBMMi44NjAxNSA0Ljg2NTM1WiIvPgo8L3N2Zz4K);--jp-icon-undo:url(data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjQgMjQiIHdpZHRoPSIxNiIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTEyLjUgOGMtMi42NSAwLTUuMDUuOTktNi45IDIuNkwyIDd2OWg5bC0zLjYyLTMuNjJjMS4zOS0xLjE2IDMuMTYtMS44OCA1LjEyLTEuODggMy41NCAwIDYuNTUgMi4zMSA3LjYgNS41bDIuMzctLjc4QzIxLjA4IDExLjAzIDE3LjE1IDggMTIuNSA4eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-user:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIHZpZXdCb3g9IjAgMCAyNCAyNCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KICA8ZyBjbGFzcz0ianAtaWNvbjMiIGZpbGw9IiM2MTYxNjEiPgogICAgPHBhdGggZD0iTTE2IDdhNCA0IDAgMTEtOCAwIDQgNCAwIDAxOCAwek0xMiAxNGE3IDcgMCAwMC03IDdoMTRhNyA3IDAgMDAtNy03eiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-users:url(data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjQiIGhlaWdodD0iMjQiIHZlcnNpb249IjEuMSIgdmlld0JveD0iMCAwIDM2IDI0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgogPGcgY2xhc3M9ImpwLWljb24zIiB0cmFuc2Zvcm09Im1hdHJpeCgxLjczMjcgMCAwIDEuNzMyNyAtMy42MjgyIC4wOTk1NzcpIiBmaWxsPSIjNjE2MTYxIj4KICA8cGF0aCB0cmFuc2Zvcm09Im1hdHJpeCgxLjUsMCwwLDEuNSwwLC02KSIgZD0ibTEyLjE4NiA3LjUwOThjLTEuMDUzNSAwLTEuOTc1NyAwLjU2NjUtMi40Nzg1IDEuNDEwMiAwLjc1MDYxIDAuMzEyNzcgMS4zOTc0IDAuODI2NDggMS44NzMgMS40NzI3aDMuNDg2M2MwLTEuNTkyLTEuMjg4OS0yLjg4MjgtMi44ODA5LTIuODgyOHoiLz4KICA8cGF0aCBkPSJtMjAuNDY1IDIuMzg5NWEyLjE4ODUgMi4xODg1IDAgMCAxLTIuMTg4NCAyLjE4ODUgMi4xODg1IDIuMTg4NSAwIDAgMS0yLjE4ODUtMi4xODg1IDIuMTg4NSAyLjE4ODUgMCAwIDEgMi4xODg1LTIuMTg4NSAyLjE4ODUgMi4xODg1IDAgMCAxIDIuMTg4NCAyLjE4ODV6Ii8+CiAgPHBhdGggdHJhbnNmb3JtPSJtYXRyaXgoMS41LDAsMCwxLjUsMCwtNikiIGQ9Im0zLjU4OTggOC40MjE5Yy0xLjExMjYgMC0yLjAxMzcgMC45MDExMS0yLjAxMzcgMi4wMTM3aDIuODE0NWMwLjI2Nzk3LTAuMzczMDkgMC41OTA3LTAuNzA0MzUgMC45NTg5OC0wLjk3ODUyLTAuMzQ0MzMtMC42MTY4OC0xLjAwMzEtMS4wMzUyLTEuNzU5OC0xLjAzNTJ6Ii8+CiAgPHBhdGggZD0ibTYuOTE1NCA0LjYyM2ExLjUyOTQgMS41Mjk0IDAgMCAxLTEuNTI5NCAxLjUyOTQgMS41Mjk0IDEuNTI5NCAwIDAgMS0xLjUyOTQtMS41Mjk0IDEuNTI5NCAxLjUyOTQgMCAwIDEgMS41Mjk0LTEuNTI5NCAxLjUyOTQgMS41Mjk0IDAgMCAxIDEuNTI5NCAxLjUyOTR6Ii8+CiAgPHBhdGggZD0ibTYuMTM1IDEzLjUzNWMwLTMuMjM5MiAyLjYyNTktNS44NjUgNS44NjUtNS44NjUgMy4yMzkyIDAgNS44NjUgMi42MjU5IDUuODY1IDUuODY1eiIvPgogIDxjaXJjbGUgY3g9IjEyIiBjeT0iMy43Njg1IiByPSIyLjk2ODUiLz4KIDwvZz4KPC9zdmc+Cg==);--jp-icon-vega:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbjEganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjMjEyMTIxIj4KICAgIDxwYXRoIGQ9Ik0xMC42IDUuNGwyLjItMy4ySDIuMnY3LjNsNC02LjZ6Ii8+CiAgICA8cGF0aCBkPSJNMTUuOCAyLjJsLTQuNCA2LjZMNyA2LjNsLTQuOCA4djUuNWgxNy42VjIuMmgtNHptLTcgMTUuNEg1LjV2LTQuNGgzLjN2NC40em00LjQgMEg5LjhWOS44aDMuNHY3Ljh6bTQuNCAwaC0zLjRWNi41aDMuNHYxMS4xeiIvPgogIDwvZz4KPC9zdmc+Cg==);--jp-icon-word:url(data:image/svg+xml;base64,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);--jp-icon-yaml:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgdmlld0JveD0iMCAwIDIyIDIyIj4KICA8ZyBjbGFzcz0ianAtaWNvbi1jb250cmFzdDIganAtaWNvbi1zZWxlY3RhYmxlIiBmaWxsPSIjRDgxQjYwIj4KICAgIDxwYXRoIGQ9Ik03LjIgMTguNnYtNS40TDMgNS42aDMuM2wxLjQgMy4xYy4zLjkuNiAxLjYgMSAyLjUuMy0uOC42LTEuNiAxLTIuNWwxLjQtMy4xaDMuNGwtNC40IDcuNnY1LjVsLTIuOS0uMXoiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxNi41IiByPSIyLjEiLz4KICAgIDxjaXJjbGUgY2xhc3M9InN0MCIgY3g9IjE3LjYiIGN5PSIxMSIgcj0iMi4xIi8+CiAgPC9nPgo8L3N2Zz4K)}
.jp-AddAboveIcon{background-image:var(--jp-icon-add-above)}.jp-AddBelowIcon{background-image:var(--jp-icon-add-below)}.jp-AddIcon{background-image:var(--jp-icon-add)}.jp-BellIcon{background-image:var(--jp-icon-bell)}.jp-BugDotIcon{background-image:var(--jp-icon-bug-dot)}.jp-BugIcon{background-image:var(--jp-icon-bug)}.jp-BuildIcon{background-image:var(--jp-icon-build)}.jp-CaretDownEmptyIcon{background-image:var(--jp-icon-caret-down-empty)}.jp-CaretDownEmptyThinIcon{background-image:var(--jp-icon-caret-down-empty-thin)}.jp-CaretDownIcon{background-image:var(--jp-icon-caret-down)}.jp-CaretLeftIcon{background-image:var(--jp-icon-caret-left)}.jp-CaretRightIcon{background-image:var(--jp-icon-caret-right)}.jp-CaretUpEmptyThinIcon{background-image:var(--jp-icon-caret-up-empty-thin)}.jp-CaretUpIcon{background-image:var(--jp-icon-caret-up)}.jp-CaseSensitiveIcon{background-image:var(--jp-icon-case-sensitive)}.jp-CheckIcon{background-image:var(--jp-icon-check)}.jp-CircleEmptyIcon{background-image:var(--jp-icon-circle-empty)}.jp-CircleIcon{background-image:var(--jp-icon-circle)}.jp-ClearIcon{background-image:var(--jp-icon-clear)}.jp-CloseIcon{background-image:var(--jp-icon-close)}.jp-CodeCheckIcon{background-image:var(--jp-icon-code-check)}.jp-CodeIcon{background-image:var(--jp-icon-code)}.jp-CollapseAllIcon{background-image:var(--jp-icon-collapse-all)}.jp-ConsoleIcon{background-image:var(--jp-icon-console)}.jp-CopyIcon{background-image:var(--jp-icon-copy)}.jp-CopyrightIcon{background-image:var(--jp-icon-copyright)}.jp-CutIcon{background-image:var(--jp-icon-cut)}.jp-DeleteIcon{background-image:var(--jp-icon-delete)}.jp-DownloadIcon{background-image:var(--jp-icon-download)}.jp-DuplicateIcon{background-image:var(--jp-icon-duplicate)}.jp-EditIcon{background-image:var(--jp-icon-edit)}.jp-EllipsesIcon{background-image:var(--jp-icon-ellipses)}.jp-ErrorIcon{background-image:var(--jp-icon-error)}.jp-ExpandAllIcon{background-image:var(--jp-icon-expand-all)}.jp-ExtensionIcon{background-image:var(--jp-icon-extension)}.jp-FastForwardIcon{background-image:var(--jp-icon-fast-forward)}.jp-FileIcon{background-image:var(--jp-icon-file)}.jp-FileUploadIcon{background-image:var(--jp-icon-file-upload)}.jp-FilterDotIcon{background-image:var(--jp-icon-filter-dot)}.jp-FilterIcon{background-image:var(--jp-icon-filter)}.jp-FilterListIcon{background-image:var(--jp-icon-filter-list)}.jp-FolderFavoriteIcon{background-image:var(--jp-icon-folder-favorite)}.jp-FolderIcon{background-image:var(--jp-icon-folder)}.jp-HomeIcon{background-image:var(--jp-icon-home)}.jp-Html5Icon{background-image:var(--jp-icon-html5)}.jp-ImageIcon{background-image:var(--jp-icon-image)}.jp-InfoIcon{background-image:var(--jp-icon-info)}.jp-InspectorIcon{background-image:var(--jp-icon-inspector)}.jp-JsonIcon{background-image:var(--jp-icon-json)}.jp-JuliaIcon{background-image:var(--jp-icon-julia)}.jp-JupyterFaviconIcon{background-image:var(--jp-icon-jupyter-favicon)}.jp-JupyterIcon{background-image:var(--jp-icon-jupyter)}.jp-JupyterlabWordmarkIcon{background-image:var(--jp-icon-jupyterlab-wordmark)}.jp-KernelIcon{background-image:var(--jp-icon-kernel)}.jp-KeyboardIcon{background-image:var(--jp-icon-keyboard)}.jp-LaunchIcon{background-image:var(--jp-icon-launch)}.jp-LauncherIcon{background-image:var(--jp-icon-launcher)}.jp-LineFormIcon{background-image:var(--jp-icon-line-form)}.jp-LinkIcon{background-image:var(--jp-icon-link)}.jp-ListIcon{background-image:var(--jp-icon-list)}.jp-MarkdownIcon{background-image:var(--jp-icon-markdown)}.jp-MoveDownIcon{background-image:var(--jp-icon-move-down)}.jp-MoveUpIcon{background-image:var(--jp-icon-move-up)}.jp-NewFolderIcon{background-image:var(--jp-icon-new-folder)}.jp-NotTrustedIcon{background-image:var(--jp-icon-not-trusted)}.jp-NotebookIcon{background-image:var(--jp-icon-notebook)}.jp-NumberingIcon{background-image:var(--jp-icon-numbering)}.jp-OfflineBoltIcon{background-image:var(--jp-icon-offline-bolt)}.jp-PaletteIcon{background-image:var(--jp-icon-palette)}.jp-PasteIcon{background-image:var(--jp-icon-paste)}.jp-PdfIcon{background-image:var(--jp-icon-pdf)}.jp-PythonIcon{background-image:var(--jp-icon-python)}.jp-RKernelIcon{background-image:var(--jp-icon-r-kernel)}.jp-ReactIcon{background-image:var(--jp-icon-react)}.jp-RedoIcon{background-image:var(--jp-icon-redo)}.jp-RefreshIcon{background-image:var(--jp-icon-refresh)}.jp-RegexIcon{background-image:var(--jp-icon-regex)}.jp-RunIcon{background-image:var(--jp-icon-run)}.jp-RunningIcon{background-image:var(--jp-icon-running)}.jp-SaveIcon{background-image:var(--jp-icon-save)}.jp-SearchIcon{background-image:var(--jp-icon-search)}.jp-SettingsIcon{background-image:var(--jp-icon-settings)}.jp-ShareIcon{background-image:var(--jp-icon-share)}.jp-SpreadsheetIcon{background-image:var(--jp-icon-spreadsheet)}.jp-StopIcon{background-image:var(--jp-icon-stop)}.jp-TabIcon{background-image:var(--jp-icon-tab)}.jp-TableRowsIcon{background-image:var(--jp-icon-table-rows)}.jp-TagIcon{background-image:var(--jp-icon-tag)}
.jp-TerminalIcon{background-image:var(--jp-icon-terminal)}.jp-TextEditorIcon{background-image:var(--jp-icon-text-editor)}.jp-TocIcon{background-image:var(--jp-icon-toc)}.jp-TreeViewIcon{background-image:var(--jp-icon-tree-view)}.jp-TrustedIcon{background-image:var(--jp-icon-trusted)}.jp-UndoIcon{background-image:var(--jp-icon-undo)}.jp-UserIcon{background-image:var(--jp-icon-user)}.jp-UsersIcon{background-image:var(--jp-icon-users)}.jp-VegaIcon{background-image:var(--jp-icon-vega)}.jp-WordIcon{background-image:var(--jp-icon-word)}.jp-YamlIcon{background-image:var(--jp-icon-yaml)}.jp-Icon,.jp-MaterialIcon{background-position:center;background-repeat:no-repeat;background-size:16px;min-width:16px;min-height:16px}.jp-Icon-cover{background-position:center;background-repeat:no-repeat;background-size:cover}.jp-Icon-16{background-size:16px;min-width:16px;min-height:16px}.jp-Icon-18{background-size:18px;min-width:18px;min-height:18px}.jp-Icon-20{background-size:20px;min-width:20px;min-height:20px}.lm-TabBar .lm-TabBar-addButton{align-items:center;display:flex;padding:4px;padding-bottom:5px;margin-right:1px;background-color:var(--jp-layout-color2)}.lm-TabBar .lm-TabBar-addButton:hover{background-color:var(--jp-layout-color1)}.lm-DockPanel-tabBar .lm-TabBar-tab{width:var(--jp-private-horizontal-tab-width)}.lm-DockPanel-tabBar .lm-TabBar-content{flex:unset}.lm-DockPanel-tabBar[data-orientation='horizontal']{flex:1 1 auto}.jp-icon0[fill]{fill:var(--jp-inverse-layout-color0)}.jp-icon1[fill]{fill:var(--jp-inverse-layout-color1)}.jp-icon2[fill]{fill:var(--jp-inverse-layout-color2)}.jp-icon3[fill]{fill:var(--jp-inverse-layout-color3)}.jp-icon4[fill]{fill:var(--jp-inverse-layout-color4)}.jp-icon0[stroke]{stroke:var(--jp-inverse-layout-color0)}.jp-icon1[stroke]{stroke:var(--jp-inverse-layout-color1)}.jp-icon2[stroke]{stroke:var(--jp-inverse-layout-color2)}.jp-icon3[stroke]{stroke:var(--jp-inverse-layout-color3)}.jp-icon4[stroke]{stroke:var(--jp-inverse-layout-color4)}.jp-icon-accent0[fill]{fill:var(--jp-layout-color0)}.jp-icon-accent1[fill]{fill:var(--jp-layout-color1)}.jp-icon-accent2[fill]{fill:var(--jp-layout-color2)}.jp-icon-accent3[fill]{fill:var(--jp-layout-color3)}.jp-icon-accent4[fill]{fill:var(--jp-layout-color4)}.jp-icon-accent0[stroke]{stroke:var(--jp-layout-color0)}.jp-icon-accent1[stroke]{stroke:var(--jp-layout-color1)}.jp-icon-accent2[stroke]{stroke:var(--jp-layout-color2)}.jp-icon-accent3[stroke]{stroke:var(--jp-layout-color3)}.jp-icon-accent4[stroke]{stroke:var(--jp-layout-color4)}.jp-icon-none[fill]{fill:none}.jp-icon-none[stroke]{stroke:none}.jp-icon-brand0[fill]{fill:var(--jp-brand-color0)}.jp-icon-brand1[fill]{fill:var(--jp-brand-color1)}.jp-icon-brand2[fill]{fill:var(--jp-brand-color2)}.jp-icon-brand3[fill]{fill:var(--jp-brand-color3)}.jp-icon-brand4[fill]{fill:var(--jp-brand-color4)}.jp-icon-brand0[stroke]{stroke:var(--jp-brand-color0)}.jp-icon-brand1[stroke]{stroke:var(--jp-brand-color1)}.jp-icon-brand2[stroke]{stroke:var(--jp-brand-color2)}.jp-icon-brand3[stroke]{stroke:var(--jp-brand-color3)}.jp-icon-brand4[stroke]{stroke:var(--jp-brand-color4)}.jp-icon-warn0[fill]{fill:var(--jp-warn-color0)}.jp-icon-warn1[fill]{fill:var(--jp-warn-color1)}.jp-icon-warn2[fill]{fill:var(--jp-warn-color2)}.jp-icon-warn3[fill]{fill:var(--jp-warn-color3)}.jp-icon-warn0[stroke]{stroke:var(--jp-warn-color0)}.jp-icon-warn1[stroke]{stroke:var(--jp-warn-color1)}.jp-icon-warn2[stroke]{stroke:var(--jp-warn-color2)}.jp-icon-warn3[stroke]{stroke:var(--jp-warn-color3)}.jp-icon-contrast0[fill]{fill:var(--jp-icon-contrast-color0)}.jp-icon-contrast1[fill]{fill:var(--jp-icon-contrast-color1)}.jp-icon-contrast2[fill]{fill:var(--jp-icon-contrast-color2)}.jp-icon-contrast3[fill]{fill:var(--jp-icon-contrast-color3)}.jp-icon-contrast0[stroke]{stroke:var(--jp-icon-contrast-color0)}.jp-icon-contrast1[stroke]{stroke:var(--jp-icon-contrast-color1)}.jp-icon-contrast2[stroke]{stroke:var(--jp-icon-contrast-color2)}.jp-icon-contrast3[stroke]{stroke:var(--jp-icon-contrast-color3)}.jp-icon-dot[fill]{fill:var(--jp-warn-color0)}.jp-jupyter-icon-color[fill]{fill:var(--jp-jupyter-icon-color,var(--jp-warn-color0))}.jp-notebook-icon-color[fill]{fill:var(--jp-notebook-icon-color,var(--jp-warn-color0))}.jp-json-icon-color[fill]{fill:var(--jp-json-icon-color,var(--jp-warn-color1))}.jp-console-icon-color[fill]{fill:var(--jp-console-icon-color,white)}.jp-console-icon-background-color[fill]{fill:var(--jp-console-icon-background-color,var(--jp-brand-color1))}.jp-terminal-icon-color[fill]{fill:var(--jp-terminal-icon-color,var(--jp-layout-color2))}.jp-terminal-icon-background-color[fill]{fill:var(--jp-terminal-icon-background-color,var(--jp-inverse-layout-color2))}.jp-text-editor-icon-color[fill]{fill:var(--jp-text-editor-icon-color,var(--jp-inverse-layout-color3))}.jp-inspector-icon-color[fill]{fill:var(--jp-inspector-icon-color,var(--jp-inverse-layout-color3))}.jp-DirListing-item.jp-mod-selected .jp-icon-selectable[fill]{fill:#fff}.jp-DirListing-item.jp-mod-selected .jp-icon-selectable-inverse[fill]{fill:var(--jp-brand-color1)}
.lm-DockPanel-tabBar .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon3[fill]{fill:none}.lm-DockPanel-tabBar .lm-TabBar-tab.lm-mod-closable.jp-mod-dirty>.lm-TabBar-tabCloseIcon>:not(:hover)>.jp-icon-busy[fill]{fill:var(--jp-inverse-layout-color3)}#jp-main-statusbar .jp-mod-selected .jp-icon-selectable[fill]{fill:#fff}#jp-main-statusbar .jp-mod-selected .jp-icon-selectable-inverse[fill]{fill:var(--jp-brand-color1)}:root{--jp-warn-color0:var(--md-orange-700)}.jp-DragIcon{margin-right:4px}.jp-icon-alt .jp-icon0[fill]{fill:var(--jp-layout-color0)}.jp-icon-alt .jp-icon1[fill]{fill:var(--jp-layout-color1)}.jp-icon-alt .jp-icon2[fill]{fill:var(--jp-layout-color2)}.jp-icon-alt .jp-icon3[fill]{fill:var(--jp-layout-color3)}.jp-icon-alt .jp-icon4[fill]{fill:var(--jp-layout-color4)}.jp-icon-alt .jp-icon0[stroke]{stroke:var(--jp-layout-color0)}.jp-icon-alt .jp-icon1[stroke]{stroke:var(--jp-layout-color1)}.jp-icon-alt .jp-icon2[stroke]{stroke:var(--jp-layout-color2)}.jp-icon-alt .jp-icon3[stroke]{stroke:var(--jp-layout-color3)}.jp-icon-alt .jp-icon4[stroke]{stroke:var(--jp-layout-color4)}.jp-icon-alt .jp-icon-accent0[fill]{fill:var(--jp-inverse-layout-color0)}.jp-icon-alt .jp-icon-accent1[fill]{fill:var(--jp-inverse-layout-color1)}.jp-icon-alt .jp-icon-accent2[fill]{fill:var(--jp-inverse-layout-color2)}.jp-icon-alt .jp-icon-accent3[fill]{fill:var(--jp-inverse-layout-color3)}.jp-icon-alt .jp-icon-accent4[fill]{fill:var(--jp-inverse-layout-color4)}.jp-icon-alt .jp-icon-accent0[stroke]{stroke:var(--jp-inverse-layout-color0)}.jp-icon-alt .jp-icon-accent1[stroke]{stroke:var(--jp-inverse-layout-color1)}.jp-icon-alt .jp-icon-accent2[stroke]{stroke:var(--jp-inverse-layout-color2)}.jp-icon-alt .jp-icon-accent3[stroke]{stroke:var(--jp-inverse-layout-color3)}.jp-icon-alt .jp-icon-accent4[stroke]{stroke:var(--jp-inverse-layout-color4)}.jp-icon-hoverShow:not(:hover) .jp-icon-hoverShow-content{display:none!important}.jp-icon-hover :hover .jp-icon0-hover[fill]{fill:var(--jp-inverse-layout-color0)}.jp-icon-hover :hover .jp-icon1-hover[fill]{fill:var(--jp-inverse-layout-color1)}.jp-icon-hover :hover .jp-icon2-hover[fill]{fill:var(--jp-inverse-layout-color2)}.jp-icon-hover :hover .jp-icon3-hover[fill]{fill:var(--jp-inverse-layout-color3)}.jp-icon-hover :hover .jp-icon4-hover[fill]{fill:var(--jp-inverse-layout-color4)}.jp-icon-hover :hover .jp-icon0-hover[stroke]{stroke:var(--jp-inverse-layout-color0)}.jp-icon-hover :hover .jp-icon1-hover[stroke]{stroke:var(--jp-inverse-layout-color1)}.jp-icon-hover :hover .jp-icon2-hover[stroke]{stroke:var(--jp-inverse-layout-color2)}.jp-icon-hover :hover .jp-icon3-hover[stroke]{stroke:var(--jp-inverse-layout-color3)}.jp-icon-hover :hover .jp-icon4-hover[stroke]{stroke:var(--jp-inverse-layout-color4)}.jp-icon-hover :hover .jp-icon-accent0-hover[fill]{fill:var(--jp-layout-color0)}.jp-icon-hover :hover .jp-icon-accent1-hover[fill]{fill:var(--jp-layout-color1)}.jp-icon-hover :hover .jp-icon-accent2-hover[fill]{fill:var(--jp-layout-color2)}.jp-icon-hover :hover .jp-icon-accent3-hover[fill]{fill:var(--jp-layout-color3)}.jp-icon-hover :hover .jp-icon-accent4-hover[fill]{fill:var(--jp-layout-color4)}.jp-icon-hover :hover .jp-icon-accent0-hover[stroke]{stroke:var(--jp-layout-color0)}.jp-icon-hover :hover .jp-icon-accent1-hover[stroke]{stroke:var(--jp-layout-color1)}.jp-icon-hover :hover .jp-icon-accent2-hover[stroke]{stroke:var(--jp-layout-color2)}.jp-icon-hover :hover .jp-icon-accent3-hover[stroke]{stroke:var(--jp-layout-color3)}.jp-icon-hover :hover .jp-icon-accent4-hover[stroke]{stroke:var(--jp-layout-color4)}.jp-icon-hover :hover .jp-icon-none-hover[fill]{fill:none}.jp-icon-hover :hover .jp-icon-none-hover[stroke]{stroke:none}.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[fill]{fill:var(--jp-layout-color0)}.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[fill]{fill:var(--jp-layout-color1)}.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[fill]{fill:var(--jp-layout-color2)}.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[fill]{fill:var(--jp-layout-color3)}.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[fill]{fill:var(--jp-layout-color4)}.jp-icon-hover.jp-icon-alt :hover .jp-icon0-hover[stroke]{stroke:var(--jp-layout-color0)}.jp-icon-hover.jp-icon-alt :hover .jp-icon1-hover[stroke]{stroke:var(--jp-layout-color1)}.jp-icon-hover.jp-icon-alt :hover .jp-icon2-hover[stroke]{stroke:var(--jp-layout-color2)}.jp-icon-hover.jp-icon-alt :hover .jp-icon3-hover[stroke]{stroke:var(--jp-layout-color3)}.jp-icon-hover.jp-icon-alt :hover .jp-icon4-hover[stroke]{stroke:var(--jp-layout-color4)}.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[fill]{fill:var(--jp-inverse-layout-color0)}.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[fill]{fill:var(--jp-inverse-layout-color1)}.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[fill]{fill:var(--jp-inverse-layout-color2)}.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[fill]{fill:var(--jp-inverse-layout-color3)}
.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[fill]{fill:var(--jp-inverse-layout-color4)}.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent0-hover[stroke]{stroke:var(--jp-inverse-layout-color0)}.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent1-hover[stroke]{stroke:var(--jp-inverse-layout-color1)}.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent2-hover[stroke]{stroke:var(--jp-inverse-layout-color2)}.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent3-hover[stroke]{stroke:var(--jp-inverse-layout-color3)}.jp-icon-hover.jp-icon-alt :hover .jp-icon-accent4-hover[stroke]{stroke:var(--jp-inverse-layout-color4)}.jp-IFrame{width:100%;height:100%}.jp-IFrame>iframe{border:0}body.lm-mod-override-cursor .jp-IFrame{position:relative}body.lm-mod-override-cursor .jp-IFrame::before{content:'';position:absolute;top:0;left:0;right:0;bottom:0;background:transparent}.jp-HoverBox{position:fixed}.jp-FormGroup-content fieldset{border:0;padding:0;min-width:0;width:100%}.jp-FormGroup-content fieldset .jp-inputFieldWrapper input,.jp-FormGroup-content fieldset .jp-inputFieldWrapper select,.jp-FormGroup-content fieldset .jp-inputFieldWrapper textarea{font-size:var(--jp-content-font-size2);border-color:var(--jp-input-border-color);border-style:solid;border-radius:var(--jp-border-radius);border-width:1px;padding:6px 8px;background:0;color:var(--jp-ui-font-color0);height:inherit}.jp-FormGroup-content fieldset input[type='checkbox']{position:relative;top:2px;margin-left:0}.jp-FormGroup-content button.jp-mod-styled{cursor:pointer}.jp-FormGroup-content .checkbox label{cursor:pointer;font-size:var(--jp-content-font-size1)}.jp-FormGroup-content .jp-root>fieldset>legend{display:none}.jp-FormGroup-content .jp-root>fieldset>p{display:none}.jp-FormGroup-content fieldset input:focus,.jp-FormGroup-content fieldset select:focus{-moz-outline-radius:unset;outline:var(--jp-border-width) solid var(--md-blue-500);outline-offset:-1px;box-shadow:inset 0 0 4px var(--md-blue-300)}.jp-FormGroup-content fieldset input:hover:not(:focus),.jp-FormGroup-content fieldset select:hover:not(:focus){background-color:var(--jp-border-color2)}.jp-FormGroup-content .checkbox .field-description{display:none}.jp-FormGroup-content #root__description{display:none}.jp-FormGroup-content .jp-modifiedIndicator{width:5px;background-color:var(--jp-brand-color2);margin-top:0;margin-left:calc(var(--jp-private-settingeditor-modifier-indent) * -1);flex-shrink:0}.jp-FormGroup-content .jp-modifiedIndicator.jp-errorIndicator{background-color:var(--jp-error-color0);margin-right:.5em}.jp-arrayFieldWrapper legend{font-size:var(--jp-content-font-size2);color:var(--jp-ui-font-color0);flex-basis:100%;padding:4px 0;font-weight:var(--jp-content-heading-font-weight);border-bottom:1px solid var(--jp-border-color2)}.jp-arrayFieldWrapper .field-description{padding:4px 0;white-space:pre-wrap}.jp-arrayFieldWrapper .array-item{width:100%;border:1px solid var(--jp-border-color2);border-radius:4px;margin:4px}.jp-ArrayOperations{display:flex;margin-left:8px}.jp-ArrayOperationsButton{margin:2px}.jp-ArrayOperationsButton .jp-icon3[fill]{fill:var(--jp-ui-font-color0)}button.jp-ArrayOperationsButton.jp-mod-styled:disabled{cursor:not-allowed;opacity:.5}.jp-FormGroup-content .validationErrors{color:var(--jp-error-color0)}.jp-FormGroup-content .panel.errors{display:none}.jp-FormGroup-contentNormal{display:flex;align-items:center;flex-wrap:wrap}.jp-FormGroup-contentNormal .jp-FormGroup-contentItem{margin-left:7px;color:var(--jp-ui-font-color0)}.jp-FormGroup-contentNormal .jp-FormGroup-description{flex-basis:100%;padding:4px 7px}.jp-FormGroup-contentNormal .jp-FormGroup-default{flex-basis:100%;padding:4px 7px}.jp-FormGroup-contentNormal .jp-FormGroup-fieldLabel{font-size:var(--jp-content-font-size1);font-weight:normal;min-width:120px}.jp-FormGroup-contentNormal fieldset:not(:first-child){margin-left:7px}.jp-FormGroup-contentNormal .field-array-of-string .array-item{display:flex;align-items:center;flex-wrap:wrap}.jp-FormGroup-contentNormal .jp-objectFieldWrapper .form-group{padding:2px 8px 2px var(--jp-private-settingeditor-modifier-indent);margin-top:2px}.jp-FormGroup-content.jp-FormGroup-contentCompact{width:100%}.jp-FormGroup-contentCompact .form-group{display:flex;padding:.5em .2em .5em 0}.jp-FormGroup-contentCompact .jp-FormGroup-compactTitle .jp-FormGroup-description{font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color2)}.jp-FormGroup-contentCompact .jp-FormGroup-fieldLabel{padding-bottom:.3em}.jp-FormGroup-contentCompact .jp-inputFieldWrapper .form-control{width:100%;box-sizing:border-box}.jp-FormGroup-contentCompact .jp-arrayFieldWrapper .jp-FormGroup-compactTitle{padding-bottom:7px}.jp-FormGroup-contentCompact .jp-objectFieldWrapper .jp-objectFieldWrapper .form-group{padding:2px 8px 2px var(--jp-private-settingeditor-modifier-indent);margin-top:2px}.jp-FormGroup-contentCompact ul.error-detail{margin-block-start:.5em;margin-block-end:.5em;padding-inline-start:1em}
.jp-SidePanel{display:flex;flex-direction:column;min-width:var(--jp-sidebar-min-width);overflow-y:auto;color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1)}.jp-SidePanel-header{flex:0 0 auto;display:flex;border-bottom:var(--jp-border-width) solid var(--jp-border-color2);font-size:var(--jp-ui-font-size0);font-weight:600;letter-spacing:1px;margin:0;padding:2px;text-transform:uppercase}.jp-SidePanel-toolbar{flex:0 0 auto}.jp-SidePanel-content{flex:1 1 auto}.jp-SidePanel-toolbar,.jp-AccordionPanel-toolbar{height:var(--jp-private-toolbar-height)}.jp-SidePanel-toolbar.jp-Toolbar-micro{display:none}.lm-AccordionPanel .jp-AccordionPanel-title{box-sizing:border-box;line-height:25px;margin:0;display:flex;align-items:center;background:var(--jp-layout-color1);color:var(--jp-ui-font-color1);border-bottom:var(--jp-border-width) solid var(--jp-toolbar-border-color);box-shadow:var(--jp-toolbar-box-shadow);font-size:var(--jp-ui-font-size0)}.jp-AccordionPanel-title{cursor:pointer;user-select:none;-moz-user-select:none;-webkit-user-select:none;text-transform:uppercase}.lm-AccordionPanel[data-orientation='horizontal']>.jp-AccordionPanel-title{display:block;transform-origin:top left;transform:rotate(-90deg) translate(-100%)}.jp-AccordionPanel-title .lm-AccordionPanel-titleLabel{user-select:none;text-overflow:ellipsis;white-space:nowrap;overflow:hidden}.jp-AccordionPanel-title .lm-AccordionPanel-titleCollapser{transform:rotate(-90deg);margin:auto 0;height:16px}.jp-AccordionPanel-title.lm-mod-expanded .lm-AccordionPanel-titleCollapser{transform:rotate(0)}.lm-AccordionPanel .jp-AccordionPanel-toolbar{background:0;box-shadow:none;border:0;margin-left:auto}.lm-AccordionPanel .lm-SplitPanel-handle:hover{background:var(--jp-layout-color3)}.jp-text-truncated{overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.jp-Spinner{position:absolute;display:flex;justify-content:center;align-items:center;z-index:10;left:0;top:0;width:100%;height:100%;background:var(--jp-layout-color0);outline:0}.jp-SpinnerContent{font-size:10px;margin:50px auto;text-indent:-9999em;width:3em;height:3em;border-radius:50%;background:var(--jp-brand-color3);background:linear-gradient(to right,#f37626 10%,rgba(255,255,255,0) 42%);position:relative;animation:load3 1s infinite linear,fadeIn 1s}.jp-SpinnerContent::before{width:50%;height:50%;background:#f37626;border-radius:100% 0 0;position:absolute;top:0;left:0;content:''}.jp-SpinnerContent::after{background:var(--jp-layout-color0);width:75%;height:75%;border-radius:50%;content:'';margin:auto;position:absolute;top:0;left:0;bottom:0;right:0}@keyframes fadeIn{0%{opacity:0}100%{opacity:1}}@keyframes load3{0%{transform:rotate(0)}100%{transform:rotate(360deg)}}button.jp-mod-styled{font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);border:0;box-sizing:border-box;text-align:center;line-height:32px;height:32px;padding:0 12px;letter-spacing:.8px;outline:0;appearance:none;-webkit-appearance:none;-moz-appearance:none}input.jp-mod-styled{background:var(--jp-input-background);height:28px;box-sizing:border-box;border:var(--jp-border-width) solid var(--jp-border-color1);padding-left:7px;padding-right:7px;font-size:var(--jp-ui-font-size2);color:var(--jp-ui-font-color0);outline:0;appearance:none;-webkit-appearance:none;-moz-appearance:none}input[type='checkbox'].jp-mod-styled{appearance:checkbox;-webkit-appearance:checkbox;-moz-appearance:checkbox;height:auto}input.jp-mod-styled:focus{border:var(--jp-border-width) solid var(--md-blue-500);box-shadow:inset 0 0 4px var(--md-blue-300)}.jp-select-wrapper{display:flex;position:relative;flex-direction:column;padding:1px;background-color:var(--jp-layout-color1);box-sizing:border-box;margin-bottom:12px}.jp-select-wrapper:not(.multiple){height:28px}.jp-select-wrapper.jp-mod-focused select.jp-mod-styled{border:var(--jp-border-width) solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow);background-color:var(--jp-input-active-background)}select.jp-mod-styled:hover{cursor:pointer;color:var(--jp-ui-font-color0);background-color:var(--jp-input-hover-background);box-shadow:inset 0 0 1px rgba(0,0,0,0.5)}select.jp-mod-styled{flex:1 1 auto;width:100%;font-size:var(--jp-ui-font-size2);background:var(--jp-input-background);color:var(--jp-ui-font-color0);padding:0 25px 0 8px;border:var(--jp-border-width) solid var(--jp-input-border-color);border-radius:0;outline:0;appearance:none;-webkit-appearance:none;-moz-appearance:none}select.jp-mod-styled:not([multiple]){height:32px}select.jp-mod-styled[multiple]{max-height:200px;overflow-y:auto}.jp-switch{display:flex;align-items:center;padding-left:4px;padding-right:4px;font-size:var(--jp-ui-font-size1);background-color:transparent;color:var(--jp-ui-font-color1);border:0;height:20px}.jp-switch:hover{background-color:var(--jp-layout-color2)}.jp-switch-label{margin-right:5px;font-family:var(--jp-ui-font-family)}
.jp-switch-track{cursor:pointer;background-color:var(--jp-switch-color,var(--jp-border-color1));-webkit-transition:.4s;transition:.4s;border-radius:34px;height:16px;width:35px;position:relative}.jp-switch-track::before{content:'';position:absolute;height:10px;width:10px;margin:3px;left:0;background-color:var(--jp-ui-inverse-font-color1);-webkit-transition:.4s;transition:.4s;border-radius:50%}.jp-switch[aria-checked='true'] .jp-switch-track{background-color:var(--jp-switch-true-position-color,var(--jp-warn-color0))}.jp-switch[aria-checked='true'] .jp-switch-track::before{left:19px}:root{--jp-private-toolbar-height:calc(28px+var(--jp-border-width))}.jp-Toolbar{color:var(--jp-ui-font-color1);flex:0 0 auto;display:flex;flex-direction:row;border-bottom:var(--jp-border-width) solid var(--jp-toolbar-border-color);box-shadow:var(--jp-toolbar-box-shadow);background:var(--jp-toolbar-background);min-height:var(--jp-toolbar-micro-height);padding:2px;z-index:8;overflow-x:hidden}.jp-Toolbar>.jp-Toolbar-item.jp-Toolbar-spacer{flex-grow:1;flex-shrink:1}.jp-Toolbar-item.jp-Toolbar-kernelStatus{display:inline-block;width:32px;background-repeat:no-repeat;background-position:center;background-size:16px}.jp-Toolbar>.jp-Toolbar-item{flex:0 0 auto;display:flex;padding-left:1px;padding-right:1px;font-size:var(--jp-ui-font-size1);line-height:var(--jp-private-toolbar-height);height:100%}div.jp-ToolbarButton{color:transparent;border:0;box-sizing:border-box;outline:0;appearance:none;-webkit-appearance:none;-moz-appearance:none;padding:0;margin:0}button.jp-ToolbarButtonComponent{background:var(--jp-layout-color1);border:0;box-sizing:border-box;outline:0;appearance:none;-webkit-appearance:none;-moz-appearance:none;padding:0 6px;margin:0;height:24px;border-radius:var(--jp-border-radius);display:flex;align-items:center;text-align:center;font-size:14px;min-width:unset;min-height:unset}button.jp-ToolbarButtonComponent:disabled{opacity:.4}button.jp-ToolbarButtonComponent>span{padding:0;flex:0 0 auto}button.jp-ToolbarButtonComponent .jp-ToolbarButtonComponent-label{font-size:var(--jp-ui-font-size1);line-height:100%;padding-left:2px;color:var(--jp-ui-font-color1);font-family:var(--jp-ui-font-family)}#jp-main-dock-panel[data-mode='single-document'] .jp-MainAreaWidget>.jp-Toolbar.jp-Toolbar-micro{padding:0;min-height:0}#jp-main-dock-panel[data-mode='single-document'] .jp-MainAreaWidget>.jp-Toolbar{border:0;box-shadow:none}.jp-WindowedPanel-outer{position:relative;overflow-y:auto}.jp-WindowedPanel-inner{position:relative}.jp-WindowedPanel-window{position:absolute;left:0;right:0;overflow:visible}body{color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1)}a{text-decoration:unset;color:unset}a:hover{text-decoration:unset;color:unset}.jp-Dialog-content a{text-decoration:revert;color:var(--jp-content-link-color)}.jp-Dialog-content a:hover{text-decoration:revert}.jp-Button{color:var(--jp-ui-font-color2);border-radius:var(--jp-border-radius);padding:0 12px;font-size:var(--jp-ui-font-size1);display:inline-flex;flex-direction:row;border:0;cursor:pointer;align-items:center;justify-content:center;text-align:left;vertical-align:middle;min-height:30px;min-width:30px}.jp-Button:disabled{cursor:not-allowed}.jp-Button:empty{padding:0!important}.jp-Button.jp-mod-small{min-height:24px;min-width:24px;font-size:12px;padding:0 7px}.jp-Button.jp-mod-minimal:hover{background-color:var(--jp-layout-color2)}.jp-Button.jp-mod-minimal{background:0}.jp-InputGroup{display:block;position:relative}.jp-InputGroup input{box-sizing:border-box;border:0;border-radius:0;background-color:transparent;color:var(--jp-ui-font-color0);box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color);padding-bottom:0;padding-top:0;padding-left:10px;padding-right:28px;position:relative;width:100%;-webkit-appearance:none;-moz-appearance:none;appearance:none;font-size:14px;font-weight:400;height:30px;line-height:30px;outline:0;vertical-align:middle}.jp-InputGroup input:focus{box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-active-box-shadow-color),inset 0 0 0 3px var(--jp-input-active-box-shadow-color)}.jp-InputGroup input:disabled{cursor:not-allowed;resize:block;background-color:var(--jp-layout-color2);color:var(--jp-ui-font-color2)}.jp-InputGroup input:disabled ~ span{cursor:not-allowed;color:var(--jp-ui-font-color2)}.jp-InputGroup input::placeholder,input::placeholder{color:var(--jp-ui-font-color2)}.jp-InputGroupAction{position:absolute;bottom:1px;right:0;padding:6px}.jp-HTMLSelect.jp-DefaultStyle select{background-color:initial;border:0;border-radius:0;box-shadow:none;color:var(--jp-ui-font-color0);display:block;font-size:var(--jp-ui-font-size1);font-family:var(--jp-ui-font-family);height:24px;line-height:14px;padding:0 25px 0 10px;text-align:left;-moz-appearance:none;-webkit-appearance:none}.jp-HTMLSelect.jp-DefaultStyle select:disabled{background-color:var(--jp-layout-color2);color:var(--jp-ui-font-color2);cursor:not-allowed;resize:block}
.jp-HTMLSelect.jp-DefaultStyle select:disabled ~ span{cursor:not-allowed}.jp-HTMLSelect.jp-DefaultStyle select:hover,.jp-HTMLSelect.jp-DefaultStyle select>option{background-color:var(--jp-layout-color2);color:var(--jp-ui-font-color0)}select{box-sizing:border-box}.jp-StatusBar-Widget{display:flex;align-items:center;background:var(--jp-layout-color2);min-height:var(--jp-statusbar-height);justify-content:space-between;padding:0 10px}.jp-StatusBar-Left{display:flex;align-items:center;flex-direction:row}.jp-StatusBar-Middle{display:flex;align-items:center}.jp-StatusBar-Right{display:flex;align-items:center;flex-direction:row-reverse}.jp-StatusBar-Item{max-height:var(--jp-statusbar-height);margin:0 2px;height:var(--jp-statusbar-height);white-space:nowrap;text-overflow:ellipsis;color:var(--jp-ui-font-color1);padding:0 6px}.jp-mod-highlighted:hover{background-color:var(--jp-layout-color3)}.jp-mod-clicked{background-color:var(--jp-brand-color1)}.jp-mod-clicked:hover{background-color:var(--jp-brand-color0)}.jp-mod-clicked .jp-StatusBar-TextItem{color:var(--jp-ui-inverse-font-color1)}.jp-StatusBar-HoverItem{box-shadow:'0px 4px 4px rgba(0, 0, 0, 0.25)'}.jp-StatusBar-TextItem{font-size:var(--jp-ui-font-size1);font-family:var(--jp-ui-font-family);line-height:24px;color:var(--jp-ui-font-color1)}.jp-StatusBar-GroupItem{display:flex;align-items:center;flex-direction:row}.jp-Statusbar-ProgressCircle svg{display:block;margin:0 auto;width:16px;height:24px;align-self:normal}.jp-Statusbar-ProgressCircle path{fill:var(--jp-inverse-layout-color3)}.jp-Statusbar-ProgressBar-progress-bar{height:10px;width:100px;border:solid .25px var(--jp-brand-color2);border-radius:3px;overflow:hidden;align-self:center}.jp-Statusbar-ProgressBar-progress-bar>div{background-color:var(--jp-brand-color2);background-image:linear-gradient(-45deg,rgba(255,255,255,0.2) 25%,transparent 25%,transparent 50%,rgba(255,255,255,0.2) 50%,rgba(255,255,255,0.2) 75%,transparent 75%,transparent);background-size:40px 40px;float:left;width:0;height:100%;font-size:12px;line-height:14px;color:#fff;text-align:center;animation:jp-Statusbar-ExecutionTime-progress-bar 2s linear infinite}.jp-Statusbar-ProgressBar-progress-bar p{color:var(--jp-ui-font-color1);font-family:var(--jp-ui-font-family);font-size:var(--jp-ui-font-size1);line-height:10px;width:100px}@keyframes jp-Statusbar-ExecutionTime-progress-bar{0%{background-position:0 0}100%{background-position:40px 40px}}:root{--jp-private-commandpalette-search-height:28px}.lm-CommandPalette{padding-bottom:0;color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1)}.jp-ModalCommandPalette{position:absolute;z-index:10000;top:38px;left:30%;margin:0;padding:4px;width:40%;box-shadow:var(--jp-elevation-z4);border-radius:4px;background:var(--jp-layout-color0)}.jp-ModalCommandPalette .lm-CommandPalette{max-height:40vh}.jp-ModalCommandPalette .lm-CommandPalette .lm-close-icon::after{display:none}.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-header{display:none}.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item{margin-left:4px;margin-right:4px}.jp-ModalCommandPalette .lm-CommandPalette .lm-CommandPalette-item.lm-mod-disabled{display:none}.lm-CommandPalette-search{padding:4px;background-color:var(--jp-layout-color1);z-index:2}.lm-CommandPalette-wrapper{overflow:overlay;padding:0 9px;background-color:var(--jp-input-active-background);height:30px;box-shadow:inset 0 0 0 var(--jp-border-width) var(--jp-input-border-color)}.lm-CommandPalette.lm-mod-focused .lm-CommandPalette-wrapper{box-shadow:inset 0 0 0 1px var(--jp-input-active-box-shadow-color),inset 0 0 0 3px var(--jp-input-active-box-shadow-color)}.jp-SearchIconGroup{color:white;background-color:var(--jp-brand-color1);position:absolute;top:4px;right:4px;padding:5px 5px 1px}.jp-SearchIconGroup svg{height:20px;width:20px}.jp-SearchIconGroup .jp-icon3[fill]{fill:var(--jp-layout-color0)}.lm-CommandPalette-input{background:transparent;width:calc(100% - 18px);float:left;border:0;outline:0;font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);line-height:var(--jp-private-commandpalette-search-height)}.lm-CommandPalette-input::-webkit-input-placeholder,.lm-CommandPalette-input::-moz-placeholder,.lm-CommandPalette-input:-ms-input-placeholder{color:var(--jp-ui-font-color2);font-size:var(--jp-ui-font-size1)}.lm-CommandPalette-header:first-child{margin-top:0}.lm-CommandPalette-header{border-bottom:solid var(--jp-border-width) var(--jp-border-color2);color:var(--jp-ui-font-color1);cursor:pointer;display:flex;font-size:var(--jp-ui-font-size0);font-weight:600;letter-spacing:1px;margin-top:8px;padding:8px 0 8px 12px;text-transform:uppercase}.lm-CommandPalette-header.lm-mod-active{background:var(--jp-layout-color2)}.lm-CommandPalette-header>mark{background-color:transparent;font-weight:bold;color:var(--jp-ui-font-color1)}.lm-CommandPalette-item{padding:4px 12px 4px 4px;color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);font-weight:400;display:flex}
.lm-CommandPalette-item.lm-mod-disabled{color:var(--jp-ui-font-color2)}.lm-CommandPalette-item.lm-mod-active{color:var(--jp-ui-inverse-font-color1);background:var(--jp-brand-color1)}.lm-CommandPalette-item.lm-mod-active .lm-CommandPalette-itemLabel>mark{color:var(--jp-ui-inverse-font-color0)}.lm-CommandPalette-item.lm-mod-active .jp-icon-selectable[fill]{fill:var(--jp-layout-color0)}.lm-CommandPalette-item.lm-mod-active:hover:not(.lm-mod-disabled){color:var(--jp-ui-inverse-font-color1);background:var(--jp-brand-color1)}.lm-CommandPalette-item:hover:not(.lm-mod-active):not(.lm-mod-disabled){background:var(--jp-layout-color2)}.lm-CommandPalette-itemContent{overflow:hidden}.lm-CommandPalette-itemLabel>mark{color:var(--jp-ui-font-color0);background-color:transparent;font-weight:bold}.lm-CommandPalette-item.lm-mod-disabled mark{color:var(--jp-ui-font-color2)}.lm-CommandPalette-item .lm-CommandPalette-itemIcon{margin:0 4px 0 0;position:relative;width:16px;top:2px;flex:0 0 auto}.lm-CommandPalette-item.lm-mod-disabled .lm-CommandPalette-itemIcon{opacity:.6}.lm-CommandPalette-item .lm-CommandPalette-itemShortcut{flex:0 0 auto}.lm-CommandPalette-itemCaption{display:none}.lm-CommandPalette-content{background-color:var(--jp-layout-color1)}.lm-CommandPalette-content:empty::after{content:'No results';margin:auto;margin-top:20px;width:100px;display:block;font-size:var(--jp-ui-font-size2);font-family:var(--jp-ui-font-family);font-weight:lighter}.lm-CommandPalette-emptyMessage{text-align:center;margin-top:24px;line-height:1.32;padding:0 8px;color:var(--jp-content-font-color3)}.jp-Dialog{position:absolute;z-index:10000;display:flex;flex-direction:column;align-items:center;justify-content:center;top:0;left:0;margin:0;padding:0;width:100%;height:100%;background:var(--jp-dialog-background)}.jp-Dialog-content{display:flex;flex-direction:column;margin-left:auto;margin-right:auto;background:var(--jp-layout-color1);padding:24px 24px 12px;min-width:300px;min-height:150px;max-width:1000px;max-height:500px;box-sizing:border-box;box-shadow:var(--jp-elevation-z20);word-wrap:break-word;border-radius:var(--jp-border-radius);font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color1);resize:both}.jp-Dialog-content.jp-Dialog-content-small{max-width:500px}.jp-Dialog-button{overflow:visible}button.jp-Dialog-button:focus{outline:1px solid var(--jp-brand-color1);outline-offset:4px;-moz-outline-radius:0}button.jp-Dialog-button:focus::-moz-focus-inner{border:0}button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus,button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus,button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus{outline-offset:4px;-moz-outline-radius:0}button.jp-Dialog-button.jp-mod-styled.jp-mod-accept:focus{outline:1px solid var(--jp-accept-color-normal,var(--jp-brand-color1))}button.jp-Dialog-button.jp-mod-styled.jp-mod-warn:focus{outline:1px solid var(--jp-warn-color-normal,var(--jp-error-color1))}button.jp-Dialog-button.jp-mod-styled.jp-mod-reject:focus{outline:1px solid var(--jp-reject-color-normal,var(--md-grey-600))}button.jp-Dialog-close-button{padding:0;height:100%;min-width:unset;min-height:unset}.jp-Dialog-header{display:flex;justify-content:space-between;flex:0 0 auto;padding-bottom:12px;font-size:var(--jp-ui-font-size3);font-weight:400;color:var(--jp-ui-font-color1)}.jp-Dialog-body{display:flex;flex-direction:column;flex:1 1 auto;font-size:var(--jp-ui-font-size1);background:var(--jp-layout-color1);color:var(--jp-ui-font-color1);overflow:auto}.jp-Dialog-footer{display:flex;flex-direction:row;justify-content:flex-end;align-items:center;flex:0 0 auto;margin-left:-12px;margin-right:-12px;padding:12px}.jp-Dialog-checkbox{padding-right:5px}.jp-Dialog-checkbox>input:focus-visible{outline:1px solid var(--jp-input-active-border-color);outline-offset:1px}.jp-Dialog-spacer{flex:1 1 auto}.jp-Dialog-title{overflow:hidden;white-space:nowrap;text-overflow:ellipsis}.jp-Dialog-body>.jp-select-wrapper{width:100%}.jp-Dialog-body>button{padding:0 16px}.jp-Dialog-body>label{line-height:1.4;color:var(--jp-ui-font-color0)}.jp-Dialog-button.jp-mod-styled:not(:last-child){margin-right:12px}.jp-Input-Boolean-Dialog{flex-direction:row-reverse;align-items:end;width:100%}.jp-Input-Boolean-Dialog>label{flex:1 1 auto}.jp-MainAreaWidget>:focus{outline:0}.jp-MainAreaWidget .jp-MainAreaWidget-error{padding:6px}.jp-MainAreaWidget .jp-MainAreaWidget-error>pre{width:auto;padding:10px;background:var(--jp-error-color3);border:var(--jp-border-width) solid var(--jp-error-color1);border-radius:var(--jp-border-radius);color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);white-space:pre-wrap;word-wrap:break-word}:root{--md-red-50:#ffebee;--md-red-100:#ffcdd2;--md-red-200:#ef9a9a;--md-red-300:#e57373;--md-red-400:#ef5350;--md-red-500:#f44336;--md-red-600:#e53935;--md-red-700:#d32f2f;--md-red-800:#c62828;--md-red-900:#b71c1c;--md-red-A100:#ff8a80;--md-red-A200:#ff5252;--md-red-A400:#ff1744;--md-red-A700:#d50000;--md-pink-50:#fce4ec;--md-pink-100:#f8bbd0;--md-pink-200:#f48fb1;--md-pink-300:#f06292;--md-pink-400:#ec407a;--md-pink-500:#e91e63;--md-pink-600:#d81b60;--md-pink-700:#c2185b;--md-pink-800:#ad1457;--md-pink-900:#880e4f;--md-pink-A100:#ff80ab;--md-pink-A200:#ff4081;--md-pink-A400:#f50057;--md-pink-A700:#c51162;--md-purple-50:#f3e5f5;--md-purple-100:#e1bee7;--md-purple-200:#ce93d8;--md-purple-300:#ba68c8;--md-purple-400:#ab47bc;--md-purple-500:#9c27b0;--md-purple-600:#8e24aa;--md-purple-700:#7b1fa2;--md-purple-800:#6a1b9a;--md-purple-900:#4a148c;--md-purple-A100:#ea80fc;--md-purple-A200:#e040fb;--md-purple-A400:#d500f9;--md-purple-A700:#a0f;--md-deep-purple-50:#ede7f6;--md-deep-purple-100:#d1c4e9;--md-deep-purple-200:#b39ddb;--md-deep-purple-300:#9575cd;--md-deep-purple-400:#7e57c2;--md-deep-purple-500:#673ab7;--md-deep-purple-600:#5e35b1;--md-deep-purple-700:#512da8;--md-deep-purple-800:#4527a0;--md-deep-purple-900:#311b92;--md-deep-purple-A100:#b388ff;--md-deep-purple-A200:#7c4dff;--md-deep-purple-A400:#651fff;--md-deep-purple-A700:#6200ea;--md-indigo-50:#e8eaf6;--md-indigo-100:#c5cae9;--md-indigo-200:#9fa8da;--md-indigo-300:#7986cb;--md-indigo-400:#5c6bc0;--md-indigo-500:#3f51b5;--md-indigo-600:#3949ab;--md-indigo-700:#303f9f;--md-indigo-800:#283593;--md-indigo-900:#1a237e;--md-indigo-A100:#8c9eff;--md-indigo-A200:#536dfe;--md-indigo-A400:#3d5afe;--md-indigo-A700:#304ffe;--md-blue-50:#e3f2fd;--md-blue-100:#bbdefb;--md-blue-200:#90caf9;--md-blue-300:#64b5f6;--md-blue-400:#42a5f5;--md-blue-500:#2196f3;--md-blue-600:#1e88e5;--md-blue-700:#1976d2;--md-blue-800:#1565c0;--md-blue-900:#0d47a1;--md-blue-A100:#82b1ff;--md-blue-A200:#448aff;--md-blue-A400:#2979ff;--md-blue-A700:#2962ff;--md-light-blue-50:#e1f5fe;--md-light-blue-100:#b3e5fc;--md-light-blue-200:#81d4fa;--md-light-blue-300:#4fc3f7;--md-light-blue-400:#29b6f6;--md-light-blue-500:#03a9f4;--md-light-blue-600:#039be5;--md-light-blue-700:#0288d1;--md-light-blue-800:#0277bd;--md-light-blue-900:#01579b;--md-light-blue-A100:#80d8ff;--md-light-blue-A200:#40c4ff;--md-light-blue-A400:#00b0ff;--md-light-blue-A700:#0091ea;--md-cyan-50:#e0f7fa;--md-cyan-100:#b2ebf2;--md-cyan-200:#80deea;--md-cyan-300:#4dd0e1;--md-cyan-400:#26c6da;--md-cyan-500:#00bcd4;--md-cyan-600:#00acc1;--md-cyan-700:#0097a7;--md-cyan-800:#00838f;--md-cyan-900:#006064;--md-cyan-A100:#84ffff;--md-cyan-A200:#18ffff;--md-cyan-A400:#00e5ff;--md-cyan-A700:#00b8d4;--md-teal-50:#e0f2f1;--md-teal-100:#b2dfdb;--md-teal-200:#80cbc4;--md-teal-300:#4db6ac;--md-teal-400:#26a69a;--md-teal-500:#009688;--md-teal-600:#00897b;--md-teal-700:#00796b;--md-teal-800:#00695c;--md-teal-900:#004d40;--md-teal-A100:#a7ffeb;--md-teal-A200:#64ffda;--md-teal-A400:#1de9b6;--md-teal-A700:#00bfa5;--md-green-50:#e8f5e9;--md-green-100:#c8e6c9;--md-green-200:#a5d6a7;--md-green-300:#81c784;--md-green-400:#66bb6a;--md-green-500:#4caf50;--md-green-600:#43a047;--md-green-700:#388e3c;--md-green-800:#2e7d32;--md-green-900:#1b5e20;--md-green-A100:#b9f6ca;--md-green-A200:#69f0ae;--md-green-A400:#00e676;--md-green-A700:#00c853;--md-light-green-50:#f1f8e9;--md-light-green-100:#dcedc8;--md-light-green-200:#c5e1a5;--md-light-green-300:#aed581;--md-light-green-400:#9ccc65;--md-light-green-500:#8bc34a;--md-light-green-600:#7cb342;--md-light-green-700:#689f38;--md-light-green-800:#558b2f;--md-light-green-900:#33691e;--md-light-green-A100:#ccff90;--md-light-green-A200:#b2ff59;--md-light-green-A400:#76ff03;--md-light-green-A700:#64dd17;--md-lime-50:#f9fbe7;--md-lime-100:#f0f4c3;--md-lime-200:#e6ee9c;--md-lime-300:#dce775;--md-lime-400:#d4e157;--md-lime-500:#cddc39;--md-lime-600:#c0ca33;--md-lime-700:#afb42b;--md-lime-800:#9e9d24;--md-lime-900:#827717;--md-lime-A100:#f4ff81;--md-lime-A200:#eeff41;--md-lime-A400:#c6ff00;--md-lime-A700:#aeea00;--md-yellow-50:#fffde7;--md-yellow-100:#fff9c4;--md-yellow-200:#fff59d;--md-yellow-300:#fff176;--md-yellow-400:#ffee58;--md-yellow-500:#ffeb3b;--md-yellow-600:#fdd835;--md-yellow-700:#fbc02d;--md-yellow-800:#f9a825;--md-yellow-900:#f57f17;--md-yellow-A100:#ffff8d;--md-yellow-A200:#ff0;--md-yellow-A400:#ffea00;--md-yellow-A700:#ffd600;--md-amber-50:#fff8e1;--md-amber-100:#ffecb3;--md-amber-200:#ffe082;--md-amber-300:#ffd54f;--md-amber-400:#ffca28;--md-amber-500:#ffc107;--md-amber-600:#ffb300;--md-amber-700:#ffa000;--md-amber-800:#ff8f00;--md-amber-900:#ff6f00;--md-amber-A100:#ffe57f;--md-amber-A200:#ffd740;--md-amber-A400:#ffc400;--md-amber-A700:#ffab00;--md-orange-50:#fff3e0;--md-orange-100:#ffe0b2;--md-orange-200:#ffcc80;--md-orange-300:#ffb74d;--md-orange-400:#ffa726;--md-orange-500:#ff9800;--md-orange-600:#fb8c00;--md-orange-700:#f57c00;--md-orange-800:#ef6c00;--md-orange-900:#e65100;--md-orange-A100:#ffd180;--md-orange-A200:#ffab40;--md-orange-A400:#ff9100;--md-orange-A700:#ff6d00;--md-deep-orange-50:#fbe9e7;--md-deep-orange-100:#ffccbc;--md-deep-orange-200:#ffab91;--md-deep-orange-300:#ff8a65;--md-deep-orange-400:#ff7043;--md-deep-orange-500:#ff5722;--md-deep-orange-600:#f4511e;--md-deep-orange-700:#e64a19;--md-deep-orange-800:#d84315;--md-deep-orange-900:#bf360c;--md-deep-orange-A100:#ff9e80;--md-deep-orange-A200:#ff6e40;--md-deep-orange-A400:#ff3d00;--md-deep-orange-A700:#dd2c00;--md-brown-50:#efebe9;--md-brown-100:#d7ccc8;--md-brown-200:#bcaaa4;--md-brown-300:#a1887f;--md-brown-400:#8d6e63;--md-brown-500:#795548;--md-brown-600:#6d4c41;--md-brown-700:#5d4037;--md-brown-800:#4e342e;--md-brown-900:#3e2723;--md-grey-50:#fafafa;--md-grey-100:#f5f5f5;--md-grey-200:#eee;--md-grey-300:#e0e0e0;--md-grey-400:#bdbdbd;--md-grey-500:#9e9e9e;--md-grey-600:#757575;--md-grey-700:#616161;--md-grey-800:#424242;--md-grey-900:#212121;--md-blue-grey-50:#eceff1;--md-blue-grey-100:#cfd8dc;--md-blue-grey-200:#b0bec5;--md-blue-grey-300:#90a4ae;--md-blue-grey-400:#78909c;--md-blue-grey-500:#607d8b;--md-blue-grey-600:#546e7a;--md-blue-grey-700:#455a64;--md-blue-grey-800:#37474f;--md-blue-grey-900:#263238}
:root{--jp-private-code-span-padding:calc((var(--jp-code-line-height) - 1) * var(--jp-code-font-size) / 2)}.jp-RenderedText{text-align:left;padding-left:var(--jp-code-padding);line-height:var(--jp-code-line-height);font-family:var(--jp-code-font-family)}.jp-RenderedText pre,.jp-RenderedJavaScript pre,.jp-RenderedHTMLCommon pre{color:var(--jp-content-font-color1);font-size:var(--jp-code-font-size);border:0;margin:0;padding:0}.jp-RenderedText pre a:link{text-decoration:none;color:var(--jp-content-link-color)}.jp-RenderedText pre a:hover{text-decoration:underline;color:var(--jp-content-link-color)}.jp-RenderedText pre a:visited{text-decoration:none;color:var(--jp-content-link-color)}.jp-RenderedText pre .ansi-black-fg{color:#3e424d}.jp-RenderedText pre .ansi-red-fg{color:#e75c58}.jp-RenderedText pre .ansi-green-fg{color:#00a250}.jp-RenderedText pre .ansi-yellow-fg{color:#ddb62b}.jp-RenderedText pre .ansi-blue-fg{color:#208ffb}.jp-RenderedText pre .ansi-magenta-fg{color:#d160c4}.jp-RenderedText pre .ansi-cyan-fg{color:#60c6c8}.jp-RenderedText pre .ansi-white-fg{color:#c5c1b4}.jp-RenderedText pre .ansi-black-bg{background-color:#3e424d;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-red-bg{background-color:#e75c58;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-green-bg{background-color:#00a250;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-yellow-bg{background-color:#ddb62b;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-blue-bg{background-color:#208ffb;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-magenta-bg{background-color:#d160c4;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-cyan-bg{background-color:#60c6c8;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-white-bg{background-color:#c5c1b4;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-black-intense-fg{color:#282c36}.jp-RenderedText pre .ansi-red-intense-fg{color:#b22b31}.jp-RenderedText pre .ansi-green-intense-fg{color:#007427}.jp-RenderedText pre .ansi-yellow-intense-fg{color:#b27d12}.jp-RenderedText pre .ansi-blue-intense-fg{color:#0065ca}.jp-RenderedText pre .ansi-magenta-intense-fg{color:#a03196}.jp-RenderedText pre .ansi-cyan-intense-fg{color:#258f8f}.jp-RenderedText pre .ansi-white-intense-fg{color:#a1a6b2}.jp-RenderedText pre .ansi-black-intense-bg{background-color:#282c36;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-red-intense-bg{background-color:#b22b31;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-green-intense-bg{background-color:#007427;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-yellow-intense-bg{background-color:#b27d12;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-blue-intense-bg{background-color:#0065ca;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-magenta-intense-bg{background-color:#a03196;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-cyan-intense-bg{background-color:#258f8f;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-white-intense-bg{background-color:#a1a6b2;padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-default-inverse-fg{color:var(--jp-ui-inverse-font-color0)}.jp-RenderedText pre .ansi-default-inverse-bg{background-color:var(--jp-inverse-layout-color0);padding:var(--jp-private-code-span-padding) 0}.jp-RenderedText pre .ansi-bold{font-weight:bold}.jp-RenderedText pre .ansi-underline{text-decoration:underline}.jp-RenderedText[data-mime-type='application/vnd.jupyter.stderr']{background:var(--jp-rendermime-error-background);padding-top:var(--jp-code-padding)}.jp-RenderedLatex{color:var(--jp-content-font-color1);font-size:var(--jp-content-font-size1);line-height:var(--jp-content-line-height)}.jp-OutputArea-output.jp-RenderedLatex{padding:var(--jp-code-padding);text-align:left}.jp-RenderedHTMLCommon{color:var(--jp-content-font-color1);font-family:var(--jp-content-font-family);font-size:var(--jp-content-font-size1);line-height:var(--jp-content-line-height);padding-right:20px}.jp-RenderedHTMLCommon em{font-style:italic}.jp-RenderedHTMLCommon strong{font-weight:bold}.jp-RenderedHTMLCommon u{text-decoration:underline}.jp-RenderedHTMLCommon a:link{text-decoration:none;color:var(--jp-content-link-color)}.jp-RenderedHTMLCommon a:hover{text-decoration:underline;color:var(--jp-content-link-color)}.jp-RenderedHTMLCommon a:visited{text-decoration:none;color:var(--jp-content-link-color)}.jp-RenderedHTMLCommon h1,.jp-RenderedHTMLCommon h2,.jp-RenderedHTMLCommon h3,.jp-RenderedHTMLCommon h4,.jp-RenderedHTMLCommon h5,.jp-RenderedHTMLCommon h6{line-height:var(--jp-content-heading-line-height);font-weight:var(--jp-content-heading-font-weight);font-style:normal;margin:var(--jp-content-heading-margin-top) 0 var(--jp-content-heading-margin-bottom) 0}
.jp-RenderedHTMLCommon h1:first-child,.jp-RenderedHTMLCommon h2:first-child,.jp-RenderedHTMLCommon h3:first-child,.jp-RenderedHTMLCommon h4:first-child,.jp-RenderedHTMLCommon h5:first-child,.jp-RenderedHTMLCommon h6:first-child{margin-top:calc(0.5 * var(--jp-content-heading-margin-top))}.jp-RenderedHTMLCommon h1:last-child,.jp-RenderedHTMLCommon h2:last-child,.jp-RenderedHTMLCommon h3:last-child,.jp-RenderedHTMLCommon h4:last-child,.jp-RenderedHTMLCommon h5:last-child,.jp-RenderedHTMLCommon h6:last-child{margin-bottom:calc(0.5 * var(--jp-content-heading-margin-bottom))}.jp-RenderedHTMLCommon h1{font-size:var(--jp-content-font-size5)}.jp-RenderedHTMLCommon h2{font-size:var(--jp-content-font-size4)}.jp-RenderedHTMLCommon h3{font-size:var(--jp-content-font-size3)}.jp-RenderedHTMLCommon h4{font-size:var(--jp-content-font-size2)}.jp-RenderedHTMLCommon h5{font-size:var(--jp-content-font-size1)}.jp-RenderedHTMLCommon h6{font-size:var(--jp-content-font-size0)}.jp-RenderedHTMLCommon ul:not(.list-inline),.jp-RenderedHTMLCommon ol:not(.list-inline){padding-left:2em}.jp-RenderedHTMLCommon ul{list-style:disc}.jp-RenderedHTMLCommon ul ul{list-style:square}.jp-RenderedHTMLCommon ul ul ul{list-style:circle}.jp-RenderedHTMLCommon ol{list-style:decimal}.jp-RenderedHTMLCommon ol ol{list-style:upper-alpha}.jp-RenderedHTMLCommon ol ol ol{list-style:lower-alpha}.jp-RenderedHTMLCommon ol ol ol ol{list-style:lower-roman}.jp-RenderedHTMLCommon ol ol ol ol ol{list-style:decimal}.jp-RenderedHTMLCommon ol,.jp-RenderedHTMLCommon ul{margin-bottom:1em}.jp-RenderedHTMLCommon ul ul,.jp-RenderedHTMLCommon ul ol,.jp-RenderedHTMLCommon ol ul,.jp-RenderedHTMLCommon ol ol{margin-bottom:0}.jp-RenderedHTMLCommon hr{color:var(--jp-border-color2);background-color:var(--jp-border-color1);margin-top:1em;margin-bottom:1em}.jp-RenderedHTMLCommon>pre{margin:1.5em 2em}.jp-RenderedHTMLCommon pre,.jp-RenderedHTMLCommon code{border:0;background-color:var(--jp-layout-color0);color:var(--jp-content-font-color1);font-family:var(--jp-code-font-family);font-size:inherit;line-height:var(--jp-code-line-height);padding:0;white-space:pre-wrap}.jp-RenderedHTMLCommon :not(pre)>code{background-color:var(--jp-layout-color2);padding:1px 5px}.jp-RenderedHTMLCommon table{border-collapse:collapse;border-spacing:0;border:0;color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);table-layout:fixed;margin-left:auto;margin-bottom:1em;margin-right:auto}.jp-RenderedHTMLCommon thead{border-bottom:var(--jp-border-width) solid var(--jp-border-color1);vertical-align:bottom}.jp-RenderedHTMLCommon td,.jp-RenderedHTMLCommon th,.jp-RenderedHTMLCommon tr{vertical-align:middle;padding:.5em;line-height:normal;white-space:normal;max-width:none;border:0}.jp-RenderedMarkdown.jp-RenderedHTMLCommon td,.jp-RenderedMarkdown.jp-RenderedHTMLCommon th{max-width:none}:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon td,:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon th,:not(.jp-RenderedMarkdown).jp-RenderedHTMLCommon tr{text-align:right}.jp-RenderedHTMLCommon th{font-weight:bold}.jp-RenderedHTMLCommon tbody tr:nth-child(odd){background:var(--jp-layout-color0)}.jp-RenderedHTMLCommon tbody tr:nth-child(even){background:var(--jp-rendermime-table-row-background)}.jp-RenderedHTMLCommon tbody tr:hover{background:var(--jp-rendermime-table-row-hover-background)}.jp-RenderedHTMLCommon p{text-align:left;margin:0;margin-bottom:1em}.jp-RenderedHTMLCommon img{-moz-force-broken-image-icon:1}.jp-RenderedHTMLCommon>img{display:block;margin-left:0;margin-right:0;margin-bottom:1em}[data-jp-theme-light='false'] .jp-RenderedImage img.jp-needs-light-background{background-color:var(--jp-inverse-layout-color1)}[data-jp-theme-light='true'] .jp-RenderedImage img.jp-needs-dark-background{background-color:var(--jp-inverse-layout-color1)}.jp-RenderedHTMLCommon img,.jp-RenderedImage img,.jp-RenderedHTMLCommon svg,.jp-RenderedSVG svg{max-width:100%;height:auto}.jp-RenderedHTMLCommon img.jp-mod-unconfined,.jp-RenderedImage img.jp-mod-unconfined,.jp-RenderedHTMLCommon svg.jp-mod-unconfined,.jp-RenderedSVG svg.jp-mod-unconfined{max-width:none}.jp-RenderedHTMLCommon .alert{padding:var(--jp-notebook-padding);border:var(--jp-border-width) solid transparent;border-radius:var(--jp-border-radius);margin-bottom:1em}.jp-RenderedHTMLCommon .alert-info{color:var(--jp-info-color0);background-color:var(--jp-info-color3);border-color:var(--jp-info-color2)}.jp-RenderedHTMLCommon .alert-info hr{border-color:var(--jp-info-color3)}.jp-RenderedHTMLCommon .alert-info>p:last-child,.jp-RenderedHTMLCommon .alert-info>ul:last-child{margin-bottom:0}.jp-RenderedHTMLCommon .alert-warning{color:var(--jp-warn-color0);background-color:var(--jp-warn-color3);border-color:var(--jp-warn-color2)}.jp-RenderedHTMLCommon .alert-warning hr{border-color:var(--jp-warn-color3)}.jp-RenderedHTMLCommon .alert-warning>p:last-child,.jp-RenderedHTMLCommon .alert-warning>ul:last-child{margin-bottom:0}.jp-RenderedHTMLCommon .alert-success{color:var(--jp-success-color0);background-color:var(--jp-success-color3);border-color:var(--jp-success-color2)}
.jp-RenderedHTMLCommon .alert-success hr{border-color:var(--jp-success-color3)}.jp-RenderedHTMLCommon .alert-success>p:last-child,.jp-RenderedHTMLCommon .alert-success>ul:last-child{margin-bottom:0}.jp-RenderedHTMLCommon .alert-danger{color:var(--jp-error-color0);background-color:var(--jp-error-color3);border-color:var(--jp-error-color2)}.jp-RenderedHTMLCommon .alert-danger hr{border-color:var(--jp-error-color3)}.jp-RenderedHTMLCommon .alert-danger>p:last-child,.jp-RenderedHTMLCommon .alert-danger>ul:last-child{margin-bottom:0}.jp-RenderedHTMLCommon blockquote{margin:1em 2em;padding:0 1em;border-left:5px solid var(--jp-border-color2)}a.jp-InternalAnchorLink{visibility:hidden;margin-left:8px;color:var(--md-blue-800)}h1:hover .jp-InternalAnchorLink,h2:hover .jp-InternalAnchorLink,h3:hover .jp-InternalAnchorLink,h4:hover .jp-InternalAnchorLink,h5:hover .jp-InternalAnchorLink,h6:hover .jp-InternalAnchorLink{visibility:visible}.jp-RenderedHTMLCommon kbd{background-color:var(--jp-rendermime-table-row-background);border:1px solid var(--jp-border-color0);border-bottom-color:var(--jp-border-color2);border-radius:3px;box-shadow:inset 0 -1px 0 rgba(0,0,0,0.25);display:inline-block;font-size:var(--jp-ui-font-size0);line-height:1em;padding:.2em .5em}.jp-RenderedHTMLCommon>*:last-child{margin-bottom:.5em}.lm-cursor-backdrop{position:fixed;width:200px;height:200px;margin-top:-100px;margin-left:-100px;will-change:transform;z-index:100}.lm-mod-drag-image{will-change:transform}.jp-lineFormSearch{padding:4px 12px;background-color:var(--jp-layout-color2);box-shadow:var(--jp-toolbar-box-shadow);z-index:2;font-size:var(--jp-ui-font-size1)}.jp-lineFormCaption{font-size:var(--jp-ui-font-size0);line-height:var(--jp-ui-font-size1);margin-top:4px;color:var(--jp-ui-font-color0)}.jp-baseLineForm{border:0;border-radius:0;position:absolute;background-size:16px;background-repeat:no-repeat;background-position:center;outline:0}.jp-lineFormButtonContainer{top:4px;right:8px;height:24px;padding:0 12px;width:12px}.jp-lineFormButtonIcon{top:0;right:0;background-color:var(--jp-brand-color1);height:100%;width:100%;box-sizing:border-box;padding:4px 6px}.jp-lineFormButton{top:0;right:0;background-color:transparent;height:100%;width:100%;box-sizing:border-box}.jp-lineFormWrapper{overflow:hidden;padding:0 8px;border:1px solid var(--jp-border-color0);background-color:var(--jp-input-active-background);height:22px}.jp-lineFormWrapperFocusWithin{border:var(--jp-border-width) solid var(--md-blue-500);box-shadow:inset 0 0 4px var(--md-blue-300)}.jp-lineFormInput{background:transparent;width:200px;height:100%;border:0;outline:0;color:var(--jp-ui-font-color0);line-height:28px}.jp-JSONEditor{display:flex;flex-direction:column;width:100%}.jp-JSONEditor-host{flex:1 1 auto;border:var(--jp-border-width) solid var(--jp-input-border-color);border-radius:0;background:var(--jp-layout-color0);min-height:50px;padding:1px}.jp-JSONEditor.jp-mod-error .jp-JSONEditor-host{border-color:red;outline-color:red}.jp-JSONEditor-header{display:flex;flex:1 0 auto;padding:0 0 0 12px}.jp-JSONEditor-header label{flex:0 0 auto}.jp-JSONEditor-commitButton{height:16px;width:16px;background-size:18px;background-repeat:no-repeat;background-position:center}.jp-JSONEditor-host.jp-mod-focused{background-color:var(--jp-input-active-background);border:1px solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow)}.jp-Editor.jp-mod-dropTarget{border:var(--jp-border-width) solid var(--jp-input-active-border-color);box-shadow:var(--jp-input-box-shadow)}.jp-DocumentSearch-input{border:0;outline:0;color:var(--jp-ui-font-color0);font-size:var(--jp-ui-font-size1);background-color:var(--jp-layout-color0);font-family:var(--jp-ui-font-family);padding:2px 1px;resize:none}.jp-DocumentSearch-overlay{position:absolute;background-color:var(--jp-toolbar-background);border-bottom:var(--jp-border-width) solid var(--jp-toolbar-border-color);border-left:var(--jp-border-width) solid var(--jp-toolbar-border-color);top:0;right:0;z-index:7;min-width:405px;padding:2px;font-size:var(--jp-ui-font-size1);--jp-private-document-search-button-height:20px}.jp-DocumentSearch-overlay button{background-color:var(--jp-toolbar-background);outline:0}.jp-DocumentSearch-overlay button:hover{background-color:var(--jp-layout-color2)}.jp-DocumentSearch-overlay button:active{background-color:var(--jp-layout-color3)}.jp-DocumentSearch-overlay-row{display:flex;align-items:center;margin-bottom:2px}.jp-DocumentSearch-button-content{display:inline-block;cursor:pointer;box-sizing:border-box;width:100%;height:100%}.jp-DocumentSearch-button-content svg{width:100%;height:100%}.jp-DocumentSearch-input-wrapper{border:var(--jp-border-width) solid var(--jp-border-color0);display:flex;background-color:var(--jp-layout-color0);margin:2px}.jp-DocumentSearch-input-wrapper:focus-within{border-color:var(--jp-cell-editor-active-border-color)}.jp-DocumentSearch-toggle-wrapper,.jp-DocumentSearch-button-wrapper{all:initial;overflow:hidden;display:inline-block;border:0;box-sizing:border-box}
.jp-DocumentSearch-toggle-wrapper{width:14px;height:14px}.jp-DocumentSearch-button-wrapper{width:var(--jp-private-document-search-button-height);height:var(--jp-private-document-search-button-height)}.jp-DocumentSearch-toggle-wrapper:focus,.jp-DocumentSearch-button-wrapper:focus{outline:var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);outline-offset:-1px}.jp-DocumentSearch-toggle-wrapper,.jp-DocumentSearch-button-wrapper,.jp-DocumentSearch-button-content:focus{outline:0}.jp-DocumentSearch-toggle-placeholder{width:5px}.jp-DocumentSearch-input-button::before{display:block;padding-top:100%}.jp-DocumentSearch-input-button-off{opacity:var(--jp-search-toggle-off-opacity)}.jp-DocumentSearch-input-button-off:hover{opacity:var(--jp-search-toggle-hover-opacity)}.jp-DocumentSearch-input-button-on{opacity:var(--jp-search-toggle-on-opacity)}.jp-DocumentSearch-index-counter{padding-left:10px;padding-right:10px;user-select:none;min-width:35px;display:inline-block}.jp-DocumentSearch-up-down-wrapper{display:inline-block;padding-right:2px;margin-left:auto;white-space:nowrap}.jp-DocumentSearch-spacer{margin-left:auto}.jp-DocumentSearch-up-down-wrapper button{outline:0;border:0;width:var(--jp-private-document-search-button-height);height:var(--jp-private-document-search-button-height);vertical-align:middle;margin:1px 5px 2px}.jp-DocumentSearch-up-down-button:hover{background-color:var(--jp-layout-color2)}.jp-DocumentSearch-up-down-button:active{background-color:var(--jp-layout-color3)}.jp-DocumentSearch-filter-button{border-radius:var(--jp-border-radius)}.jp-DocumentSearch-filter-button:hover{background-color:var(--jp-layout-color2)}.jp-DocumentSearch-filter-button-enabled{background-color:var(--jp-layout-color2)}.jp-DocumentSearch-filter-button-enabled:hover{background-color:var(--jp-layout-color3)}.jp-DocumentSearch-search-options{padding:0 8px;margin-left:3px;width:100%;display:grid;justify-content:start;grid-template-columns:1fr 1fr;align-items:center;justify-items:stretch}.jp-DocumentSearch-search-filter-disabled{color:var(--jp-ui-font-color2)}.jp-DocumentSearch-search-filter{display:flex;align-items:center;user-select:none}.jp-DocumentSearch-regex-error{color:var(--jp-error-color0)}.jp-DocumentSearch-replace-button-wrapper{overflow:hidden;display:inline-block;box-sizing:border-box;border:var(--jp-border-width) solid var(--jp-border-color0);margin:auto 2px;padding:1px 4px;height:calc(var(--jp-private-document-search-button-height)+2px)}.jp-DocumentSearch-replace-button-wrapper:focus{border:var(--jp-border-width) solid var(--jp-cell-editor-active-border-color)}.jp-DocumentSearch-replace-button{display:inline-block;text-align:center;cursor:pointer;box-sizing:border-box;color:var(--jp-ui-font-color1);line-height:calc(var(--jp-private-document-search-button-height) - 2px);width:100%;height:100%}.jp-DocumentSearch-replace-button:focus{outline:0}.jp-DocumentSearch-replace-wrapper-class{margin-left:14px;display:flex}.jp-DocumentSearch-replace-toggle{border:0;background-color:var(--jp-toolbar-background);border-radius:var(--jp-border-radius)}.jp-DocumentSearch-replace-toggle:hover{background-color:var(--jp-layout-color2)}.cm-editor{line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);font-family:var(--jp-code-font-family);border:0;border-radius:0;height:auto}.cm-editor pre{padding:0 var(--jp-code-padding)}.jp-CodeMirrorEditor[data-type='inline'] .cm-dialog{background-color:var(--jp-layout-color0);color:var(--jp-content-font-color1)}.jp-CodeMirrorEditor{cursor:text}@media screen and (min-width:2138px) and (max-width:4319px){.jp-CodeMirrorEditor[data-type='inline'] .cm-cursor{border-left:var(--jp-code-cursor-width1) solid var(--jp-editor-cursor-color)}}@media screen and (min-width:4320px){.jp-CodeMirrorEditor[data-type='inline'] .cm-cursor{border-left:var(--jp-code-cursor-width2) solid var(--jp-editor-cursor-color)}}.cm-editor.jp-mod-readOnly .cm-cursor{display:none}.jp-CollaboratorCursor{border-left:5px solid transparent;border-right:5px solid transparent;border-top:0;border-bottom:3px solid;background-clip:content-box;margin-left:-5px;margin-right:-5px}.cm-searching,.cm-searching span{background-color:var(--jp-search-unselected-match-background-color);color:var(--jp-search-unselected-match-color)}.cm-searching::selection,.cm-searching span::selection{background-color:var(--jp-search-unselected-match-background-color);color:var(--jp-search-unselected-match-color)}.jp-current-match>.cm-searching,.jp-current-match>.cm-searching span,.cm-searching>.jp-current-match,.cm-searching>.jp-current-match span{background-color:var(--jp-search-selected-match-background-color);color:var(--jp-search-selected-match-color)}.jp-current-match>.cm-searching::selection,.cm-searching>.jp-current-match::selection,.jp-current-match>.cm-searching span::selection{background-color:var(--jp-search-selected-match-background-color);color:var(--jp-search-selected-match-color)}
.cm-trailingspace{background-image:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAsElEQVQIHQGlAFr/AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA7+r3zKmT0/+pk9P/7+r3zAAAAAAAAAAABAAAAAAAAAAA6OPzM+/q9wAAAAAA6OPzMwAAAAAAAAAAAgAAAAAAAAAAGR8NiRQaCgAZIA0AGR8NiQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQyoYJ/SY80UAAAAASUVORK5CYII=);background-position:center left;background-repeat:repeat-x}.jp-CollaboratorCursor-hover{position:absolute;z-index:1;transform:translateX(-50%);color:white;border-radius:3px;padding-left:4px;padding-right:4px;padding-top:1px;padding-bottom:1px;text-align:center;font-size:var(--jp-ui-font-size1);white-space:nowrap}.jp-CodeMirror-ruler{border-left:1px dashed var(--jp-border-color2)}.jp-CodeMirrorEditor .cm-ySelectionCaret{position:relative;border-left:1px solid black;margin-left:-1px;margin-right:-1px;box-sizing:border-box}.jp-CodeMirrorEditor .cm-ySelectionCaret>.cm-ySelectionInfo{white-space:nowrap;position:absolute;top:-1.15em;padding-bottom:.05em;left:-1px;font-size:.95em;font-family:var(--jp-ui-font-family);font-weight:bold;line-height:normal;user-select:none;color:white;padding-left:2px;padding-right:2px;z-index:101;transition:opacity .3s ease-in-out}.jp-CodeMirrorEditor .cm-ySelectionInfo{transition-delay:.7s;opacity:0}.jp-CodeMirrorEditor .cm-ySelectionCaret:hover>.cm-ySelectionInfo{opacity:1;transition-delay:0}.jp-MimeDocument{outline:0}:root{--jp-private-filebrowser-button-height:28px;--jp-private-filebrowser-button-width:48px}.jp-FileBrowser .jp-SidePanel-content{display:flex;flex-direction:column}.jp-FileBrowser-toolbar.jp-Toolbar{flex-wrap:wrap;row-gap:12px;border-bottom:0;height:auto;margin:8px 12px 0;box-shadow:none;padding:0;justify-content:flex-start}.jp-FileBrowser-Panel{flex:1 1 auto;display:flex;flex-direction:column}.jp-BreadCrumbs{flex:0 0 auto;margin:8px 12px}.jp-BreadCrumbs-item{margin:0 2px;padding:0 2px;border-radius:var(--jp-border-radius);cursor:pointer}.jp-BreadCrumbs-item:hover{background-color:var(--jp-layout-color2)}.jp-BreadCrumbs-item:first-child{margin-left:0}.jp-BreadCrumbs-item.jp-mod-dropTarget{background-color:var(--jp-brand-color2);opacity:.7}.jp-FileBrowser-toolbar>.jp-Toolbar-item{flex:0 0 auto;padding-left:0;padding-right:2px;align-items:center;height:unset}.jp-FileBrowser-toolbar>.jp-Toolbar-item .jp-ToolbarButtonComponent{width:40px}.jp-FileDialog.jp-mod-conflict input{color:var(--jp-error-color1)}.jp-FileDialog .jp-new-name-title{margin-top:12px}.jp-LastModified-hidden{display:none}.jp-FileSize-hidden{display:none}.jp-FileBrowser .lm-AccordionPanel>h3:first-child{display:none}.jp-DirListing{flex:1 1 auto;display:flex;flex-direction:column;outline:0}.jp-DirListing-header{flex:0 0 auto;display:flex;flex-direction:row;align-items:center;overflow:hidden;border-top:var(--jp-border-width) solid var(--jp-border-color2);border-bottom:var(--jp-border-width) solid var(--jp-border-color1);box-shadow:var(--jp-toolbar-box-shadow);z-index:2}.jp-DirListing-headerItem{padding:4px 12px 2px;font-weight:500}.jp-DirListing-headerItem:hover{background:var(--jp-layout-color2)}.jp-DirListing-headerItem.jp-id-name{flex:1 0 84px}.jp-DirListing-headerItem.jp-id-modified{flex:0 0 112px;border-left:var(--jp-border-width) solid var(--jp-border-color2);text-align:right}.jp-DirListing-headerItem.jp-id-filesize{flex:0 0 75px;border-left:var(--jp-border-width) solid var(--jp-border-color2);text-align:right}.jp-id-narrow{display:none;flex:0 0 5px;padding:4px;border-left:var(--jp-border-width) solid var(--jp-border-color2);text-align:right;color:var(--jp-border-color2)}.jp-DirListing-narrow .jp-id-narrow{display:block}.jp-DirListing-narrow .jp-id-modified,.jp-DirListing-narrow .jp-DirListing-itemModified{display:none}.jp-DirListing-headerItem.jp-mod-selected{font-weight:600}.jp-DirListing-content{flex:1 1 auto;margin:0;padding:0;list-style-type:none;overflow:auto;background-color:var(--jp-layout-color1)}.jp-DirListing-content mark{color:var(--jp-ui-font-color0);background-color:transparent;font-weight:bold}.jp-DirListing-content .jp-DirListing-item.jp-mod-selected mark{color:var(--jp-ui-inverse-font-color0)}.jp-DirListing.jp-mod-native-drop .jp-DirListing-content{outline:5px dashed rgba(128,128,128,0.5);outline-offset:-10px;cursor:copy}.jp-DirListing-item{display:flex;flex-direction:row;align-items:center;padding:4px 12px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jp-DirListing-checkboxWrapper{padding:4px}.jp-DirListing-header .jp-DirListing-checkboxWrapper+.jp-DirListing-headerItem{padding-left:4px}.jp-DirListing-content .jp-DirListing-checkboxWrapper{position:relative;left:-4px;margin:-4px 0 -4px -8px}.jp-DirListing-checkboxWrapper.jp-mod-visible{visibility:visible}@media(hover:hover){.jp-DirListing-checkboxWrapper{visibility:hidden}.jp-DirListing-item:hover .jp-DirListing-checkboxWrapper,.jp-DirListing-item.jp-mod-selected .jp-DirListing-checkboxWrapper{visibility:visible}}.jp-DirListing-item[data-is-dot]{opacity:75%}.jp-DirListing-item.jp-mod-selected{color:var(--jp-ui-inverse-font-color1);background:var(--jp-brand-color1)}.jp-DirListing-item.jp-mod-dropTarget{background:var(--jp-brand-color3)}.jp-DirListing-item:hover:not(.jp-mod-selected){background:var(--jp-layout-color2)}.jp-DirListing-itemIcon{flex:0 0 20px;margin-right:4px}
.jp-DirListing-itemText{flex:1 0 64px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;user-select:none}.jp-DirListing-itemText:focus{outline-width:2px;outline-color:var(--jp-inverse-layout-color1);outline-style:solid;outline-offset:1px}.jp-DirListing-item.jp-mod-selected .jp-DirListing-itemText:focus{outline-color:var(--jp-layout-color1)}.jp-DirListing-itemModified{flex:0 0 125px;text-align:right}.jp-DirListing-itemFileSize{flex:0 0 90px;text-align:right}.jp-DirListing-editor{flex:1 0 64px;outline:0;border:0;color:var(--jp-ui-font-color1);background-color:var(--jp-layout-color1)}.jp-DirListing-item.jp-mod-running .jp-DirListing-itemIcon::before{color:var(--jp-success-color1);content:'\25CF';font-size:8px;position:absolute;left:-8px}.jp-DirListing-item.jp-mod-running.jp-mod-selected .jp-DirListing-itemIcon::before{color:var(--jp-ui-inverse-font-color1)}.jp-DirListing-item.lm-mod-drag-image,.jp-DirListing-item.jp-mod-selected.lm-mod-drag-image{font-size:var(--jp-ui-font-size1);padding-left:4px;margin-left:4px;width:160px;background-color:var(--jp-ui-inverse-font-color2);box-shadow:var(--jp-elevation-z2);border-radius:0;color:var(--jp-ui-font-color1);transform:translateX(-40%) translateY(-58%)}.jp-Document{min-width:120px;min-height:120px;outline:0}.jp-OutputArea{overflow-y:auto}.jp-OutputArea-child{display:table;table-layout:fixed;width:100%;overflow:hidden}.jp-OutputPrompt{width:var(--jp-cell-prompt-width);color:var(--jp-cell-outprompt-font-color);font-family:var(--jp-cell-prompt-font-family);padding:var(--jp-code-padding);letter-spacing:var(--jp-cell-prompt-letter-spacing);line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid transparent;opacity:var(--jp-cell-prompt-opacity);text-align:right;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jp-OutputArea-prompt{display:table-cell;vertical-align:top}.jp-OutputArea-output{display:table-cell;width:100%;height:auto;overflow:auto;user-select:text;-moz-user-select:text;-webkit-user-select:text;-ms-user-select:text}.jp-OutputArea .jp-RenderedText{padding-left:1ch}.jp-OutputArea-promptOverlay{position:absolute;top:0;width:var(--jp-cell-prompt-width);height:100%;opacity:.5}.jp-OutputArea-promptOverlay:hover{background:var(--jp-layout-color2);box-shadow:inset 0 0 1px var(--jp-inverse-layout-color0);cursor:zoom-out}.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay:hover{cursor:zoom-in}.jp-OutputArea-output.jp-mod-isolated{width:100%;display:block}body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated{position:relative}body.lm-mod-override-cursor .jp-OutputArea-output.jp-mod-isolated::before{content:'';position:absolute;top:0;left:0;right:0;bottom:0;background:transparent}.jp-OutputArea-output pre{border:0;margin:0;padding:0;overflow-x:auto;overflow-y:auto;word-break:break-all;word-wrap:break-word;white-space:pre-wrap}.jp-OutputArea-output.jp-RenderedHTMLCommon table{margin-left:0;margin-right:0}.jp-OutputArea-output dl,.jp-OutputArea-output dt,.jp-OutputArea-output dd{display:block}.jp-OutputArea-output dl{width:100%;overflow:hidden;padding:0;margin:0}.jp-OutputArea-output dt{font-weight:bold;float:left;width:20%;padding:0;margin:0}.jp-OutputArea-output dd{float:left;width:80%;padding:0;margin:0}.jp-TrimmedOutputs pre{background:var(--jp-layout-color3);font-size:calc(var(--jp-code-font-size) * 1.4);text-align:center;text-transform:uppercase}.jp-OutputArea .jp-OutputArea .jp-OutputArea-prompt{display:none}.jp-OutputArea-prompt:empty{padding:0;border:0}.jp-OutputArea-output.jp-OutputArea-executeResult{margin-left:0;width:100%}.jp-OutputArea-executeResult .jp-RenderedText.jp-OutputArea-output{padding-top:var(--jp-code-padding);border-top:var(--jp-border-width) solid transparent}.jp-Stdin-prompt{color:var(--jp-content-font-color0);padding-right:var(--jp-code-padding);vertical-align:baseline;flex:0 0 auto}.jp-Stdin-input{font-family:var(--jp-code-font-family);font-size:inherit;color:inherit;background-color:inherit;width:42%;min-width:200px;vertical-align:baseline;padding:0 .25em;margin:0 .25em;flex:0 0 70%}.jp-Stdin-input::placeholder{opacity:0}.jp-Stdin-input:focus{box-shadow:none}.jp-Stdin-input:focus::placeholder{opacity:1}.jp-LinkedOutputView .jp-OutputArea{height:100%;display:block}.jp-LinkedOutputView .jp-OutputArea-output:only-child{height:100%}@media print{.jp-OutputArea-child{break-inside:avoid-page}}@media only screen and (max-width:760px){.jp-OutputPrompt{display:table-row;text-align:left}.jp-OutputArea-child .jp-OutputArea-output{display:table-row;margin-left:var(--jp-notebook-padding)}}.jp-TrimmedOutputs>a{margin:10px;text-decoration:none;cursor:pointer}.jp-TrimmedOutputs>a:hover{text-decoration:none}:root{--jp-private-toc-active-width:4px}.jp-TableOfContents{display:flex;flex-direction:column;background:var(--jp-layout-color1);color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);height:100%}
.jp-TableOfContents-placeholder{text-align:center}.jp-TableOfContents-placeholderContent{color:var(--jp-content-font-color2);padding:8px}.jp-TableOfContents-placeholderContent>h3{margin-bottom:var(--jp-content-heading-margin-bottom)}.jp-TableOfContents .jp-SidePanel-content{overflow-y:auto}.jp-TableOfContents-tree{margin:4px}.jp-TableOfContents ol{list-style-type:none}.jp-TableOfContents li>ol{padding-left:11px}.jp-TableOfContents-content{margin:0 0 0 var(--jp-private-toc-active-width);padding:0;background-color:var(--jp-layout-color1)}.jp-tocItem{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.jp-tocItem-heading{display:flex;cursor:pointer}.jp-tocItem-heading:hover{background-color:var(--jp-layout-color2)}.jp-tocItem-content{display:block;padding:4px 0;white-space:nowrap;text-overflow:ellipsis;overflow-x:hidden}.jp-tocItem-collapser{height:20px;margin:2px 2px 0;padding:0;background:0;border:0;cursor:pointer}.jp-tocItem-collapser:hover{background-color:var(--jp-layout-color3)}.jp-tocItem-heading::before{content:' ';background:transparent;width:var(--jp-private-toc-active-width);height:24px;position:absolute;left:0;border-radius:var(--jp-border-radius)}.jp-tocItem-heading.jp-tocItem-active::before{background-color:var(--jp-brand-color1)}.jp-tocItem-heading:hover.jp-tocItem-active::before{background:var(--jp-brand-color0);opacity:1}.jp-Collapser{flex:0 0 var(--jp-cell-collapser-width);padding:0;margin:0;border:0;outline:0;background:transparent;border-radius:var(--jp-border-radius);opacity:1}.jp-Collapser-child{display:block;width:100%;box-sizing:border-box;position:absolute;top:0;bottom:0}@media print{.jp-Collapser{display:none}}.jp-CellHeader,.jp-CellFooter{height:0;width:100%;padding:0;margin:0;border:0;outline:0;background:transparent}.jp-InputArea{display:table;table-layout:fixed;width:100%;overflow:hidden}.jp-InputArea-editor{display:table-cell;overflow:hidden;vertical-align:top;border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);border-radius:0;background:var(--jp-cell-editor-background)}.jp-InputPrompt{display:table-cell;vertical-align:top;width:var(--jp-cell-prompt-width);color:var(--jp-cell-inprompt-font-color);font-family:var(--jp-cell-prompt-font-family);padding:var(--jp-code-padding);letter-spacing:var(--jp-cell-prompt-letter-spacing);opacity:var(--jp-cell-prompt-opacity);line-height:var(--jp-code-line-height);font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid transparent;text-align:right;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}@media only screen and (max-width:760px){.jp-InputArea-editor{display:table-row;margin-left:var(--jp-notebook-padding)}.jp-InputPrompt{display:table-row;text-align:left}}.jp-Placeholder{display:table;table-layout:fixed;width:100%}.jp-Placeholder-prompt{display:table-cell;box-sizing:border-box}.jp-Placeholder-content{display:table-cell;padding:4px 6px;border:1px solid transparent;border-radius:0;background:0;box-sizing:border-box;cursor:pointer}.jp-Placeholder-contentContainer{display:flex}.jp-Placeholder-content:hover,.jp-InputPlaceholder>.jp-Placeholder-content:hover{border-color:var(--jp-layout-color3)}.jp-Placeholder-content .jp-MoreHorizIcon{width:32px;height:16px;border:1px solid transparent;border-radius:var(--jp-border-radius)}.jp-Placeholder-content .jp-MoreHorizIcon:hover{border:1px solid var(--jp-border-color1);box-shadow:0 0 2px 0 rgba(0,0,0,0.25);background-color:var(--jp-layout-color0)}.jp-PlaceholderText{white-space:nowrap;overflow-x:hidden;color:var(--jp-inverse-layout-color3);font-family:var(--jp-code-font-family)}.jp-InputPlaceholder>.jp-Placeholder-content{border-color:var(--jp-cell-editor-border-color);background:var(--jp-cell-editor-background)}:root{--jp-private-cell-scrolling-output-offset:5px}.jp-Cell{padding:var(--jp-cell-padding);margin:0;border:0;outline:0;background:transparent}.jp-Cell-inputWrapper,.jp-Cell-outputWrapper{display:flex;flex-direction:row;padding:0;margin:0;overflow:visible}.jp-Cell-inputArea,.jp-Cell-outputArea{flex:1 1 auto}.jp-Cell.jp-mod-noOutputs .jp-Cell-outputCollapser{border:none!important;background:transparent!important}.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputCollapser{min-height:var(--jp-cell-collapser-min-height)}.jp-Cell:not(.jp-mod-noOutputs) .jp-Cell-outputWrapper{margin-top:5px}.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea{overflow-y:auto;max-height:24em;margin-left:var(--jp-private-cell-scrolling-output-offset);resize:vertical}.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea[style*='height']{max-height:unset}.jp-CodeCell.jp-mod-outputsScrolled .jp-Cell-outputArea::after{content:' ';box-shadow:inset 0 0 6px 2px rgb(0 0 0 / 30%);width:100%;height:100%;position:sticky;bottom:0;top:0;margin-top:-50%;float:left;display:block;pointer-events:none}
.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-child{padding-top:6px}.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-prompt{width:calc(var(--jp-cell-prompt-width) - var(--jp-private-cell-scrolling-output-offset))}.jp-CodeCell.jp-mod-outputsScrolled .jp-OutputArea-promptOverlay{left:calc(-1 * var(--jp-private-cell-scrolling-output-offset))}.jp-MarkdownOutput{display:table-cell;width:100%;margin-top:0;margin-bottom:0;padding-left:var(--jp-code-padding)}.jp-MarkdownOutput.jp-RenderedHTMLCommon{overflow:auto}.jp-collapseHeadingButton{display:flex;min-height:var(--jp-cell-collapser-min-height);font-size:var(--jp-code-font-size);position:absolute;background-color:transparent;background-size:25px;background-repeat:no-repeat;background-position-x:center;background-position-y:top;background-image:var(--jp-icon-caret-down);right:0;top:0;bottom:0}.jp-collapseHeadingButton.jp-mod-collapsed{background-image:var(--jp-icon-caret-right)}.jp-MarkdownCell .jp-InputPrompt{font-size:var(--jp-content-font-size1)}.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='1']{font-size:var(--jp-content-font-size5);background-position-y:calc(0.3 * var(--jp-content-font-size5))}.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='2']{font-size:var(--jp-content-font-size4);background-position-y:calc(0.3 * var(--jp-content-font-size4))}.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='3']{font-size:var(--jp-content-font-size3);background-position-y:calc(0.3 * var(--jp-content-font-size3))}.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='4']{font-size:var(--jp-content-font-size2);background-position-y:calc(0.3 * var(--jp-content-font-size2))}.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='5']{font-size:var(--jp-content-font-size1);background-position-y:top}.jp-mod-rendered .jp-collapseHeadingButton[data-heading-level='6']{font-size:var(--jp-content-font-size0);background-position-y:top}.jp-Notebook.jp-mod-showHiddenCellsButton .jp-collapseHeadingButton{display:none}.jp-Notebook.jp-mod-showHiddenCellsButton :is(.jp-MarkdownCell:hover,.jp-mod-active) .jp-collapseHeadingButton{display:flex}.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton{margin-left:calc(var(--jp-cell-prompt-width)+2 * var(--jp-code-padding));margin-top:var(--jp-code-padding);border:1px solid var(--jp-border-color2);background-color:var(--jp-border-color3)!important;color:var(--jp-content-font-color0)!important;display:flex}.jp-Notebook.jp-mod-showHiddenCellsButton .jp-showHiddenCellsButton:hover{background-color:var(--jp-border-color2)!important}.jp-showHiddenCellsButton{display:none}@media print{.jp-Cell-inputWrapper,.jp-Cell-outputWrapper{display:block}}:root{--jp-notebook-toolbar-padding:2px 5px 2px 2px}.jp-NotebookPanel-toolbar{padding:var(--jp-notebook-toolbar-padding);contain:style size!important}.jp-Toolbar-item.jp-Notebook-toolbarCellType .jp-select-wrapper.jp-mod-focused{border:0;box-shadow:none}.jp-Notebook-toolbarCellTypeDropdown select{height:24px;font-size:var(--jp-ui-font-size1);line-height:14px;border-radius:0;display:block}.jp-Notebook-toolbarCellTypeDropdown span{top:5px!important}.jp-Toolbar-responsive-popup{position:absolute;height:fit-content;display:flex;flex-direction:row;flex-wrap:wrap;justify-content:flex-end;border-bottom:var(--jp-border-width) solid var(--jp-toolbar-border-color);box-shadow:var(--jp-toolbar-box-shadow);background:var(--jp-toolbar-background);min-height:var(--jp-toolbar-micro-height);padding:var(--jp-notebook-toolbar-padding);z-index:1;right:0;top:0}.jp-Toolbar>.jp-Toolbar-responsive-opener{margin-left:auto}.jp-Notebook-ExecutionIndicator{position:relative;display:inline-block;height:100%;z-index:9997}.jp-Notebook-ExecutionIndicator-tooltip{visibility:hidden;height:auto;width:max-content;width:-moz-max-content;background-color:var(--jp-layout-color2);color:var(--jp-ui-font-color1);text-align:justify;border-radius:6px;padding:0 5px;position:fixed;display:table}.jp-Notebook-ExecutionIndicator-tooltip.up{transform:translateX(-50%) translateY(-100%) translateY(-32px)}.jp-Notebook-ExecutionIndicator-tooltip.down{transform:translateX(calc(-100%+16px)) translateY(5px)}.jp-Notebook-ExecutionIndicator-tooltip.hidden{display:none}.jp-Notebook-ExecutionIndicator:hover .jp-Notebook-ExecutionIndicator-tooltip{visibility:visible}.jp-Notebook-ExecutionIndicator span{font-size:var(--jp-ui-font-size1);font-family:var(--jp-ui-font-family);color:var(--jp-ui-font-color1);line-height:24px;display:block}.jp-Notebook-ExecutionIndicator-progress-bar{display:flex;justify-content:center;height:100%}.jp-tocItem-content::after{content:'';width:12px;height:12px;background:0;border:0;position:absolute;right:0}.jp-tocItem-content[data-running='0']::after{border-radius:50%;border:var(--jp-border-width) solid var(--jp-inverse-layout-color3);background:0}
.jp-tocItem-content[data-running='1']::after{border-radius:50%;border:var(--jp-border-width) solid var(--jp-inverse-layout-color3);background-color:var(--jp-inverse-layout-color3)}.jp-tocItem-content[data-running='0'],.jp-tocItem-content[data-running='1']{margin-right:12px}.jp-Notebook-footer{height:27px;margin-left:calc(var(--jp-cell-prompt-width)+var(--jp-cell-collapser-width)+var(--jp-cell-padding));width:calc(100% -(var(--jp-cell-prompt-width)+var(--jp-cell-collapser-width)+var(--jp-cell-padding)+var(--jp-cell-padding)));border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);color:var(--jp-ui-font-color3);margin-top:6px;background:0;cursor:pointer}.jp-Notebook-footer:focus{border-color:var(--jp-cell-editor-active-border-color)}@media(hover:hover){.jp-Notebook-footer{opacity:0}.jp-Notebook-footer:focus,.jp-Notebook-footer:hover{opacity:1}}:root{--jp-side-by-side-output-size:1fr;--jp-side-by-side-resized-cell:var(--jp-side-by-side-output-size);--jp-private-notebook-dragImage-width:304px;--jp-private-notebook-dragImage-height:36px;--jp-private-notebook-selected-color:var(--md-blue-400);--jp-private-notebook-active-color:var(--md-green-400)}.jp-NotebookPanel{display:block;height:100%}.jp-NotebookPanel.jp-Document{min-width:240px;min-height:120px}.jp-Notebook{padding:var(--jp-notebook-padding);outline:0;overflow:auto;background:var(--jp-layout-color0)}.jp-Notebook.jp-mod-scrollPastEnd::after{display:block;content:'';min-height:var(--jp-notebook-scroll-padding)}.jp-MainAreaWidget-ContainStrict .jp-Notebook *{contain:strict}.jp-Notebook .jp-Cell{overflow:visible}.jp-Notebook .jp-Cell .jp-InputPrompt{cursor:move}.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-InputPrompt{opacity:var(--jp-cell-prompt-not-active-opacity);color:var(--jp-cell-prompt-not-active-font-color)}.jp-Notebook .jp-Cell:not(.jp-mod-active) .jp-OutputPrompt{opacity:var(--jp-cell-prompt-not-active-opacity);color:var(--jp-cell-prompt-not-active-font-color)}.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser{background:var(--jp-brand-color1)}.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt{color:var(--jp-warn-color1)}.jp-Notebook .jp-Cell.jp-mod-dirty .jp-InputPrompt::before{color:var(--jp-warn-color1);content:''}.jp-Notebook .jp-Cell.jp-mod-active.jp-mod-dirty .jp-Collapser{background:var(--jp-warn-color1)}.jp-Notebook .jp-Cell .jp-Collapser:hover{box-shadow:var(--jp-elevation-z2);background:var(--jp-brand-color1);opacity:var(--jp-cell-collapser-not-active-hover-opacity)}.jp-Notebook .jp-Cell.jp-mod-active .jp-Collapser:hover{background:var(--jp-brand-color0);opacity:1}.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-selected{background:var(--jp-notebook-multiselected-color)}.jp-Notebook.jp-mod-commandMode .jp-Cell.jp-mod-active.jp-mod-selected:not(.jp-mod-multiSelected){background:transparent}.jp-Notebook.jp-mod-editMode .jp-Cell.jp-mod-active .jp-InputArea-editor{border:var(--jp-border-width) solid var(--jp-cell-editor-active-border-color);box-shadow:var(--jp-input-box-shadow);background-color:var(--jp-cell-editor-active-background)}.jp-Notebook-cell.jp-mod-dropSource{opacity:.5}.jp-Notebook-cell.jp-mod-dropTarget,.jp-Notebook.jp-mod-commandMode .jp-Notebook-cell.jp-mod-active.jp-mod-selected.jp-mod-dropTarget{border-top-color:var(--jp-private-notebook-selected-color);border-top-style:solid;border-top-width:2px}.jp-dragImage{display:block;flex-direction:row;width:var(--jp-private-notebook-dragImage-width);height:var(--jp-private-notebook-dragImage-height);border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);background:var(--jp-cell-editor-background);overflow:visible}.jp-dragImage-singlePrompt{box-shadow:2px 2px 4px 0 rgba(0,0,0,0.12)}.jp-dragImage .jp-dragImage-content{flex:1 1 auto;z-index:2;font-size:var(--jp-code-font-size);font-family:var(--jp-code-font-family);line-height:var(--jp-code-line-height);padding:var(--jp-code-padding);border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);background:var(--jp-cell-editor-background-color);color:var(--jp-content-font-color3);text-align:left;margin:4px 4px 4px 0}.jp-dragImage .jp-dragImage-prompt{flex:0 0 auto;min-width:36px;color:var(--jp-cell-inprompt-font-color);padding:var(--jp-code-padding);padding-left:12px;font-family:var(--jp-cell-prompt-font-family);letter-spacing:var(--jp-cell-prompt-letter-spacing);line-height:1.9;font-size:var(--jp-code-font-size);border:var(--jp-border-width) solid transparent}.jp-dragImage-multipleBack{z-index:-1;position:absolute;height:32px;width:300px;top:8px;left:8px;background:var(--jp-layout-color2);border:var(--jp-border-width) solid var(--jp-input-border-color);box-shadow:2px 2px 4px 0 rgba(0,0,0,0.12)}.jp-NotebookTools{display:block;min-width:var(--jp-sidebar-min-width);color:var(--jp-ui-font-color1);background:var(--jp-layout-color1);font-size:var(--jp-ui-font-size1);overflow:auto}
.jp-ActiveCellTool{padding:12px 0;display:flex}.jp-ActiveCellTool-Content{flex:1 1 auto}.jp-ActiveCellTool .jp-ActiveCellTool-CellContent{background:var(--jp-cell-editor-background);border:var(--jp-border-width) solid var(--jp-cell-editor-border-color);border-radius:0;min-height:29px}.jp-ActiveCellTool .jp-InputPrompt{min-width:calc(var(--jp-cell-prompt-width) * .75)}.jp-ActiveCellTool-CellContent>pre{padding:5px 4px;margin:0;white-space:normal}.jp-MetadataEditorTool{flex-direction:column;padding:12px 0}.jp-RankedPanel>:not(:first-child){margin-top:12px}.jp-KeySelector select.jp-mod-styled{font-size:var(--jp-ui-font-size1);color:var(--jp-ui-font-color0);border:var(--jp-border-width) solid var(--jp-border-color1)}.jp-KeySelector label,.jp-MetadataEditorTool label,.jp-NumberSetter label{line-height:1.4}.jp-NotebookTools .jp-select-wrapper{margin-top:4px;margin-bottom:0}.jp-NumberSetter input{width:100%;margin-top:4px}.jp-NotebookTools .jp-Collapse{margin-top:16px}.jp-mod-presentationMode .jp-Notebook{--jp-content-font-size1:var(--jp-content-presentation-font-size1);--jp-code-font-size:var(--jp-code-presentation-font-size)}.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-InputPrompt,.jp-mod-presentationMode .jp-Notebook .jp-Cell .jp-OutputPrompt{flex:0 0 110px}.jp-mod-sideBySide.jp-Notebook .jp-Notebook-cell{margin-top:3em;margin-bottom:3em;margin-left:5%;margin-right:5%}.jp-mod-sideBySide.jp-Notebook .jp-CodeCell{display:grid;grid-template-columns:minmax(0,1fr) min-content minmax(0,var(--jp-side-by-side-output-size));grid-template-rows:auto minmax(0,1fr) auto;grid-template-areas:'header header header' 'input handle output' 'footer footer footer'}.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell{grid-template-columns:minmax(0,1fr) min-content minmax(0,var(--jp-side-by-side-resized-cell))}.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellHeader{grid-area:header}.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-inputWrapper{grid-area:input}.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-Cell-outputWrapper{margin-top:0;grid-area:output}.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellFooter{grid-area:footer}.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle{grid-area:handle;user-select:none;display:block;height:100%;cursor:ew-resize;padding:0 var(--jp-cell-padding)}.jp-mod-sideBySide.jp-Notebook .jp-CodeCell .jp-CellResizeHandle::after{content:'';display:block;background:var(--jp-border-color2);height:100%;width:5px}.jp-mod-sideBySide.jp-Notebook .jp-CodeCell.jp-mod-resizedCell .jp-CellResizeHandle::after{background:var(--jp-border-color0)}.jp-CellResizeHandle{display:none}.jp-Cell-Placeholder{padding-left:55px}.jp-Cell-Placeholder-wrapper{background:#fff;border:1px solid;border-color:#e5e6e9 #dfe0e4 #d0d1d5;border-radius:4px;-webkit-border-radius:4px;margin:10px 15px}.jp-Cell-Placeholder-wrapper-inner{padding:15px;position:relative}.jp-Cell-Placeholder-wrapper-body{background-repeat:repeat;background-size:50% auto}.jp-Cell-Placeholder-wrapper-body div{background:#f6f7f8;background-image:-webkit-linear-gradient(left,#f6f7f8 0%,#edeef1 20%,#f6f7f8 40%,#f6f7f8 100%);background-repeat:no-repeat;background-size:800px 104px;height:104px;position:absolute;right:15px;left:15px;top:15px}div.jp-Cell-Placeholder-h1{top:20px;height:20px;left:15px;width:150px}div.jp-Cell-Placeholder-h2{left:15px;top:50px;height:10px;width:100px}div.jp-Cell-Placeholder-content-1,div.jp-Cell-Placeholder-content-2,div.jp-Cell-Placeholder-content-3{left:15px;right:15px;height:10px}div.jp-Cell-Placeholder-content-1{top:100px}div.jp-Cell-Placeholder-content-2{top:120px}div.jp-Cell-Placeholder-content-3{top:140px}</style> <style type="text/css">:root{--jp-shadow-base-lightness:0;--jp-shadow-umbra-color:rgba(var(--jp-shadow-base-lightness),var(--jp-shadow-base-lightness),var(--jp-shadow-base-lightness),0.2);--jp-shadow-penumbra-color:rgba(var(--jp-shadow-base-lightness),var(--jp-shadow-base-lightness),var(--jp-shadow-base-lightness),0.14);--jp-shadow-ambient-color:rgba(var(--jp-shadow-base-lightness),var(--jp-shadow-base-lightness),var(--jp-shadow-base-lightness),0.12);--jp-elevation-z0:none;--jp-elevation-z1:0 2px 1px -1px var(--jp-shadow-umbra-color),0 1px 1px 0 var(--jp-shadow-penumbra-color),0 1px 3px 0 var(--jp-shadow-ambient-color);--jp-elevation-z2:0 3px 1px -2px var(--jp-shadow-umbra-color),0 2px 2px 0 var(--jp-shadow-penumbra-color),0 1px 5px 0 var(--jp-shadow-ambient-color);--jp-elevation-z4:0 2px 4px -1px var(--jp-shadow-umbra-color),0 4px 5px 0 var(--jp-shadow-penumbra-color),0 1px 10px 0 var(--jp-shadow-ambient-color);--jp-elevation-z6:0 3px 5px -1px var(--jp-shadow-umbra-color),0 6px 10px 0 var(--jp-shadow-penumbra-color),0 1px 18px 0 var(--jp-shadow-ambient-color);--jp-elevation-z8:0 5px 5px -3px var(--jp-shadow-umbra-color),0 8px 10px 1px var(--jp-shadow-penumbra-color),0 3px 14px 2px var(--jp-shadow-ambient-color);--jp-elevation-z12:0 7px 8px -4px var(--jp-shadow-umbra-color),0 12px 17px 2px var(--jp-shadow-penumbra-color),0 5px 22px 4px var(--jp-shadow-ambient-color);--jp-elevation-z16:0 8px 10px -5px var(--jp-shadow-umbra-color),0 16px 24px 2px var(--jp-shadow-penumbra-color),0 6px 30px 5px var(--jp-shadow-ambient-color);--jp-elevation-z20:0 10px 13px -6px var(--jp-shadow-umbra-color),0 20px 31px 3px var(--jp-shadow-penumbra-color),0 8px 38px 7px var(--jp-shadow-ambient-color);--jp-elevation-z24:0 11px 15px -7px var(--jp-shadow-umbra-color),0 24px 38px 3px var(--jp-shadow-penumbra-color),0 9px 46px 8px var(--jp-shadow-ambient-color);--jp-border-width:1px;--jp-border-color0:var(--md-grey-400);--jp-border-color1:var(--md-grey-400);--jp-border-color2:var(--md-grey-300);--jp-border-color3:var(--md-grey-200);--jp-inverse-border-color:var(--md-grey-600);--jp-border-radius:2px;--jp-ui-font-scale-factor:1.2;--jp-ui-font-size0:.83333em;--jp-ui-font-size1:13px;--jp-ui-font-size2:1.2em;--jp-ui-font-size3:1.44em;--jp-ui-font-family:system-ui,-apple-system,blinkmacsystemfont,'Segoe UI',helvetica,arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';--jp-ui-font-color0:rgba(0,0,0,1);--jp-ui-font-color1:rgba(0,0,0,0.87);--jp-ui-font-color2:rgba(0,0,0,0.54);--jp-ui-font-color3:rgba(0,0,0,0.38);--jp-ui-inverse-font-color0:rgba(255,255,255,1);--jp-ui-inverse-font-color1:rgba(255,255,255,1);--jp-ui-inverse-font-color2:rgba(255,255,255,0.7);--jp-ui-inverse-font-color3:rgba(255,255,255,0.5);--jp-content-line-height:1.6;--jp-content-font-scale-factor:1.2;--jp-content-font-size0:.83333em;--jp-content-font-size1:14px;--jp-content-font-size2:1.2em;--jp-content-font-size3:1.44em;--jp-content-font-size4:1.728em;--jp-content-font-size5:2.0736em;--jp-content-presentation-font-size1:17px;--jp-content-heading-line-height:1;--jp-content-heading-margin-top:1.2em;--jp-content-heading-margin-bottom:.8em;--jp-content-heading-font-weight:500;--jp-content-font-color0:rgba(0,0,0,1);--jp-content-font-color1:rgba(0,0,0,0.87);--jp-content-font-color2:rgba(0,0,0,0.54);--jp-content-font-color3:rgba(0,0,0,0.38);--jp-content-link-color:var(--md-blue-900);--jp-content-font-family:system-ui,-apple-system,blinkmacsystemfont,'Segoe UI',helvetica,arial,sans-serif,'Apple Color Emoji','Segoe UI Emoji','Segoe UI Symbol';--jp-code-font-size:13px;--jp-code-line-height:1.3077;--jp-code-padding:5px;--jp-code-font-family-default:menlo,consolas,'DejaVu Sans Mono',monospace;--jp-code-font-family:var(--jp-code-font-family-default);--jp-code-presentation-font-size:16px;--jp-code-cursor-width0:1.4px;--jp-code-cursor-width1:2px;--jp-code-cursor-width2:4px;--jp-layout-color0:white;--jp-layout-color1:white;--jp-layout-color2:var(--md-grey-200);--jp-layout-color3:var(--md-grey-400);--jp-layout-color4:var(--md-grey-600);--jp-inverse-layout-color0:#111;--jp-inverse-layout-color1:var(--md-grey-900);--jp-inverse-layout-color2:var(--md-grey-800);--jp-inverse-layout-color3:var(--md-grey-700);--jp-inverse-layout-color4:var(--md-grey-600);--jp-brand-color0:var(--md-blue-900);--jp-brand-color1:var(--md-blue-700);--jp-brand-color2:var(--md-blue-300);--jp-brand-color3:var(--md-blue-100);--jp-brand-color4:var(--md-blue-50);--jp-accent-color0:var(--md-green-900);--jp-accent-color1:var(--md-green-700);--jp-accent-color2:var(--md-green-300);--jp-accent-color3:var(--md-green-100);--jp-warn-color0:var(--md-orange-900);--jp-warn-color1:var(--md-orange-700);--jp-warn-color2:var(--md-orange-300);--jp-warn-color3:var(--md-orange-100);--jp-error-color0:var(--md-red-900);--jp-error-color1:var(--md-red-700);--jp-error-color2:var(--md-red-300);--jp-error-color3:var(--md-red-100);--jp-success-color0:var(--md-green-900);--jp-success-color1:var(--md-green-700);--jp-success-color2:var(--md-green-300);--jp-success-color3:var(--md-green-100);--jp-info-color0:var(--md-cyan-900);--jp-info-color1:var(--md-cyan-700);--jp-info-color2:var(--md-cyan-300);--jp-info-color3:var(--md-cyan-100);--jp-cell-padding:5px;--jp-cell-collapser-width:8px;--jp-cell-collapser-min-height:20px;--jp-cell-collapser-not-active-hover-opacity:.6;--jp-cell-editor-background:var(--md-grey-100);--jp-cell-editor-border-color:var(--md-grey-300);--jp-cell-editor-box-shadow:inset 0 0 2px var(--md-blue-300);--jp-cell-editor-active-background:var(--jp-layout-color0);--jp-cell-editor-active-border-color:var(--jp-brand-color1);--jp-cell-prompt-width:64px;--jp-cell-prompt-font-family:var(--jp-code-font-family-default);--jp-cell-prompt-letter-spacing:0;--jp-cell-prompt-opacity:1;--jp-cell-prompt-not-active-opacity:.5;--jp-cell-prompt-not-active-font-color:var(--md-grey-700);--jp-cell-inprompt-font-color:#307fc1;--jp-cell-outprompt-font-color:#bf5b3d;--jp-notebook-padding:10px;--jp-notebook-select-background:var(--jp-layout-color1);--jp-notebook-multiselected-color:var(--md-blue-50);--jp-notebook-scroll-padding:calc(100% - var(--jp-code-font-size) * var(--jp-code-line-height) - var(--jp-code-padding) - var(--jp-cell-padding) - 1px);--jp-rendermime-error-background:#fdd;--jp-rendermime-table-row-background:var(--md-grey-100);--jp-rendermime-table-row-hover-background:var(--md-light-blue-50);--jp-dialog-background:rgba(0,0,0,0.25);--jp-console-padding:10px;--jp-toolbar-border-color:var(--jp-border-color1);--jp-toolbar-micro-height:8px;--jp-toolbar-background:var(--jp-layout-color1);--jp-toolbar-box-shadow:0 0 2px 0 rgba(0,0,0,0.24);--jp-toolbar-header-margin:4px 4px 0 4px;--jp-toolbar-active-background:var(--md-grey-300);--jp-statusbar-height:24px;--jp-input-box-shadow:inset 0 0 2px var(--md-blue-300);--jp-input-active-background:var(--jp-layout-color1);--jp-input-hover-background:var(--jp-layout-color1);--jp-input-background:var(--md-grey-100);--jp-input-border-color:var(--jp-inverse-border-color);--jp-input-active-border-color:var(--jp-brand-color1);--jp-input-active-box-shadow-color:rgba(19,124,189,0.3);--jp-editor-selected-background:#d9d9d9;--jp-editor-selected-focused-background:#d7d4f0;--jp-editor-cursor-color:var(--jp-ui-font-color0);--jp-mirror-editor-keyword-color:#008000;--jp-mirror-editor-atom-color:#88f;--jp-mirror-editor-number-color:#080;--jp-mirror-editor-def-color:#00f;--jp-mirror-editor-variable-color:var(--md-grey-900);--jp-mirror-editor-variable-2-color:#00366d;--jp-mirror-editor-variable-3-color:#085;--jp-mirror-editor-punctuation-color:#05a;--jp-mirror-editor-property-color:#05a;--jp-mirror-editor-operator-color:#a2f;--jp-mirror-editor-comment-color:#408080;--jp-mirror-editor-string-color:#ba2121;--jp-mirror-editor-string-2-color:#708;--jp-mirror-editor-meta-color:#a2f;--jp-mirror-editor-qualifier-color:#555;--jp-mirror-editor-builtin-color:#008000;--jp-mirror-editor-bracket-color:#997;--jp-mirror-editor-tag-color:#170;--jp-mirror-editor-attribute-color:#00c;--jp-mirror-editor-header-color:blue;--jp-mirror-editor-quote-color:#090;--jp-mirror-editor-link-color:#00c;--jp-mirror-editor-error-color:#f00;--jp-mirror-editor-hr-color:#999;--jp-collaborator-color1:#ffad8e;--jp-collaborator-color2:#dac83d;--jp-collaborator-color3:#72dd76;--jp-collaborator-color4:#00e4d0;--jp-collaborator-color5:#45d4ff;--jp-collaborator-color6:#e2b1ff;--jp-collaborator-color7:#ff9de6;--jp-vega-background:white;--jp-sidebar-min-width:250px;--jp-search-toggle-off-opacity:.5;--jp-search-toggle-hover-opacity:.8;--jp-search-toggle-on-opacity:1;--jp-search-selected-match-background-color:#f5c800;--jp-search-selected-match-color:black;--jp-search-unselected-match-background-color:var(--jp-inverse-layout-color0);--jp-search-unselected-match-color:var(--jp-ui-inverse-font-color0);--jp-icon-contrast-color0:var(--md-purple-600);--jp-icon-contrast-color1:var(--md-green-600);--jp-icon-contrast-color2:var(--md-pink-600);--jp-icon-contrast-color3:var(--md-blue-600);--jp-accept-color-normal:var(--md-blue-700);--jp-accept-color-hover:var(--md-blue-800);--jp-accept-color-active:var(--md-blue-900);--jp-warn-color-normal:var(--md-red-700);--jp-warn-color-hover:var(--md-red-800);--jp-warn-color-active:var(--md-red-900);--jp-reject-color-normal:var(--md-grey-600);--jp-reject-color-hover:var(--md-grey-700);--jp-reject-color-active:var(--md-grey-800);--jp-jupyter-icon-color:#f37626;--jp-notebook-icon-color:#f37626;--jp-json-icon-color:var(--md-orange-700);--jp-console-icon-background-color:var(--md-blue-700);--jp-console-icon-color:white;--jp-terminal-icon-background-color:var(--md-grey-800);--jp-terminal-icon-color:var(--md-grey-200);--jp-text-editor-icon-color:var(--md-grey-700);--jp-inspector-icon-color:var(--md-grey-700);--jp-switch-color:var(--md-grey-400);--jp-switch-true-position-color:var(--md-orange-900)}</style> <style type="text/css">*{-webkit-print-color-adjust:exact}a.anchor-link{display:none}.jp-InputArea{overflow:hidden}.jp-InputArea-editor{overflow:hidden}.cm-editor.cm-s-jupyter .highlight pre{padding:var(--jp-code-padding) 4px;margin:0;font-family:inherit;font-size:inherit;line-height:inherit;color:inherit}.jp-OutputArea-output pre{line-height:inherit;font-family:inherit}.jp-RenderedText pre{color:var(--jp-content-font-color1);font-size:var(--jp-code-font-size)}.jp-Collapser{display:none}@page{margin:.5in}@media print{.jp-Cell-inputWrapper,.jp-Cell-outputWrapper{display:block}}</style> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML-full,Safe"> </script> <script type="text/x-mathjax-config">
    init_mathjax = function() {
        if (window.MathJax) {
        // MathJax loaded
            MathJax.Hub.Config({
                TeX: {
                    equationNumbers: {
                    autoNumber: "AMS",
                    useLabelIds: true
                    }
                },
                tex2jax: {
                    inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true,
                    processEnvironments: true
                },
                displayAlign: 'center',
                CommonHTML: {
                    linebreaks: {
                    automatic: true
                    }
                }
            });

            MathJax.Hub.Queue(["Typeset", MathJax.Hub]);
        }
    }
    init_mathjax();
    </script> <script type="module">
  document.addEventListener("DOMContentLoaded", async () => {
    const diagrams = document.querySelectorAll(".jp-Mermaid > pre.mermaid");
    // do not load mermaidjs if not needed
    if (!diagrams.length) {
      return;
    }
    const mermaid = (await import("https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.2.3/mermaid.esm.min.mjs")).default;

    mermaid.initialize({
      maxTextSize: 100000,
      startOnLoad: false,
      fontFamily: window
        .getComputedStyle(document.body)
        .getPropertyValue("--jp-ui-font-family"),
      theme: document.querySelector("body[data-jp-theme-light='true']")
        ? "default"
        : "dark",
    });

    let _nextMermaidId = 0;

    function makeMermaidImage(svg) {
      const img = document.createElement('img');
      const maxWidth = svg.match(/max-width: (\d+)/);
      if (maxWidth && maxWidth[1]) {
        const width = parseInt(maxWidth[1]);
        if (width && !Number.isNaN(width) && Number.isFinite(width)) {
          img.width = width;
        }
      }
      img.setAttribute('src', `data:image/svg+xml,${encodeURIComponent(svg)}`);
      return img;
    }

    async function makeMermaidError(text) {
      let errorMessage = '';
      try {
        await mermaid.parse(text);
      } catch (err) {
        errorMessage = `${err}`;
      }

      const result = document.createElement('details');
      const summary = document.createElement('summary');
      const pre = document.createElement('pre');
      const code = document.createElement('code');
      code.innerText = text;
      pre.appendChild(code);
      summary.appendChild(pre);
      result.appendChild(summary);

      const warning = document.createElement('pre');
      warning.innerText = errorMessage;
      result.appendChild(warning);
      return result;
    }

    async function renderOneMarmaid(src) {
      const id = `jp-mermaid-${_nextMermaidId++}`;
      const parent = src.parentNode;
      let raw = src.textContent.trim();
      const el = document.createElement("div");
      el.style.visibility = "hidden";
      document.body.appendChild(el);
      let result = null;
      try {
        const { svg } = await mermaid.render(id, raw, el);
        result = makeMermaidImage(svg);
      } catch (err) {
        parent.classList.add("jp-mod-warning");
        result = await makeMermaidError(raw);
      } finally {
        el.remove();
      }
      parent.classList.add("jp-RenderedMermaid");
      parent.appendChild(result);
    }

    void Promise.all([...diagrams].map(renderOneMarmaid));
  });
</script> <style>.jp-RenderedMarkdown .jp-Mermaid:not(.jp-RenderedMermaid){display:none}.jp-RenderedMarkdown .jp-RenderedMermaid.jp-mod-warning{width:auto;padding:10px;border:var(--jp-border-width) solid var(--jp-warn-color2);border-radius:var(--jp-border-radius);color:var(--jp-ui-font-color1);font-size:var(--jp-ui-font-size1);white-space:pre-wrap;word-wrap:break-word}.jp-RenderedMarkdown .jp-RenderedMermaid.jp-mod-warning details>pre{margin-top:1em}.jp-RenderedMarkdown .jp-RenderedMermaid.jp-mod-warning summary{color:var(--jp-warn-color2)}.jp-RenderedMarkdown .jp-RenderedMermaid.jp-mod-warning summary>pre{display:inline-block}.jp-RenderedMermaid>.mermaid{display:none}</style> </head> <body class="jp-Notebook" data-jp-theme-light="true" data-jp-theme-name="JupyterLab Light"> <main> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <h1 id="Image-Classification">Image Classification<a class="anchor-link" href="#Image-Classification"></a></h1><p>In this tutorial, we are going to build a neural network that can classify handwritten digits (0-9)! Does that sound exciting? Probabbly not in this problem domain. However the principles we are going to apply in handwritten digit recognition are equally valid to other visual recognition challanges. Would you like to build a 1000 class image classifier? Are you developing an automated vehicle? Do you want to replicate the human visual system? Read on.</p> <p><em>Disclaimer: the latter two objectives are far more complicated than this tutorial makes vision seem to be. It is almost abusive to consider human vision as simple as convolution.</em></p> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <h3 id="Notice-and-Copyright">Notice and Copyright<a class="anchor-link" href="#Notice-and-Copyright"></a></h3> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>This tutorial was written to complete the Quiz 14 requirement of Data Mining:</p> <blockquote> <p>Complete the MNIST Classifier shown in class and submit the code+output screenshot.</p> <p>Change the network to contain 4 convolution layers with 6, 32, 64, 16 layers, and 3 fully connected layers with 256, 64, 10 nodes in each layer respectively.</p> <p>Use sigmoid activation in all layers except the output layer.</p> </blockquote> <p>And later extended for the Assignment 1 requirement of the same class:</p> <blockquote> <p>Your goal is building CIFAR-10 image classifier.</p> </blockquote> <p>All comments and code were written from memory. No papers, books, Google, stack overflow, or Internet unless noted.</p> <p>Copyright  Jacob Valdez 2021. Released under MIT License.</p> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <h2 id="Getting-Started">Getting Started<a class="anchor-link" href="#Getting-Started"></a></h2> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>As you start to explore github, you'll observe a few common nicknames that we give our packages. I'm just going to import my default go-to's for now:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">IPython.display</span> <span class="k">as</span> <span class="nn">display</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="k">as</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.layers</span> <span class="k">as</span> <span class="nn">tfkl</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>
</pre></div> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <h2 id="The-Data">The Data<a class="anchor-link" href="#The-Data"></a></h2> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>Let's load the <code>mnist</code> dataset and observe a few elements.</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">Y_train</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 0s 0us/step
11501568/11490434 [==============================] - 0s 0us/step
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>5</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>0</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>4</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>1</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)
</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>Notice that each number has an image (stored in <code>X_train/test</code>) and a label (stored in <code>Y_train/test</code>) Each image is 28 by 28 pixels and there are 60000 training examples and 10000 test examples. Note that this dataset is supplied in integers so I'm going to convert it to floating point representation for our neural network:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'before'</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="n">X_test</span><span class="o">/</span><span class="mf">255.</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'after'</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>before uint8
after float64
</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <h2 id="The-Classifier">The Classifier<a class="anchor-link" href="#The-Classifier"></a></h2> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>We're just going to build a plain-old Convolutional Neural Network. The idea of performing convolutions is that not every part of an images has information pertaining to every other part. As we analyze a scene, we can often decompose the visual information relationships into a spatially segmented hierarchy. Convolutional neural networks carry this inductive bias by performing a miniature perceptron operation at every receptive field location in an image. Unless commented below, we'll use keras's default implementations to achieve this:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>  <span class="c1"># give each pixel a 1 dimensional channel</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">GlobalMaxPooling2D</span><span class="p">(),</span>  <span class="c1"># this layer will take the highest value features over all pixels for each of the 16 filters</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'sigmoid'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="p">])</span>
</pre></div> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <h2 id="Training">Training<a class="anchor-link" href="#Training"></a></h2><p>Next, we're goign to train our classifier. Since the data is supplied with integer labels but our model outputs probabilities over 10 classes, we cannot directly differentiate between the two without either</p> <ul> <li>converting <code>y_train</code> and <code>y_test</code> integer labels into one-hot encodings or</li> <li>using a sparse categorical loss function.</li> </ul> <p>I select the latter option for computational and information theoretic reasons. Cross entropy $H(p,q)$ represents the expected amount of extra information needed to encode some code under an existing distribution. Formally, $$H(p,q)=E_{x \sim p(x)}[-\log{q(x)}]$$ This is ideal when our model serves as the posterier $q(x,y)$ and the dataset as the prior $p(x,y)$. Our loss function will then be the sparse categorical cross entropy between our model's estimates and the dataset labels. Keras provides a high level interface to implement this in the <code>model.compile</code> function:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
reshape (Reshape)            (None, 28, 28, 1)         0         
_________________________________________________________________
conv2d (Conv2D)              (None, 26, 26, 6)         60        
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 24, 24, 32)        1760      
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 22, 22, 64)        18496     
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 20, 20, 16)        9232      
_________________________________________________________________
global_max_pooling2d (Global (None, 16)                0         
_________________________________________________________________
dense (Dense)                (None, 256)               4352      
_________________________________________________________________
dense_1 (Dense)              (None, 64)                16448     
_________________________________________________________________
dense_2 (Dense)              (None, 10)                650       
=================================================================
Total params: 50,998
Trainable params: 50,998
Non-trainable params: 0
_________________________________________________________________
</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>Now it's time to actually train the model. Let's supply our training a testing data and see how training progresses:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">Y_train</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">),</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Epoch 1/10
938/938 - 22s - loss: 2.3095 - val_loss: 2.3083
Epoch 2/10
938/938 - 5s - loss: 2.0046 - val_loss: 1.8036
Epoch 3/10
938/938 - 5s - loss: 1.5575 - val_loss: 1.3240
Epoch 4/10
938/938 - 5s - loss: 1.0506 - val_loss: 0.8737
Epoch 5/10
938/938 - 5s - loss: 0.6946 - val_loss: 0.5424
Epoch 6/10
938/938 - 5s - loss: 0.5413 - val_loss: 0.5187
Epoch 7/10
938/938 - 5s - loss: 0.4601 - val_loss: 0.4580
Epoch 8/10
938/938 - 5s - loss: 0.3984 - val_loss: 0.3420
Epoch 9/10
938/938 - 5s - loss: 0.3344 - val_loss: 0.2832
Epoch 10/10
938/938 - 5s - loss: 0.2850 - val_loss: 0.2613
</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>What's happening? The loss isn't improving.</p> <p>Why can't we just plug and chug whatever data we want into our model? Consider two reasons:</p> <ol> <li>There is no globally optimal universal approximator, and specialized models such as this CNN may not have sufficient inductive priors to estimate their data generating distribution</li> <li>Sigmoid-type activation functions saturate the gradients relatively easily. This means that when the input is large in the positive or negative extrema, gradients are effectively zero. During backpropagation, the gradients hardly penetrate the top layer and only slowly penetrate lower and lower into the model. (See the paper that introduced batch norm and <em>The Principles of Deep Learning Theory</em> for a longer discussion of these points.)</li> </ol> <p>We can solve this problem by changing our activation function to something that is still nonlinear but allows gradients to flow faster over the epochs. My go-to activation function is the rectified linear unit <code>relu</code>:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>  <span class="c1"># give each pixel a 1 dimensional channel</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">GlobalMaxPooling2D</span><span class="p">(),</span>  <span class="c1"># this layer will take the highest value features over all pixels for each of the 16 filters</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
<span class="p">])</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">Y_train</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">),</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Epoch 1/10
938/938 - 6s - loss: 0.6999 - val_loss: 0.3878
Epoch 2/10
938/938 - 5s - loss: 0.2282 - val_loss: 0.1778
Epoch 3/10
938/938 - 5s - loss: 0.1500 - val_loss: 0.1543
Epoch 4/10
938/938 - 5s - loss: 0.1216 - val_loss: 0.1268
Epoch 5/10
938/938 - 5s - loss: 0.1027 - val_loss: 0.0911
Epoch 6/10
938/938 - 5s - loss: 0.0929 - val_loss: 0.0902
Epoch 7/10
938/938 - 5s - loss: 0.0808 - val_loss: 0.0770
Epoch 8/10
938/938 - 5s - loss: 0.0733 - val_loss: 0.0844
Epoch 9/10
938/938 - 5s - loss: 0.0680 - val_loss: 0.0790
Epoch 10/10
938/938 - 5s - loss: 0.0632 - val_loss: 0.0964
</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>What a significant change. <code>relu</code> definitely performed better in the first 10 epochs than <code>sigmoid</code>. Feel free to experiment yourself with this model.</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="c1"># your code here (download this notebook at https://raw.githubusercontent.com/JacobFV/jacobfv.github.io/source/notebooks/MNIST_Classifier.ipynb)</span>
</pre></div> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <h2 id="How-to-Overfit-Your-Dev-Set">How to Overfit Your Dev Set<a class="anchor-link" href="#How-to-Overfit-Your-Dev-Set"></a></h2><p>I hope you've enjoyed learning about machine learning by tweaking the hyperparameters of your model. Likely you realize at this point that we could tweek hyperparameters forever. Why not let machine learn machine learning instead? <a href="https://docs.ray.io/en/latest/tune/index.html"><code>ray-tune</code></a> is a powerful tool we can use to find the optimal hyperparameters for a model. Per its official docs, <code>ray.tune</code> frames its optimization problem into a run -- report metric -- optimize iteration loop. To give you the idea, here's their <a href="https://docs.ray.io/en/latest/tune/index.html">quick start code</a>:</p> <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray</span> <span class="kn">import</span> <span class="n">tune</span>


<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mf">0.1</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">step</span> <span class="o">/</span> <span class="mi">100</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="mf">0.1</span>


<span class="k">def</span> <span class="nf">training_function</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="c1"># Hyperparameters</span>
    <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s2">"alpha"</span><span class="p">],</span> <span class="n">config</span><span class="p">[</span><span class="s2">"beta"</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="c1"># Iterative training function - can be any arbitrary training procedure.</span>
        <span class="n">intermediate_score</span> <span class="o">=</span> <span class="n">objective</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
        <span class="c1"># Feed the score back back to Tune.</span>
        <span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">mean_loss</span><span class="o">=</span><span class="n">intermediate_score</span><span class="p">)</span>


<span class="n">analysis</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">training_function</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">"alpha"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]),</span>
        <span class="s2">"beta"</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Best config: "</span><span class="p">,</span> <span class="n">analysis</span><span class="o">.</span><span class="n">get_best_config</span><span class="p">(</span>
    <span class="n">metric</span><span class="o">=</span><span class="s2">"mean_loss"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"min"</span><span class="p">))</span>

<span class="c1"># Get a dataframe for analyzing trial results.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">analysis</span><span class="o">.</span><span class="n">results_df</span>
</pre></div> <p>Let's make an isomorphic case with our MNIST classifier: We'll have a triple optimization loop. On the inside, <code>SGD</code>, <code>Adam</code>, <code>RMSProp</code>, or another first order optimizer will backpropagate gradients into the trainable parameters. After 10 epochs, a hyperparameter optimizer will tune our choice of activation function, hidden convolution and dense layers, hidden depth, loss function, and inner optimizer. Finally, we'll be the slow optimizer and make changes to the primary and secondary optimization loops when needed. Let's start by defining our meta-objective:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="c1"># on a separate console run:</span>
<span class="c1"># pip install -q ray[tune]</span>
<span class="c1"># ray start --head --num-cpus 2 --num-gpus 1</span>

<span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">ray.tune</span> <span class="k">as</span> <span class="nn">tune</span>
<span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">address</span><span class="o">=</span><span class="s1">'auto'</span><span class="p">,</span> <span class="n">_redis_password</span><span class="o">=</span><span class="s1">'5241590000000000'</span><span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>2021-11-01 13:39:23,542	INFO worker.py:827 -- Connecting to existing Ray cluster at address: 10.138.0.10:6379
</pre> </div> </div> <div class="jp-OutputArea-child jp-OutputArea-executeResult"> <div class="jp-OutputPrompt jp-OutputArea-prompt">Out[]:</div> <div class="jp-RenderedText jp-OutputArea-output jp-OutputArea-executeResult" data-mime-type="text/plain" tabindex="0"> <pre>{'node_ip_address': '10.138.0.10',
 'raylet_ip_address': '10.138.0.10',
 'redis_address': '10.138.0.10:6379',
 'object_store_address': '/tmp/ray/session_2021-11-01_13-39-17_184816_6838/sockets/plasma_store',
 'raylet_socket_name': '/tmp/ray/session_2021-11-01_13-39-17_184816_6838/sockets/raylet',
 'webui_url': None,
 'session_dir': '/tmp/ray/session_2021-11-01_13-39-17_184816_6838',
 'metrics_export_port': 49266,
 'node_id': '06fd01adf83b504b561996944ea682fc4135d39c2ebd6199b713c524'}</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <h3 id="Iteration-1">Iteration 1<a class="anchor-link" href="#Iteration-1"></a></h3> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">meta_loss</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>

    <span class="c1"># load dataset</span>
    <span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_train</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">/</span> <span class="mf">255.</span>
    

    <span class="c1"># number of units in each layer (if applicable)</span>
    <span class="n">N1</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'N1'</span><span class="p">]</span>
    <span class="n">N2</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'N2'</span><span class="p">]</span>
    <span class="n">N3</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'N3'</span><span class="p">]</span>
    <span class="n">N4</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'N4'</span><span class="p">]</span>
    <span class="n">N5</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'N5'</span><span class="p">]</span>
    <span class="n">N6</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'N6'</span><span class="p">]</span>
    <span class="n">N7</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'N7'</span><span class="p">]</span>

    <span class="c1"># layer type: conv2d, dense, maxpooling2d, flatten, dropout, none</span>
    <span class="c1"># exactly one flatten layer is allowed and conv2d must be placed before flatten</span>
    <span class="c1"># errors are indicated by massive negative losses</span>
    <span class="n">L1</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'L1'</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">L2</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'L2'</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">L3</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'L3'</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">L4</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'L4'</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">L5</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'L5'</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">L6</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'L6'</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="n">L7</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'L7'</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

    <span class="n">conv_activation</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'conv_activation'</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>  <span class="c1"># 'sigmoid', 'relu', 'tanh', 'elu', 'selu', 'softplus', 'softsign'</span>
    <span class="n">dense_activation</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'dense_activation'</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>  <span class="c1"># 'sigmoid', 'relu', 'tanh', 'elu', 'selu', 'softplus', 'softsign'</span>
    <span class="n">initial_learning_rate</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">config</span><span class="p">[</span><span class="s1">'initial_learning_rate_exp'</span><span class="p">]</span>  <span class="c1"># -4.0 to -1.0</span>
    <span class="n">learning_rate_rate</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">config</span><span class="p">[</span><span class="s1">'learning_rate_rate'</span><span class="p">]</span>  <span class="c1"># 0.0 to 1.0</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'optimizer_name'</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>  <span class="c1"># 'adam', 'sgd', 'rmsprop', 'adagrad', 'adadelta', 'adamax', or 'nadam'</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">]</span>  <span class="c1"># 4 to 1024, integers only</span>
    <span class="n">loss_name</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'loss_name'</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>  <span class="c1"># 'mse', 'mae', 'mape', 'categorical_crossentropy', or 'sparse_categorical_crossentropy'</span>

    <span class="c1"># activation functions</span>
    <span class="n">activations</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'sigmoid'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">,</span>
        <span class="s1">'relu'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="s1">'tanh'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span>
        <span class="s1">'elu'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">elu</span><span class="p">,</span>
        <span class="s1">'selu'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">selu</span><span class="p">,</span>
        <span class="s1">'softplus'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softplus</span><span class="p">,</span>
        <span class="s1">'softsign'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softsign</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">conv_activation</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="n">conv_activation</span><span class="p">]</span>
    <span class="n">dense_activation</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="n">dense_activation</span><span class="p">]</span>

    <span class="c1"># make the loss function</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'mse'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanSquaredError</span><span class="p">(),</span>
        <span class="s1">'mae'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanAbsoluteError</span><span class="p">(),</span>
        <span class="s1">'mape'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">MeanAbsolutePercentageError</span><span class="p">(),</span>
        <span class="s1">'categorical_crossentropy'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">CategoricalCrossentropy</span><span class="p">(),</span>
        <span class="s1">'sparse_categorical_crossentropy'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="p">}</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="n">loss_name</span><span class="p">]</span>

    <span class="c1"># convert labels to one-hot vectors for dense loss penalties</span>
    <span class="k">if</span> <span class="n">loss_name</span> <span class="o">!=</span> <span class="s1">'spare_categorical_crossentropy'</span><span class="p">:</span>
        <span class="n">Y_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        <span class="n">Y_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">depth</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    
    <span class="c1"># optimizer and learning rate</span>
    <span class="n">optimziers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'SGD'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span>
        <span class="s1">'RMSprop'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">,</span>
        <span class="s1">'Adagrad'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">,</span>
        <span class="s1">'Adadelta'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">,</span>
        <span class="s1">'Adam'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
        <span class="s1">'Adamax'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adamax</span><span class="p">,</span>
        <span class="s1">'Nadam'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimziers</span><span class="p">[</span><span class="n">optimizer_name</span><span class="p">](</span><span class="n">initial_learning_rate</span><span class="p">)</span>

    <span class="n">learning_rate_scheduler</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">initial_learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">learning_rate_rate</span> <span class="o">**</span> <span class="n">epoch</span><span class="p">))</span>

    <span class="c1"># build model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># give each pixel a 1 dimensional channel</span>
    <span class="p">])</span>

    <span class="n">flattened</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">for</span> <span class="n">L</span><span class="p">,</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">L1</span><span class="p">,</span> <span class="n">L2</span><span class="p">,</span> <span class="n">L3</span><span class="p">,</span> <span class="n">L4</span><span class="p">,</span> <span class="n">L5</span><span class="p">,</span> <span class="n">L6</span><span class="p">,</span> <span class="n">L7</span><span class="p">],</span> <span class="p">[</span><span class="n">N1</span><span class="p">,</span> <span class="n">N2</span><span class="p">,</span> <span class="n">N3</span><span class="p">,</span> <span class="n">N4</span><span class="p">,</span> <span class="n">N5</span><span class="p">,</span> <span class="n">N6</span><span class="p">,</span> <span class="n">N7</span><span class="p">]):</span>
        <span class="k">if</span> <span class="n">L</span> <span class="o">==</span> <span class="s1">'conv2d'</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">flattened</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> 
                                      <span class="n">activation</span><span class="o">=</span><span class="n">conv_activation</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">L</span> <span class="o">==</span> <span class="s1">'maxpooling2d'</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">flattened</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tfkl</span><span class="o">.</span><span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
        <span class="k">elif</span> <span class="n">L</span> <span class="o">==</span> <span class="s1">'flatten'</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">flattened</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tfkl</span><span class="o">.</span><span class="n">Flatten</span><span class="p">())</span>
                <span class="n">flattened</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">L</span> <span class="o">==</span> <span class="s1">'dropout'</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tfkl</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">L</span> <span class="o">==</span> <span class="s1">'dense'</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">flattened</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">dense_activation</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">L</span> <span class="o">==</span> <span class="s1">'none'</span><span class="p">:</span>  <span class="c1"># no more hidden layers</span>
            <span class="k">break</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'unknown layer type </span><span class="si">{</span><span class="n">L</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>  <span class="c1"># softmax activation is used for classification</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

    <span class="c1"># train model</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">Y_train</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">learning_rate_scheduler</span><span class="p">],</span>
        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">),</span>
        <span class="n">validation_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># report validation loss</span>
    <span class="n">final_val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_loss'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">validation_loss</span><span class="o">=</span><span class="n">final_val_loss</span><span class="p">)</span>
</pre></div> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>Now just looking at the hyperparameter space we've defined, you can see why this is overkill for MNIST. Each run of <code>meta_loss</code> runs a full 10 iterations on the optimization loop beneath it. To meet these computation demands, I'm running this notebook on a deep learning optimized Google Cloud VM (n1-highmem-2 with an nvidia-tesla-k80). Learn how you can do this on your own for AWS or GCP from my <a href="https://jacobfv.github.io/blog/rtc-jupyterlab-in-the-cloud/">previous notebook</a>.</p> <p>Without further hesitation (the assignment due date is approaching), let's start tuning!</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">analysis</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">meta_loss</span><span class="p">,</span>
    <span class="n">resources_per_trial</span><span class="o">=</span><span class="p">{</span><span class="s1">'gpu'</span><span class="p">:</span> <span class="mi">1</span><span class="p">},</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">'N1'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">256</span><span class="p">]),</span>
        <span class="s1">'N2'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">256</span><span class="p">]),</span>
        <span class="s1">'N3'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">256</span><span class="p">]),</span>
        <span class="s1">'N4'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">256</span><span class="p">]),</span>
        <span class="s1">'N5'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">256</span><span class="p">]),</span>
        <span class="s1">'N6'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">256</span><span class="p">]),</span>
        <span class="s1">'N7'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">192</span><span class="p">,</span> <span class="mi">256</span><span class="p">]),</span>
        <span class="s1">'L1'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="s1">'conv2d'</span><span class="p">,</span> <span class="s1">'dense'</span><span class="p">,</span> <span class="s1">'maxpooling2d'</span><span class="p">,</span> <span class="s1">'flatten'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span> <span class="s1">'none'</span><span class="p">]),</span>
        <span class="s1">'L2'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="s1">'conv2d'</span><span class="p">,</span> <span class="s1">'dense'</span><span class="p">,</span> <span class="s1">'maxpooling2d'</span><span class="p">,</span> <span class="s1">'flatten'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span> <span class="s1">'none'</span><span class="p">]),</span>
        <span class="s1">'L3'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="s1">'conv2d'</span><span class="p">,</span> <span class="s1">'dense'</span><span class="p">,</span> <span class="s1">'maxpooling2d'</span><span class="p">,</span> <span class="s1">'flatten'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span> <span class="s1">'none'</span><span class="p">]),</span>
        <span class="s1">'L4'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="s1">'conv2d'</span><span class="p">,</span> <span class="s1">'dense'</span><span class="p">,</span> <span class="s1">'maxpooling2d'</span><span class="p">,</span> <span class="s1">'flatten'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span> <span class="s1">'none'</span><span class="p">]),</span>
        <span class="s1">'L5'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="s1">'conv2d'</span><span class="p">,</span> <span class="s1">'dense'</span><span class="p">,</span> <span class="s1">'maxpooling2d'</span><span class="p">,</span> <span class="s1">'flatten'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span> <span class="s1">'none'</span><span class="p">]),</span>
        <span class="s1">'L6'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="s1">'conv2d'</span><span class="p">,</span> <span class="s1">'dense'</span><span class="p">,</span> <span class="s1">'maxpooling2d'</span><span class="p">,</span> <span class="s1">'flatten'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span> <span class="s1">'none'</span><span class="p">]),</span>
        <span class="s1">'L7'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="s1">'conv2d'</span><span class="p">,</span> <span class="s1">'dense'</span><span class="p">,</span> <span class="s1">'maxpooling2d'</span><span class="p">,</span> <span class="s1">'flatten'</span><span class="p">,</span> <span class="s1">'dropout'</span><span class="p">,</span> <span class="s1">'none'</span><span class="p">]),</span>
        <span class="s1">'dense_activation'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="s1">'sigmoid'</span><span class="p">,</span> <span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'selu'</span><span class="p">,</span> <span class="s1">'softplus'</span><span class="p">,</span> <span class="s1">'softsign'</span><span class="p">]),</span>
        <span class="s1">'conv_activation'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="s1">'sigmoid'</span><span class="p">,</span> <span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'selu'</span><span class="p">,</span> <span class="s1">'softplus'</span><span class="p">,</span> <span class="s1">'softsign'</span><span class="p">]),</span>
        <span class="s1">'initial_learning_rate_exp'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">4.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">),</span>
        <span class="s1">'learning_rate_rate'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
        <span class="s1">'optimizer_name'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">'adam'</span><span class="p">,</span> <span class="s1">'sgd'</span><span class="p">,</span> <span class="s1">'rmsprop'</span><span class="p">,</span> <span class="s1">'adagrad'</span><span class="p">,</span> <span class="s1">'adadelta'</span><span class="p">,</span> <span class="s1">'adamax'</span><span class="p">,</span> <span class="s1">'nadam'</span><span class="p">]),</span>
        <span class="s1">'batch_size'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]),</span>
        <span class="s1">'loss_name'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">'mse'</span><span class="p">,</span> <span class="s1">'mae'</span><span class="p">,</span> <span class="s1">'mape'</span><span class="p">,</span> <span class="s1">'categorical_crossentropy'</span><span class="p">,</span> <span class="s1">'sparse_categorical_crossentropy'</span><span class="p">]),</span>
    <span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Best config: "</span><span class="p">,</span> <span class="n">analysis</span><span class="o">.</span><span class="n">get_best_config</span><span class="p">(</span>
    <span class="n">metric</span><span class="o">=</span><span class="s2">"val_loss"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"min"</span><span class="p">))</span>

<span class="c1"># Get a dataframe for analyzing trial results.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">analysis</span><span class="o">.</span><span class="n">results_df</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>2021-11-01 12:24:01,660	WARNING function_runner.py:559 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.
/opt/conda/lib/python3.7/site-packages/ray/tune/suggest/basic_variant.py:289: UserWarning: The number of pre-generated samples (267302874351744) exceeds the serialization threshold (1000000). Resume ability is disabled. To fix this, reduce the number of dimensions/size of the provided grid search.
  f"The number of pre-generated samples ({grid_vals}) "
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.4/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.21 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01<br/>Number of trials: 16/267302874351744 (16 PENDING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th>L1 </th><th>L2 </th><th>L3 </th><th>L4 </th><th>L5 </th><th>L6 </th><th>L7 </th><th style="text-align: right;"> N1</th><th style="text-align: right;"> N2</th><th style="text-align: right;"> N3</th><th style="text-align: right;"> N4</th><th style="text-align: right;"> N5</th><th style="text-align: right;"> N6</th><th style="text-align: right;"> N7</th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th style="text-align: right;"> initial_learning_rate_exp</th><th style="text-align: right;"> learning_rate_rate</th><th>loss_name </th><th>optimizer_name </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00000</td><td>PENDING </td><td> </td><td>conv2d </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.51525</td><td style="text-align: right;"> 0.553209 </td><td>mape </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00001</td><td>PENDING </td><td> </td><td>dense </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.37358</td><td style="text-align: right;"> 0.314978 </td><td>sparse_categorical_crossentropy</td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00002</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.8581 </td><td style="text-align: right;"> 0.512218 </td><td>sparse_categorical_crossentropy</td><td>adamax </td></tr> <tr><td>meta_loss_98963_00003</td><td>PENDING </td><td> </td><td>flatten </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.27046</td><td style="text-align: right;"> 0.454703 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00004</td><td>PENDING </td><td> </td><td>dropout </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.53965</td><td style="text-align: right;"> 0.861406 </td><td>categorical_crossentropy </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00005</td><td>PENDING </td><td> </td><td>none </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.50222</td><td style="text-align: right;"> 0.955176 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00006</td><td>PENDING </td><td> </td><td>conv2d </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.40886</td><td style="text-align: right;"> 0.878881 </td><td>mae </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00007</td><td>PENDING </td><td> </td><td>dense </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.66232</td><td style="text-align: right;"> 0.355708 </td><td>mae </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00008</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 64</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.15489</td><td style="text-align: right;"> 0.736778 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00009</td><td>PENDING </td><td> </td><td>flatten </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.96978</td><td style="text-align: right;"> 0.814146 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00010</td><td>PENDING </td><td> </td><td>dropout </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.84345</td><td style="text-align: right;"> 0.335166 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00011</td><td>PENDING </td><td> </td><td>none </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.12773</td><td style="text-align: right;"> 0.515024 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00012</td><td>PENDING </td><td> </td><td>conv2d </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.44683</td><td style="text-align: right;"> 0.949793 </td><td>mse </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00013</td><td>PENDING </td><td> </td><td>dense </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.7508 </td><td style="text-align: right;"> 0.0587266</td><td>categorical_crossentropy </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00014</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.15043</td><td style="text-align: right;"> 0.594349 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00015</td><td>PENDING </td><td> </td><td>flatten </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.01626</td><td style="text-align: right;"> 0.938932 </td><td>mse </td><td>adagrad </td></tr> </tbody> </table><br/><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre><span class="ansi-cyan-fg">(ImplicitFunc pid=1145)</span> Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
   16384/11490434 [..............................] - ETA: 0s
11493376/11490434 [==============================] - 0s 0us/step
11501568/11490434 [==============================] - 0s 0us/step
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 2.0/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.21 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01<br/>Number of trials: 17/267302874351744 (16 PENDING, 1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th>L1 </th><th>L2 </th><th>L3 </th><th>L4 </th><th>L5 </th><th>L6 </th><th>L7 </th><th style="text-align: right;"> N1</th><th style="text-align: right;"> N2</th><th style="text-align: right;"> N3</th><th style="text-align: right;"> N4</th><th style="text-align: right;"> N5</th><th style="text-align: right;"> N6</th><th style="text-align: right;"> N7</th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th style="text-align: right;"> initial_learning_rate_exp</th><th style="text-align: right;"> learning_rate_rate</th><th>loss_name </th><th>optimizer_name </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00000</td><td>RUNNING </td><td> </td><td>conv2d </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.51525</td><td style="text-align: right;"> 0.553209 </td><td>mape </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00001</td><td>PENDING </td><td> </td><td>dense </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.37358</td><td style="text-align: right;"> 0.314978 </td><td>sparse_categorical_crossentropy</td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00002</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.8581 </td><td style="text-align: right;"> 0.512218 </td><td>sparse_categorical_crossentropy</td><td>adamax </td></tr> <tr><td>meta_loss_98963_00003</td><td>PENDING </td><td> </td><td>flatten </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.27046</td><td style="text-align: right;"> 0.454703 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00004</td><td>PENDING </td><td> </td><td>dropout </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.53965</td><td style="text-align: right;"> 0.861406 </td><td>categorical_crossentropy </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00005</td><td>PENDING </td><td> </td><td>none </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.50222</td><td style="text-align: right;"> 0.955176 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00006</td><td>PENDING </td><td> </td><td>conv2d </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.40886</td><td style="text-align: right;"> 0.878881 </td><td>mae </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00007</td><td>PENDING </td><td> </td><td>dense </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.66232</td><td style="text-align: right;"> 0.355708 </td><td>mae </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00008</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 64</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.15489</td><td style="text-align: right;"> 0.736778 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00009</td><td>PENDING </td><td> </td><td>flatten </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.96978</td><td style="text-align: right;"> 0.814146 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00010</td><td>PENDING </td><td> </td><td>dropout </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.84345</td><td style="text-align: right;"> 0.335166 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00011</td><td>PENDING </td><td> </td><td>none </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.12773</td><td style="text-align: right;"> 0.515024 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00012</td><td>PENDING </td><td> </td><td>conv2d </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.44683</td><td style="text-align: right;"> 0.949793 </td><td>mse </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00013</td><td>PENDING </td><td> </td><td>dense </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.7508 </td><td style="text-align: right;"> 0.0587266</td><td>categorical_crossentropy </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00014</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.15043</td><td style="text-align: right;"> 0.594349 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00015</td><td>PENDING </td><td> </td><td>flatten </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.01626</td><td style="text-align: right;"> 0.938932 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00016</td><td>PENDING </td><td> </td><td>dropout </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.70958</td><td style="text-align: right;"> 0.0631872</td><td>mape </td><td>sgd </td></tr> </tbody> </table><br/><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre><span class="ansi-cyan-fg">(pid=1145)</span> 2021-11-01 12:24:08.783944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1145)</span> 2021-11-01 12:24:08.941310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1145)</span> 2021-11-01 12:24:08.942175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1145)</span> 2021-11-01 12:24:08.944842: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
<span class="ansi-cyan-fg">(pid=1145)</span> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
<span class="ansi-cyan-fg">(pid=1145)</span> 2021-11-01 12:24:08.945198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1145)</span> 2021-11-01 12:24:08.946028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1145)</span> 2021-11-01 12:24:08.946751: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1145)</span> 2021-11-01 12:24:11.377990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1145)</span> 2021-11-01 12:24:11.378975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1145)</span> 2021-11-01 12:24:11.379808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1145)</span> 2021-11-01 12:24:11,436	ERROR function_runner.py:266 -- Runner Thread raised error.
<span class="ansi-cyan-fg">(pid=1145)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=1145)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=1145)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=1145)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=1145)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
<span class="ansi-cyan-fg">(pid=1145)</span>     return target(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
<span class="ansi-cyan-fg">(pid=1145)</span>     on_value = ops.convert_to_tensor(1, dtype, name="on_value")
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=1145)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=1145)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=1145)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=1145)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=1145)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=1145)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=1145)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=1145)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=1145)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=1145)</span> Exception in thread Thread-2:
<span class="ansi-cyan-fg">(pid=1145)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
<span class="ansi-cyan-fg">(pid=1145)</span>     self.run()
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 279, in run
<span class="ansi-cyan-fg">(pid=1145)</span>     raise e
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=1145)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=1145)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=1145)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=1145)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
<span class="ansi-cyan-fg">(pid=1145)</span>     return target(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
<span class="ansi-cyan-fg">(pid=1145)</span>     on_value = ops.convert_to_tensor(1, dtype, name="on_value")
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=1145)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=1145)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=1145)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=1145)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=1145)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=1145)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=1145)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=1145)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=1145)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=1145)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=1145)</span> 
2021-11-01 12:24:11,639	ERROR trial_runner.py:846 -- Trial meta_loss_98963_00000: Error processing event.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 812, in _process_trial
    results = self.trial_executor.fetch_result(trial)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 767, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/opt/conda/lib/python3.7/site-packages/ray/_private/client_mode_hook.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/ray/worker.py", line 1621, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TuneError): <span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=1145, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7fda288a30d0&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 189, in train_buffered
    result = self.train()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 248, in train
    result = self.step()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 379, in step
    self._report_thread_runner_error(block=True)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 527, in _report_thread_runner_error
    ("Trial raised an exception. Traceback:\n{}".format(err_tb_str)
ray.tune.error.TuneError: Trial raised an exception. Traceback:
<span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=1145, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7fda288a30d0&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
    self._entrypoint()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
    self._status_reporter.get_checkpoint())
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
    output = fn()
  File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
    return target(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
    on_value = ops.convert_to_tensor(1, dtype, name="on_value")
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
    allow_broadcast=True)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
MemoryError: std::bad_alloc
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Result for meta_loss_98963_00000:
  {}
  
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.4/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.21 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01<br/>Number of trials: 18/267302874351744 (1 ERROR, 16 PENDING, 1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th>L1 </th><th>L2 </th><th>L3 </th><th>L4 </th><th>L5 </th><th>L6 </th><th>L7 </th><th style="text-align: right;"> N1</th><th style="text-align: right;"> N2</th><th style="text-align: right;"> N3</th><th style="text-align: right;"> N4</th><th style="text-align: right;"> N5</th><th style="text-align: right;"> N6</th><th style="text-align: right;"> N7</th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th style="text-align: right;"> initial_learning_rate_exp</th><th style="text-align: right;"> learning_rate_rate</th><th>loss_name </th><th>optimizer_name </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00001</td><td>RUNNING </td><td> </td><td>dense </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.37358</td><td style="text-align: right;"> 0.314978 </td><td>sparse_categorical_crossentropy</td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00002</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.8581 </td><td style="text-align: right;"> 0.512218 </td><td>sparse_categorical_crossentropy</td><td>adamax </td></tr> <tr><td>meta_loss_98963_00003</td><td>PENDING </td><td> </td><td>flatten </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.27046</td><td style="text-align: right;"> 0.454703 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00004</td><td>PENDING </td><td> </td><td>dropout </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.53965</td><td style="text-align: right;"> 0.861406 </td><td>categorical_crossentropy </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00005</td><td>PENDING </td><td> </td><td>none </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.50222</td><td style="text-align: right;"> 0.955176 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00006</td><td>PENDING </td><td> </td><td>conv2d </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.40886</td><td style="text-align: right;"> 0.878881 </td><td>mae </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00007</td><td>PENDING </td><td> </td><td>dense </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.66232</td><td style="text-align: right;"> 0.355708 </td><td>mae </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00008</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 64</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.15489</td><td style="text-align: right;"> 0.736778 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00009</td><td>PENDING </td><td> </td><td>flatten </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.96978</td><td style="text-align: right;"> 0.814146 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00010</td><td>PENDING </td><td> </td><td>dropout </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.84345</td><td style="text-align: right;"> 0.335166 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00011</td><td>PENDING </td><td> </td><td>none </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.12773</td><td style="text-align: right;"> 0.515024 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00012</td><td>PENDING </td><td> </td><td>conv2d </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.44683</td><td style="text-align: right;"> 0.949793 </td><td>mse </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00013</td><td>PENDING </td><td> </td><td>dense </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.7508 </td><td style="text-align: right;"> 0.0587266</td><td>categorical_crossentropy </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00014</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.15043</td><td style="text-align: right;"> 0.594349 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00015</td><td>PENDING </td><td> </td><td>flatten </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.01626</td><td style="text-align: right;"> 0.938932 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00016</td><td>PENDING </td><td> </td><td>dropout </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.70958</td><td style="text-align: right;"> 0.0631872</td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00017</td><td>PENDING </td><td> </td><td>none </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.41504</td><td style="text-align: right;"> 0.482399 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00000</td><td>ERROR </td><td> </td><td>conv2d </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.51525</td><td style="text-align: right;"> 0.553209 </td><td>mape </td><td>adagrad </td></tr> </tbody> </table><br/>Number of errored trials: 1<br/><table> <thead> <tr><th>Trial name </th><th style="text-align: right;"> # failures</th><th>error file </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00000</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00000_0_L1=conv2d,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,b_2021-11-01_12-24-02/error.txt</td></tr> </tbody> </table><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 2.0/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.21 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01<br/>Number of trials: 18/267302874351744 (1 ERROR, 16 PENDING, 1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th>L1 </th><th>L2 </th><th>L3 </th><th>L4 </th><th>L5 </th><th>L6 </th><th>L7 </th><th style="text-align: right;"> N1</th><th style="text-align: right;"> N2</th><th style="text-align: right;"> N3</th><th style="text-align: right;"> N4</th><th style="text-align: right;"> N5</th><th style="text-align: right;"> N6</th><th style="text-align: right;"> N7</th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th style="text-align: right;"> initial_learning_rate_exp</th><th style="text-align: right;"> learning_rate_rate</th><th>loss_name </th><th>optimizer_name </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00001</td><td>RUNNING </td><td> </td><td>dense </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.37358</td><td style="text-align: right;"> 0.314978 </td><td>sparse_categorical_crossentropy</td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00002</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.8581 </td><td style="text-align: right;"> 0.512218 </td><td>sparse_categorical_crossentropy</td><td>adamax </td></tr> <tr><td>meta_loss_98963_00003</td><td>PENDING </td><td> </td><td>flatten </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.27046</td><td style="text-align: right;"> 0.454703 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00004</td><td>PENDING </td><td> </td><td>dropout </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.53965</td><td style="text-align: right;"> 0.861406 </td><td>categorical_crossentropy </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00005</td><td>PENDING </td><td> </td><td>none </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.50222</td><td style="text-align: right;"> 0.955176 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00006</td><td>PENDING </td><td> </td><td>conv2d </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.40886</td><td style="text-align: right;"> 0.878881 </td><td>mae </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00007</td><td>PENDING </td><td> </td><td>dense </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.66232</td><td style="text-align: right;"> 0.355708 </td><td>mae </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00008</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 64</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.15489</td><td style="text-align: right;"> 0.736778 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00009</td><td>PENDING </td><td> </td><td>flatten </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.96978</td><td style="text-align: right;"> 0.814146 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00010</td><td>PENDING </td><td> </td><td>dropout </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.84345</td><td style="text-align: right;"> 0.335166 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00011</td><td>PENDING </td><td> </td><td>none </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.12773</td><td style="text-align: right;"> 0.515024 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00012</td><td>PENDING </td><td> </td><td>conv2d </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.44683</td><td style="text-align: right;"> 0.949793 </td><td>mse </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00013</td><td>PENDING </td><td> </td><td>dense </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.7508 </td><td style="text-align: right;"> 0.0587266</td><td>categorical_crossentropy </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00014</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.15043</td><td style="text-align: right;"> 0.594349 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00015</td><td>PENDING </td><td> </td><td>flatten </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.01626</td><td style="text-align: right;"> 0.938932 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00016</td><td>PENDING </td><td> </td><td>dropout </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.70958</td><td style="text-align: right;"> 0.0631872</td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00017</td><td>PENDING </td><td> </td><td>none </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.41504</td><td style="text-align: right;"> 0.482399 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00000</td><td>ERROR </td><td> </td><td>conv2d </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.51525</td><td style="text-align: right;"> 0.553209 </td><td>mape </td><td>adagrad </td></tr> </tbody> </table><br/>Number of errored trials: 1<br/><table> <thead> <tr><th>Trial name </th><th style="text-align: right;"> # failures</th><th>error file </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00000</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00000_0_L1=conv2d,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,b_2021-11-01_12-24-02/error.txt</td></tr> </tbody> </table><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre><span class="ansi-cyan-fg">(pid=1185)</span> 2021-11-01 12:24:17.581494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1185)</span> 2021-11-01 12:24:17.592053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1185)</span> 2021-11-01 12:24:17.592853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1185)</span> 2021-11-01 12:24:17.594109: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
<span class="ansi-cyan-fg">(pid=1185)</span> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
<span class="ansi-cyan-fg">(pid=1185)</span> 2021-11-01 12:24:17.594570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1185)</span> 2021-11-01 12:24:17.595438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1185)</span> 2021-11-01 12:24:17.596336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1185)</span> 2021-11-01 12:24:18.164144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1185)</span> 2021-11-01 12:24:18.165161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1185)</span> 2021-11-01 12:24:18.166119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1185)</span> 2021-11-01 12:24:18,167	ERROR function_runner.py:266 -- Runner Thread raised error.
<span class="ansi-cyan-fg">(pid=1185)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=1185)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=1185)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=1185)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=1185)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
<span class="ansi-cyan-fg">(pid=1185)</span>     return target(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
<span class="ansi-cyan-fg">(pid=1185)</span>     on_value = ops.convert_to_tensor(1, dtype, name="on_value")
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=1185)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=1185)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=1185)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=1185)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=1185)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=1185)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=1185)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=1185)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=1185)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=1185)</span> Exception in thread Thread-2:
<span class="ansi-cyan-fg">(pid=1185)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
<span class="ansi-cyan-fg">(pid=1185)</span>     self.run()
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 279, in run
<span class="ansi-cyan-fg">(pid=1185)</span>     raise e
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=1185)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=1185)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=1185)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=1185)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
<span class="ansi-cyan-fg">(pid=1185)</span>     return target(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
<span class="ansi-cyan-fg">(pid=1185)</span>     on_value = ops.convert_to_tensor(1, dtype, name="on_value")
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=1185)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=1185)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=1185)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=1185)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=1185)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=1185)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=1185)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=1185)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=1185)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=1185)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=1185)</span> 
2021-11-01 12:24:18,370	ERROR trial_runner.py:846 -- Trial meta_loss_98963_00001: Error processing event.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 812, in _process_trial
    results = self.trial_executor.fetch_result(trial)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 767, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/opt/conda/lib/python3.7/site-packages/ray/_private/client_mode_hook.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/ray/worker.py", line 1621, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TuneError): <span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=1185, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7fd6ffc6cad0&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 189, in train_buffered
    result = self.train()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 248, in train
    result = self.step()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 379, in step
    self._report_thread_runner_error(block=True)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 527, in _report_thread_runner_error
    ("Trial raised an exception. Traceback:\n{}".format(err_tb_str)
ray.tune.error.TuneError: Trial raised an exception. Traceback:
<span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=1185, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7fd6ffc6cad0&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
    self._entrypoint()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
    self._status_reporter.get_checkpoint())
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
    output = fn()
  File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
    return target(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
    on_value = ops.convert_to_tensor(1, dtype, name="on_value")
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
    allow_broadcast=True)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
MemoryError: std::bad_alloc
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Result for meta_loss_98963_00001:
  {}
  
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 2.0/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.21 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01<br/>Number of trials: 19/267302874351744 (2 ERROR, 16 PENDING, 1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th>L1 </th><th>L2 </th><th>L3 </th><th>L4 </th><th>L5 </th><th>L6 </th><th>L7 </th><th style="text-align: right;"> N1</th><th style="text-align: right;"> N2</th><th style="text-align: right;"> N3</th><th style="text-align: right;"> N4</th><th style="text-align: right;"> N5</th><th style="text-align: right;"> N6</th><th style="text-align: right;"> N7</th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th style="text-align: right;"> initial_learning_rate_exp</th><th style="text-align: right;"> learning_rate_rate</th><th>loss_name </th><th>optimizer_name </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00002</td><td>RUNNING </td><td> </td><td>maxpooling2d</td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.8581 </td><td style="text-align: right;"> 0.512218 </td><td>sparse_categorical_crossentropy</td><td>adamax </td></tr> <tr><td>meta_loss_98963_00003</td><td>PENDING </td><td> </td><td>flatten </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.27046</td><td style="text-align: right;"> 0.454703 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00004</td><td>PENDING </td><td> </td><td>dropout </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.53965</td><td style="text-align: right;"> 0.861406 </td><td>categorical_crossentropy </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00005</td><td>PENDING </td><td> </td><td>none </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.50222</td><td style="text-align: right;"> 0.955176 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00006</td><td>PENDING </td><td> </td><td>conv2d </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.40886</td><td style="text-align: right;"> 0.878881 </td><td>mae </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00007</td><td>PENDING </td><td> </td><td>dense </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.66232</td><td style="text-align: right;"> 0.355708 </td><td>mae </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00008</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 64</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.15489</td><td style="text-align: right;"> 0.736778 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00009</td><td>PENDING </td><td> </td><td>flatten </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.96978</td><td style="text-align: right;"> 0.814146 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00010</td><td>PENDING </td><td> </td><td>dropout </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.84345</td><td style="text-align: right;"> 0.335166 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00011</td><td>PENDING </td><td> </td><td>none </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.12773</td><td style="text-align: right;"> 0.515024 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00012</td><td>PENDING </td><td> </td><td>conv2d </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.44683</td><td style="text-align: right;"> 0.949793 </td><td>mse </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00013</td><td>PENDING </td><td> </td><td>dense </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.7508 </td><td style="text-align: right;"> 0.0587266</td><td>categorical_crossentropy </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00014</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.15043</td><td style="text-align: right;"> 0.594349 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00015</td><td>PENDING </td><td> </td><td>flatten </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.01626</td><td style="text-align: right;"> 0.938932 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00016</td><td>PENDING </td><td> </td><td>dropout </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.70958</td><td style="text-align: right;"> 0.0631872</td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00017</td><td>PENDING </td><td> </td><td>none </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.41504</td><td style="text-align: right;"> 0.482399 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00018</td><td>PENDING </td><td> </td><td>conv2d </td><td>flatten </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.26361</td><td style="text-align: right;"> 0.83558 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00000</td><td>ERROR </td><td> </td><td>conv2d </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.51525</td><td style="text-align: right;"> 0.553209 </td><td>mape </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00001</td><td>ERROR </td><td> </td><td>dense </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.37358</td><td style="text-align: right;"> 0.314978 </td><td>sparse_categorical_crossentropy</td><td>adagrad </td></tr> </tbody> </table><br/>Number of errored trials: 2<br/><table> <thead> <tr><th>Trial name </th><th style="text-align: right;"> # failures</th><th>error file </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00000</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00000_0_L1=conv2d,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,b_2021-11-01_12-24-02/error.txt</td></tr> <tr><td>meta_loss_98963_00001</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00001_1_L1=dense,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,ba_2021-11-01_12-24-03/error.txt</td></tr> </tbody> </table><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre><span class="ansi-cyan-fg">(pid=1231)</span> 2021-11-01 12:24:24.314833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1231)</span> 2021-11-01 12:24:24.325610: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1231)</span> 2021-11-01 12:24:24.326377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1231)</span> 2021-11-01 12:24:24.328110: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
<span class="ansi-cyan-fg">(pid=1231)</span> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
<span class="ansi-cyan-fg">(pid=1231)</span> 2021-11-01 12:24:24.329209: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1231)</span> 2021-11-01 12:24:24.330326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1231)</span> 2021-11-01 12:24:24.331181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1231)</span> 2021-11-01 12:24:24.774456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1231)</span> 2021-11-01 12:24:24.775204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1231)</span> 2021-11-01 12:24:24.776030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1231)</span> 2021-11-01 12:24:24,777	ERROR function_runner.py:266 -- Runner Thread raised error.
<span class="ansi-cyan-fg">(pid=1231)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=1231)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=1231)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=1231)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=1231)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
<span class="ansi-cyan-fg">(pid=1231)</span>     return target(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
<span class="ansi-cyan-fg">(pid=1231)</span>     on_value = ops.convert_to_tensor(1, dtype, name="on_value")
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=1231)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=1231)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=1231)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=1231)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=1231)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=1231)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=1231)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=1231)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=1231)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=1231)</span> Exception in thread Thread-2:
<span class="ansi-cyan-fg">(pid=1231)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
<span class="ansi-cyan-fg">(pid=1231)</span>     self.run()
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 279, in run
<span class="ansi-cyan-fg">(pid=1231)</span>     raise e
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=1231)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=1231)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=1231)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=1231)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
<span class="ansi-cyan-fg">(pid=1231)</span>     return target(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
<span class="ansi-cyan-fg">(pid=1231)</span>     on_value = ops.convert_to_tensor(1, dtype, name="on_value")
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=1231)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=1231)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=1231)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=1231)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=1231)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=1231)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=1231)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=1231)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=1231)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=1231)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=1231)</span> 
2021-11-01 12:24:24,979	ERROR trial_runner.py:846 -- Trial meta_loss_98963_00002: Error processing event.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 812, in _process_trial
    results = self.trial_executor.fetch_result(trial)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 767, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/opt/conda/lib/python3.7/site-packages/ray/_private/client_mode_hook.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/ray/worker.py", line 1621, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TuneError): <span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=1231, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7fe9427c1d50&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 189, in train_buffered
    result = self.train()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 248, in train
    result = self.step()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 379, in step
    self._report_thread_runner_error(block=True)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 527, in _report_thread_runner_error
    ("Trial raised an exception. Traceback:\n{}".format(err_tb_str)
ray.tune.error.TuneError: Trial raised an exception. Traceback:
<span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=1231, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7fe9427c1d50&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
    self._entrypoint()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
    self._status_reporter.get_checkpoint())
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
    output = fn()
  File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
    return target(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
    on_value = ops.convert_to_tensor(1, dtype, name="on_value")
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
    allow_broadcast=True)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
MemoryError: std::bad_alloc
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Result for meta_loss_98963_00002:
  {}
  
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.6/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.21 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01<br/>Number of trials: 20/267302874351744 (3 ERROR, 16 PENDING, 1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th>L1 </th><th>L2 </th><th>L3 </th><th>L4 </th><th>L5 </th><th>L6 </th><th>L7 </th><th style="text-align: right;"> N1</th><th style="text-align: right;"> N2</th><th style="text-align: right;"> N3</th><th style="text-align: right;"> N4</th><th style="text-align: right;"> N5</th><th style="text-align: right;"> N6</th><th style="text-align: right;"> N7</th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th style="text-align: right;"> initial_learning_rate_exp</th><th style="text-align: right;"> learning_rate_rate</th><th>loss_name </th><th>optimizer_name </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00003</td><td>RUNNING </td><td> </td><td>flatten </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.27046</td><td style="text-align: right;"> 0.454703 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00004</td><td>PENDING </td><td> </td><td>dropout </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.53965</td><td style="text-align: right;"> 0.861406 </td><td>categorical_crossentropy </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00005</td><td>PENDING </td><td> </td><td>none </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.50222</td><td style="text-align: right;"> 0.955176 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00006</td><td>PENDING </td><td> </td><td>conv2d </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.40886</td><td style="text-align: right;"> 0.878881 </td><td>mae </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00007</td><td>PENDING </td><td> </td><td>dense </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.66232</td><td style="text-align: right;"> 0.355708 </td><td>mae </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00008</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 64</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.15489</td><td style="text-align: right;"> 0.736778 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00009</td><td>PENDING </td><td> </td><td>flatten </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.96978</td><td style="text-align: right;"> 0.814146 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00010</td><td>PENDING </td><td> </td><td>dropout </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.84345</td><td style="text-align: right;"> 0.335166 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00011</td><td>PENDING </td><td> </td><td>none </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.12773</td><td style="text-align: right;"> 0.515024 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00012</td><td>PENDING </td><td> </td><td>conv2d </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.44683</td><td style="text-align: right;"> 0.949793 </td><td>mse </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00013</td><td>PENDING </td><td> </td><td>dense </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.7508 </td><td style="text-align: right;"> 0.0587266</td><td>categorical_crossentropy </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00014</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.15043</td><td style="text-align: right;"> 0.594349 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00015</td><td>PENDING </td><td> </td><td>flatten </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.01626</td><td style="text-align: right;"> 0.938932 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00016</td><td>PENDING </td><td> </td><td>dropout </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.70958</td><td style="text-align: right;"> 0.0631872</td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00017</td><td>PENDING </td><td> </td><td>none </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.41504</td><td style="text-align: right;"> 0.482399 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00018</td><td>PENDING </td><td> </td><td>conv2d </td><td>flatten </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.26361</td><td style="text-align: right;"> 0.83558 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00019</td><td>PENDING </td><td> </td><td>dense </td><td>flatten </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.09267</td><td style="text-align: right;"> 0.103705 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00000</td><td>ERROR </td><td> </td><td>conv2d </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.51525</td><td style="text-align: right;"> 0.553209 </td><td>mape </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00001</td><td>ERROR </td><td> </td><td>dense </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.37358</td><td style="text-align: right;"> 0.314978 </td><td>sparse_categorical_crossentropy</td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00002</td><td>ERROR </td><td> </td><td>maxpooling2d</td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.8581 </td><td style="text-align: right;"> 0.512218 </td><td>sparse_categorical_crossentropy</td><td>adamax </td></tr> </tbody> </table><br/>Number of errored trials: 3<br/><table> <thead> <tr><th>Trial name </th><th style="text-align: right;"> # failures</th><th>error file </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00000</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00000_0_L1=conv2d,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,b_2021-11-01_12-24-02/error.txt</td></tr> <tr><td>meta_loss_98963_00001</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00001_1_L1=dense,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,ba_2021-11-01_12-24-03/error.txt</td></tr> <tr><td>meta_loss_98963_00002</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00002_2_L1=maxpooling2d,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,_2021-11-01_12-24-11/error.txt</td></tr> </tbody> </table><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre><span class="ansi-cyan-fg">(pid=1270)</span> 2021-11-01 12:24:30.963152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1270)</span> 2021-11-01 12:24:30.973430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1270)</span> 2021-11-01 12:24:30.974169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1270)</span> 2021-11-01 12:24:30.975364: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
<span class="ansi-cyan-fg">(pid=1270)</span> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
<span class="ansi-cyan-fg">(pid=1270)</span> 2021-11-01 12:24:30.975658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1270)</span> 2021-11-01 12:24:30.976454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1270)</span> 2021-11-01 12:24:30.977195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1270)</span> 2021-11-01 12:24:31.412220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1270)</span> 2021-11-01 12:24:31.413057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1270)</span> 2021-11-01 12:24:31.413788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1270)</span> 2021-11-01 12:24:31,415	ERROR function_runner.py:266 -- Runner Thread raised error.
<span class="ansi-cyan-fg">(pid=1270)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=1270)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=1270)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=1270)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=1270)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
<span class="ansi-cyan-fg">(pid=1270)</span>     return target(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
<span class="ansi-cyan-fg">(pid=1270)</span>     on_value = ops.convert_to_tensor(1, dtype, name="on_value")
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=1270)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=1270)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=1270)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=1270)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=1270)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=1270)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=1270)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=1270)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=1270)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=1270)</span> Exception in thread Thread-2:
<span class="ansi-cyan-fg">(pid=1270)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
<span class="ansi-cyan-fg">(pid=1270)</span>     self.run()
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 279, in run
<span class="ansi-cyan-fg">(pid=1270)</span>     raise e
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=1270)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=1270)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=1270)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=1270)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
<span class="ansi-cyan-fg">(pid=1270)</span>     return target(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
<span class="ansi-cyan-fg">(pid=1270)</span>     on_value = ops.convert_to_tensor(1, dtype, name="on_value")
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=1270)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=1270)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=1270)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=1270)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=1270)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=1270)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=1270)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=1270)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=1270)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=1270)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=1270)</span> 
2021-11-01 12:24:31,618	ERROR trial_runner.py:846 -- Trial meta_loss_98963_00003: Error processing event.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 812, in _process_trial
    results = self.trial_executor.fetch_result(trial)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 767, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/opt/conda/lib/python3.7/site-packages/ray/_private/client_mode_hook.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/ray/worker.py", line 1621, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TuneError): <span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=1270, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7fc247370150&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 189, in train_buffered
    result = self.train()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 248, in train
    result = self.step()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 379, in step
    self._report_thread_runner_error(block=True)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 527, in _report_thread_runner_error
    ("Trial raised an exception. Traceback:\n{}".format(err_tb_str)
ray.tune.error.TuneError: Trial raised an exception. Traceback:
<span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=1270, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7fc247370150&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
    self._entrypoint()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
    self._status_reporter.get_checkpoint())
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
    output = fn()
  File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
    return target(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
    on_value = ops.convert_to_tensor(1, dtype, name="on_value")
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
    allow_broadcast=True)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
MemoryError: std::bad_alloc
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Result for meta_loss_98963_00003:
  {}
  
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.5/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.21 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01<br/>Number of trials: 21/267302874351744 (4 ERROR, 16 PENDING, 1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th>L1 </th><th>L2 </th><th>L3 </th><th>L4 </th><th>L5 </th><th>L6 </th><th>L7 </th><th style="text-align: right;"> N1</th><th style="text-align: right;"> N2</th><th style="text-align: right;"> N3</th><th style="text-align: right;"> N4</th><th style="text-align: right;"> N5</th><th style="text-align: right;"> N6</th><th style="text-align: right;"> N7</th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th style="text-align: right;"> initial_learning_rate_exp</th><th style="text-align: right;"> learning_rate_rate</th><th>loss_name </th><th>optimizer_name </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00004</td><td>RUNNING </td><td> </td><td>dropout </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.53965</td><td style="text-align: right;"> 0.861406 </td><td>categorical_crossentropy </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00005</td><td>PENDING </td><td> </td><td>none </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.50222</td><td style="text-align: right;"> 0.955176 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00006</td><td>PENDING </td><td> </td><td>conv2d </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.40886</td><td style="text-align: right;"> 0.878881 </td><td>mae </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00007</td><td>PENDING </td><td> </td><td>dense </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.66232</td><td style="text-align: right;"> 0.355708 </td><td>mae </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00008</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 64</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.15489</td><td style="text-align: right;"> 0.736778 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00009</td><td>PENDING </td><td> </td><td>flatten </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.96978</td><td style="text-align: right;"> 0.814146 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00010</td><td>PENDING </td><td> </td><td>dropout </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.84345</td><td style="text-align: right;"> 0.335166 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00011</td><td>PENDING </td><td> </td><td>none </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.12773</td><td style="text-align: right;"> 0.515024 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00012</td><td>PENDING </td><td> </td><td>conv2d </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.44683</td><td style="text-align: right;"> 0.949793 </td><td>mse </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00013</td><td>PENDING </td><td> </td><td>dense </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.7508 </td><td style="text-align: right;"> 0.0587266</td><td>categorical_crossentropy </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00014</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.15043</td><td style="text-align: right;"> 0.594349 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00015</td><td>PENDING </td><td> </td><td>flatten </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.01626</td><td style="text-align: right;"> 0.938932 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00016</td><td>PENDING </td><td> </td><td>dropout </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.70958</td><td style="text-align: right;"> 0.0631872</td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00017</td><td>PENDING </td><td> </td><td>none </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.41504</td><td style="text-align: right;"> 0.482399 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00018</td><td>PENDING </td><td> </td><td>conv2d </td><td>flatten </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.26361</td><td style="text-align: right;"> 0.83558 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00019</td><td>PENDING </td><td> </td><td>dense </td><td>flatten </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.09267</td><td style="text-align: right;"> 0.103705 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00000</td><td>ERROR </td><td> </td><td>conv2d </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.51525</td><td style="text-align: right;"> 0.553209 </td><td>mape </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00001</td><td>ERROR </td><td> </td><td>dense </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.37358</td><td style="text-align: right;"> 0.314978 </td><td>sparse_categorical_crossentropy</td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00002</td><td>ERROR </td><td> </td><td>maxpooling2d</td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.8581 </td><td style="text-align: right;"> 0.512218 </td><td>sparse_categorical_crossentropy</td><td>adamax </td></tr> <tr><td>meta_loss_98963_00003</td><td>ERROR </td><td> </td><td>flatten </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.27046</td><td style="text-align: right;"> 0.454703 </td><td>mape </td><td>sgd </td></tr> </tbody> </table><br/>... 1 more trials not shown (1 PENDING)<br/>Number of errored trials: 4<br/><table> <thead> <tr><th>Trial name </th><th style="text-align: right;"> # failures</th><th>error file </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00000</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00000_0_L1=conv2d,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,b_2021-11-01_12-24-02/error.txt</td></tr> <tr><td>meta_loss_98963_00001</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00001_1_L1=dense,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,ba_2021-11-01_12-24-03/error.txt</td></tr> <tr><td>meta_loss_98963_00002</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00002_2_L1=maxpooling2d,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,_2021-11-01_12-24-11/error.txt</td></tr> <tr><td>meta_loss_98963_00003</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00003_3_L1=flatten,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,_2021-11-01_12-24-18/error.txt</td></tr> </tbody> </table><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 2.0/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.21 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01<br/>Number of trials: 21/267302874351744 (4 ERROR, 16 PENDING, 1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th>L1 </th><th>L2 </th><th>L3 </th><th>L4 </th><th>L5 </th><th>L6 </th><th>L7 </th><th style="text-align: right;"> N1</th><th style="text-align: right;"> N2</th><th style="text-align: right;"> N3</th><th style="text-align: right;"> N4</th><th style="text-align: right;"> N5</th><th style="text-align: right;"> N6</th><th style="text-align: right;"> N7</th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th style="text-align: right;"> initial_learning_rate_exp</th><th style="text-align: right;"> learning_rate_rate</th><th>loss_name </th><th>optimizer_name </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00004</td><td>RUNNING </td><td> </td><td>dropout </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.53965</td><td style="text-align: right;"> 0.861406 </td><td>categorical_crossentropy </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00005</td><td>PENDING </td><td> </td><td>none </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.50222</td><td style="text-align: right;"> 0.955176 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00006</td><td>PENDING </td><td> </td><td>conv2d </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.40886</td><td style="text-align: right;"> 0.878881 </td><td>mae </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00007</td><td>PENDING </td><td> </td><td>dense </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.66232</td><td style="text-align: right;"> 0.355708 </td><td>mae </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00008</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 64</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.15489</td><td style="text-align: right;"> 0.736778 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00009</td><td>PENDING </td><td> </td><td>flatten </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.96978</td><td style="text-align: right;"> 0.814146 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00010</td><td>PENDING </td><td> </td><td>dropout </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.84345</td><td style="text-align: right;"> 0.335166 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00011</td><td>PENDING </td><td> </td><td>none </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.12773</td><td style="text-align: right;"> 0.515024 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00012</td><td>PENDING </td><td> </td><td>conv2d </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.44683</td><td style="text-align: right;"> 0.949793 </td><td>mse </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00013</td><td>PENDING </td><td> </td><td>dense </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.7508 </td><td style="text-align: right;"> 0.0587266</td><td>categorical_crossentropy </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00014</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.15043</td><td style="text-align: right;"> 0.594349 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00015</td><td>PENDING </td><td> </td><td>flatten </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.01626</td><td style="text-align: right;"> 0.938932 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00016</td><td>PENDING </td><td> </td><td>dropout </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.70958</td><td style="text-align: right;"> 0.0631872</td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00017</td><td>PENDING </td><td> </td><td>none </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.41504</td><td style="text-align: right;"> 0.482399 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00018</td><td>PENDING </td><td> </td><td>conv2d </td><td>flatten </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.26361</td><td style="text-align: right;"> 0.83558 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00019</td><td>PENDING </td><td> </td><td>dense </td><td>flatten </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.09267</td><td style="text-align: right;"> 0.103705 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00000</td><td>ERROR </td><td> </td><td>conv2d </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.51525</td><td style="text-align: right;"> 0.553209 </td><td>mape </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00001</td><td>ERROR </td><td> </td><td>dense </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.37358</td><td style="text-align: right;"> 0.314978 </td><td>sparse_categorical_crossentropy</td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00002</td><td>ERROR </td><td> </td><td>maxpooling2d</td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.8581 </td><td style="text-align: right;"> 0.512218 </td><td>sparse_categorical_crossentropy</td><td>adamax </td></tr> <tr><td>meta_loss_98963_00003</td><td>ERROR </td><td> </td><td>flatten </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.27046</td><td style="text-align: right;"> 0.454703 </td><td>mape </td><td>sgd </td></tr> </tbody> </table><br/>... 1 more trials not shown (1 PENDING)<br/>Number of errored trials: 4<br/><table> <thead> <tr><th>Trial name </th><th style="text-align: right;"> # failures</th><th>error file </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00000</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00000_0_L1=conv2d,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,b_2021-11-01_12-24-02/error.txt</td></tr> <tr><td>meta_loss_98963_00001</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00001_1_L1=dense,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,ba_2021-11-01_12-24-03/error.txt</td></tr> <tr><td>meta_loss_98963_00002</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00002_2_L1=maxpooling2d,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,_2021-11-01_12-24-11/error.txt</td></tr> <tr><td>meta_loss_98963_00003</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00003_3_L1=flatten,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,_2021-11-01_12-24-18/error.txt</td></tr> </tbody> </table><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre><span class="ansi-cyan-fg">(pid=1308)</span> 2021-11-01 12:24:37.617787: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1308)</span> 2021-11-01 12:24:37.629614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1308)</span> 2021-11-01 12:24:37.630415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1308)</span> 2021-11-01 12:24:37.631673: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
<span class="ansi-cyan-fg">(pid=1308)</span> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
<span class="ansi-cyan-fg">(pid=1308)</span> 2021-11-01 12:24:37.632031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1308)</span> 2021-11-01 12:24:37.632958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1308)</span> 2021-11-01 12:24:37.633716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1308)</span> 2021-11-01 12:24:38.062656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1308)</span> 2021-11-01 12:24:38.063476: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1308)</span> 2021-11-01 12:24:38.064327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=1308)</span> 2021-11-01 12:24:38,065	ERROR function_runner.py:266 -- Runner Thread raised error.
<span class="ansi-cyan-fg">(pid=1308)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=1308)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=1308)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=1308)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=1308)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
<span class="ansi-cyan-fg">(pid=1308)</span>     return target(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
<span class="ansi-cyan-fg">(pid=1308)</span>     on_value = ops.convert_to_tensor(1, dtype, name="on_value")
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=1308)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=1308)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=1308)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=1308)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=1308)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=1308)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=1308)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=1308)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=1308)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=1308)</span> Exception in thread Thread-2:
<span class="ansi-cyan-fg">(pid=1308)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
<span class="ansi-cyan-fg">(pid=1308)</span>     self.run()
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 279, in run
<span class="ansi-cyan-fg">(pid=1308)</span>     raise e
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=1308)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=1308)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=1308)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=1308)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
<span class="ansi-cyan-fg">(pid=1308)</span>     return target(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
<span class="ansi-cyan-fg">(pid=1308)</span>     on_value = ops.convert_to_tensor(1, dtype, name="on_value")
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=1308)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=1308)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=1308)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=1308)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=1308)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=1308)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=1308)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=1308)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=1308)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=1308)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=1308)</span> 
2021-11-01 12:24:38,268	ERROR trial_runner.py:846 -- Trial meta_loss_98963_00004: Error processing event.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 812, in _process_trial
    results = self.trial_executor.fetch_result(trial)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 767, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/opt/conda/lib/python3.7/site-packages/ray/_private/client_mode_hook.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/ray/worker.py", line 1621, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TuneError): <span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=1308, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7f9ad1b6e110&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 189, in train_buffered
    result = self.train()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 248, in train
    result = self.step()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 379, in step
    self._report_thread_runner_error(block=True)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 527, in _report_thread_runner_error
    ("Trial raised an exception. Traceback:\n{}".format(err_tb_str)
ray.tune.error.TuneError: Trial raised an exception. Traceback:
<span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=1308, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7f9ad1b6e110&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
    self._entrypoint()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
    self._status_reporter.get_checkpoint())
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
    output = fn()
  File "/tmp/ipykernel_886/1119233880.py", line 61, in meta_loss
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py", line 206, in wrapper
    return target(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py", line 4338, in one_hot
    on_value = ops.convert_to_tensor(1, dtype, name="on_value")
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
    allow_broadcast=True)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
MemoryError: std::bad_alloc
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Result for meta_loss_98963_00004:
  {}
  
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>2021-11-01 12:24:40,402	WARNING worker.py:1227 -- The autoscaler failed with the following error:
Terminated with signal 15
  File "/opt/conda/lib/python3.7/site-packages/ray/autoscaler/_private/monitor.py", line 430, in &lt;module&gt;
    monitor.run()
  File "/opt/conda/lib/python3.7/site-packages/ray/autoscaler/_private/monitor.py", line 331, in run
    self._run()
  File "/opt/conda/lib/python3.7/site-packages/ray/autoscaler/_private/monitor.py", line 248, in _run
    time.sleep(AUTOSCALER_UPDATE_INTERVAL_S)

2021-11-01 12:24:40,508	ERROR worker.py:1229 -- listen_error_messages_raylet: Connection closed by server.
2021-11-01 12:24:40,511	ERROR import_thread.py:88 -- ImportThread: Connection closed by server.
2021-11-01 12:24:40,517	ERROR worker.py:475 -- print_logs: Connection closed by server.
2021-11-01 12:24:40,545	ERROR ray_trial_executor.py:600 -- Trial meta_loss_98963_00006: Unexpected error starting runner.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/redis/connection.py", line 559, in connect
    sock = self._connect()
  File "/opt/conda/lib/python3.7/site-packages/redis/connection.py", line 615, in _connect
    raise err
  File "/opt/conda/lib/python3.7/site-packages/redis/connection.py", line 603, in _connect
    sock.connect(socket_address)
ConnectionRefusedError: [Errno 111] Connection refused

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 590, in start_trial
    return self._start_trial(trial, checkpoint, train=train)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 465, in _start_trial
    runner = self._setup_remote_runner(trial)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 307, in _setup_remote_runner
    trainable_cls = trial.get_trainable_cls()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trial.py", line 646, in get_trainable_cls
    return get_trainable_cls(self.trainable_name)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/registry.py", line 31, in get_trainable_cls
    validate_trainable(trainable_name)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/registry.py", line 36, in validate_trainable
    if not has_trainable(trainable_name):
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/registry.py", line 27, in has_trainable
    return _global_registry.contains(TRAINABLE_CLASS, trainable_name)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/registry.py", line 151, in contains
    value = _internal_kv_get(_make_key(category, key))
  File "/opt/conda/lib/python3.7/site-packages/ray/_private/client_mode_hook.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/ray/experimental/internal_kv.py", line 57, in _internal_kv_get
    return ray.worker.global_worker.redis_client.hget(key, "value")
  File "/opt/conda/lib/python3.7/site-packages/redis/client.py", line 3010, in hget
    return self.execute_command('HGET', name, key)
  File "/opt/conda/lib/python3.7/site-packages/redis/client.py", line 898, in execute_command
    conn = self.connection or pool.get_connection(command_name, **options)
  File "/opt/conda/lib/python3.7/site-packages/redis/connection.py", line 1192, in get_connection
    connection.connect()
  File "/opt/conda/lib/python3.7/site-packages/redis/connection.py", line 563, in connect
    raise ConnectionError(self._error_message(e))
redis.exceptions.ConnectionError: Error 111 connecting to 10.138.0.10:6379. Connection refused.
2021-11-01 12:24:42,551	WARNING util.py:166 -- The `start_trial` operation took 2.006 s, which may be a performance bottleneck.
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.2/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 1.0/2 CPUs, 1.0/1 GPUs, 0.0/7.21 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01<br/>Number of trials: 22/267302874351744 (6 ERROR, 15 PENDING, 1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th>L1 </th><th>L2 </th><th>L3 </th><th>L4 </th><th>L5 </th><th>L6 </th><th>L7 </th><th style="text-align: right;"> N1</th><th style="text-align: right;"> N2</th><th style="text-align: right;"> N3</th><th style="text-align: right;"> N4</th><th style="text-align: right;"> N5</th><th style="text-align: right;"> N6</th><th style="text-align: right;"> N7</th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th style="text-align: right;"> initial_learning_rate_exp</th><th style="text-align: right;"> learning_rate_rate</th><th>loss_name </th><th>optimizer_name </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00005</td><td>RUNNING </td><td> </td><td>none </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.50222</td><td style="text-align: right;"> 0.955176 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00007</td><td>PENDING </td><td> </td><td>dense </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.66232</td><td style="text-align: right;"> 0.355708 </td><td>mae </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00008</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 64</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.15489</td><td style="text-align: right;"> 0.736778 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00009</td><td>PENDING </td><td> </td><td>flatten </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.96978</td><td style="text-align: right;"> 0.814146 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00010</td><td>PENDING </td><td> </td><td>dropout </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.84345</td><td style="text-align: right;"> 0.335166 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00011</td><td>PENDING </td><td> </td><td>none </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.12773</td><td style="text-align: right;"> 0.515024 </td><td>categorical_crossentropy </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00012</td><td>PENDING </td><td> </td><td>conv2d </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.44683</td><td style="text-align: right;"> 0.949793 </td><td>mse </td><td>adamax </td></tr> <tr><td>meta_loss_98963_00013</td><td>PENDING </td><td> </td><td>dense </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.7508 </td><td style="text-align: right;"> 0.0587266</td><td>categorical_crossentropy </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00014</td><td>PENDING </td><td> </td><td>maxpooling2d</td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.15043</td><td style="text-align: right;"> 0.594349 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00015</td><td>PENDING </td><td> </td><td>flatten </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.01626</td><td style="text-align: right;"> 0.938932 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00016</td><td>PENDING </td><td> </td><td>dropout </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.70958</td><td style="text-align: right;"> 0.0631872</td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00017</td><td>PENDING </td><td> </td><td>none </td><td>maxpooling2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.41504</td><td style="text-align: right;"> 0.482399 </td><td>mae </td><td>nadam </td></tr> <tr><td>meta_loss_98963_00018</td><td>PENDING </td><td> </td><td>conv2d </td><td>flatten </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 48</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.26361</td><td style="text-align: right;"> 0.83558 </td><td>mse </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00019</td><td>PENDING </td><td> </td><td>dense </td><td>flatten </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.09267</td><td style="text-align: right;"> 0.103705 </td><td>sparse_categorical_crossentropy</td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00000</td><td>ERROR </td><td> </td><td>conv2d </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 24</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.51525</td><td style="text-align: right;"> 0.553209 </td><td>mape </td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00001</td><td>ERROR </td><td> </td><td>dense </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.37358</td><td style="text-align: right;"> 0.314978 </td><td>sparse_categorical_crossentropy</td><td>adagrad </td></tr> <tr><td>meta_loss_98963_00002</td><td>ERROR </td><td> </td><td>maxpooling2d</td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.8581 </td><td style="text-align: right;"> 0.512218 </td><td>sparse_categorical_crossentropy</td><td>adamax </td></tr> <tr><td>meta_loss_98963_00003</td><td>ERROR </td><td> </td><td>flatten </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 4</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -1.27046</td><td style="text-align: right;"> 0.454703 </td><td>mape </td><td>sgd </td></tr> <tr><td>meta_loss_98963_00004</td><td>ERROR </td><td> </td><td>dropout </td><td>conv2d </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 16</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -3.53965</td><td style="text-align: right;"> 0.861406 </td><td>categorical_crossentropy </td><td>adadelta </td></tr> <tr><td>meta_loss_98963_00006</td><td>ERROR </td><td> </td><td>conv2d </td><td>dense </td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td>conv2d</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 8</td><td style="text-align: right;"> 128</td><td>sigmoid </td><td>sigmoid </td><td style="text-align: right;"> -2.40886</td><td style="text-align: right;"> 0.878881 </td><td>mae </td><td>adadelta </td></tr> </tbody> </table><br/>... 2 more trials not shown (2 PENDING)<br/>Number of errored trials: 6<br/><table> <thead> <tr><th>Trial name </th><th style="text-align: right;"> # failures</th><th>error file </th></tr> </thead> <tbody> <tr><td>meta_loss_98963_00000</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00000_0_L1=conv2d,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,b_2021-11-01_12-24-02/error.txt</td></tr> <tr><td>meta_loss_98963_00001</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00001_1_L1=dense,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,ba_2021-11-01_12-24-03/error.txt</td></tr> <tr><td>meta_loss_98963_00002</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00002_2_L1=maxpooling2d,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,_2021-11-01_12-24-11/error.txt</td></tr> <tr><td>meta_loss_98963_00003</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00003_3_L1=flatten,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,_2021-11-01_12-24-18/error.txt</td></tr> <tr><td>meta_loss_98963_00004</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00004_4_L1=dropout,L2=conv2d,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,_2021-11-01_12-24-25/error.txt</td></tr> <tr><td>meta_loss_98963_00006</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-24-01/meta_loss_98963_00006_6_L1=conv2d,L2=dense,L3=conv2d,L4=conv2d,L5=conv2d,L6=conv2d,L7=conv2d,N1=8,N2=8,N3=8,N4=8,N5=8,N6=8,N7=8,ba_2021-11-01_12-24-38/error.txt</td></tr> </tbody> </table><br/> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>Obviously, I got carried away. There are way too many tunable parameters to expect convergence. Let's try a smaller search space with only <code>units</code> changing</p> <h3 id="Iteration-2">Iteration 2<a class="anchor-link" href="#Iteration-2"></a></h3> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">meta_loss</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>

    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
    <span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
    <span class="kn">import</span> <span class="nn">IPython.display</span> <span class="k">as</span> <span class="nn">display</span>

    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="k">as</span> <span class="nn">keras</span>
    <span class="kn">import</span> <span class="nn">tensorflow.keras.layers</span> <span class="k">as</span> <span class="nn">tfkl</span>
    <span class="kn">import</span> <span class="nn">tensorflow.keras.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>
    
    <span class="c1"># load dataset</span>
    <span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_train</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">/</span> <span class="mf">255.</span>
    
    <span class="n">units</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'units'</span><span class="p">]</span>  <span class="c1"># number of units in the middle layer (if applicable)</span>
    <span class="n">conv_activation</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'conv_activation'</span><span class="p">]</span>  <span class="c1"># 'relu', 'elu', 'softplus'</span>
    <span class="n">dense_activation</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'dense_activation'</span><span class="p">]</span>  <span class="c1"># 'relu', 'elu', 'softplus'</span>
    <span class="n">initial_learning_rate</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">config</span><span class="p">[</span><span class="s1">'initial_learning_rate_exp'</span><span class="p">]</span>  <span class="c1"># -4.0 to -1.0</span>
    <span class="n">learning_rate_rate</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="n">config</span><span class="p">[</span><span class="s1">'learning_rate_rate'</span><span class="p">]</span>  <span class="c1"># 0.0 to 1.0</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'optimizer_name'</span><span class="p">]</span>  <span class="c1"># 'adam', 'sgd', 'rmsprop', 'adagrad', 'adadelta', 'adamax', or 'nadam'</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="p">[</span><span class="s1">'batch_size'</span><span class="p">]</span>  <span class="c1"># 4 to 1024, integers only</span>

    <span class="c1"># activation functions</span>
    <span class="n">activations</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'relu'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="s1">'elu'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">elu</span><span class="p">,</span>
        <span class="s1">'softplus'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softplus</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">conv_activation</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="n">conv_activation</span><span class="p">]</span>
    <span class="n">dense_activation</span> <span class="o">=</span> <span class="n">activations</span><span class="p">[</span><span class="n">dense_activation</span><span class="p">]</span>
    
    <span class="c1"># optimizer and learning rate</span>
    <span class="n">optimziers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'SGD'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span>
        <span class="s1">'RMSprop'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">,</span>
        <span class="s1">'Adagrad'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adagrad</span><span class="p">,</span>
        <span class="s1">'Adadelta'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adadelta</span><span class="p">,</span>
        <span class="s1">'Adam'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
        <span class="s1">'Adamax'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adamax</span><span class="p">,</span>
        <span class="s1">'Nadam'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Nadam</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimziers</span><span class="p">[</span><span class="n">optimizer_name</span><span class="p">](</span><span class="n">initial_learning_rate</span><span class="p">)</span>

    <span class="n">learning_rate_scheduler</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">LearningRateScheduler</span><span class="p">(</span>
        <span class="k">lambda</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">_</span><span class="p">:</span> <span class="n">initial_learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">learning_rate_rate</span> <span class="o">**</span> <span class="n">epoch</span><span class="p">))</span>

    <span class="c1"># build model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>  <span class="c1"># give each pixel a 1 dimensional channel</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="n">units</span><span class="o">+</span><span class="mi">8</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">GlobalMaxPooling2D</span><span class="p">(),</span>  <span class="c1"># this layer will take the highest value features over all pixels for each of the 16 filters</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">dense_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">((</span><span class="n">units</span><span class="o">+</span><span class="mi">10</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">dense_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
    <span class="p">])</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> 
        <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">)</span>

    <span class="c1"># train model</span>
    <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span>
        <span class="n">y</span><span class="o">=</span><span class="n">Y_train</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">learning_rate_scheduler</span><span class="p">],</span>
        <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">),</span>
        <span class="n">validation_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># report validation loss</span>
    <span class="n">final_val_loss</span> <span class="o">=</span> <span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">'val_loss'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">validation_loss</span><span class="o">=</span><span class="n">final_val_loss</span><span class="p">)</span>
</pre></div> </div> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">large_config</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'units'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">]),</span>
    <span class="s1">'dense_activation'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span> <span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'softplus'</span><span class="p">]),</span>
    <span class="s1">'conv_activation'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span> <span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'softplus'</span><span class="p">]),</span>
    <span class="s1">'initial_learning_rate_exp'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mf">4.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">),</span>
    <span class="s1">'learning_rate_rate'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="s1">'optimizer_name'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">'adam'</span><span class="p">,</span> <span class="s1">'sgd'</span><span class="p">,</span> <span class="s1">'rmsprop'</span><span class="p">,</span> <span class="s1">'adagrad'</span><span class="p">,</span> <span class="s1">'adadelta'</span><span class="p">,</span> <span class="s1">'adamax'</span><span class="p">,</span> <span class="s1">'nadam'</span><span class="p">]),</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">]),</span>
    <span class="s1">'loss_name'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">'mse'</span><span class="p">,</span> <span class="s1">'mae'</span><span class="p">,</span> <span class="s1">'mape'</span><span class="p">,</span> <span class="s1">'categorical_crossentropy'</span><span class="p">,</span> <span class="s1">'sparse_categorical_crossentropy'</span><span class="p">]),</span>
<span class="p">}</span>

<span class="n">small_config</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">'units'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span><span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span>
    <span class="s1">'dense_activation'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span> <span class="s1">'relu'</span><span class="p">,</span> <span class="p">]),</span>
    <span class="s1">'conv_activation'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">grid_search</span><span class="p">([</span> <span class="s1">'relu'</span><span class="p">,</span> <span class="p">]),</span>
    <span class="s1">'initial_learning_rate_exp'</span><span class="p">:</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span>
    <span class="s1">'learning_rate_rate'</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="s1">'optimizer_name'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="s1">'Adam'</span><span class="p">,</span> <span class="s1">'SGD'</span><span class="p">]),</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]),</span>
<span class="p">}</span>
</pre></div> </div> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">meta_loss</span><span class="p">({</span>
    <span class="s1">'units'</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
    <span class="s1">'dense_activation'</span><span class="p">:</span> <span class="s1">'relu'</span><span class="p">,</span>
    <span class="s1">'conv_activation'</span><span class="p">:</span> <span class="s1">'relu'</span><span class="p">,</span>
    <span class="s1">'initial_learning_rate_exp'</span><span class="p">:</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">,</span>
    <span class="s1">'learning_rate_rate'</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">,</span>
    <span class="s1">'optimizer_name'</span><span class="p">:</span> <span class="s1">'SGD'</span><span class="p">,</span>
    <span class="s1">'batch_size'</span><span class="p">:</span> <span class="mi">32</span>
<span class="p">})</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>2021-11-01 12:29:39.483154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-11-01 12:29:39.494402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-11-01 12:29:39.495286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-11-01 12:29:39.496558: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-01 12:29:39.496951: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-11-01 12:29:39.497758: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-11-01 12:29:39.498647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-11-01 12:29:39.914087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-11-01 12:29:39.914874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2021-11-01 12:29:39.915628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">MemoryError</span>                               Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipykernel_1785/850133443.py</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      6</span>     <span class="ansi-blue-fg">'learning_rate_rate'</span><span class="ansi-blue-fg">:</span> <span class="ansi-cyan-fg">0.9</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span>     <span class="ansi-blue-fg">'optimizer_name'</span><span class="ansi-blue-fg">:</span> <span class="ansi-blue-fg">'SGD'</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">----&gt; 8</span><span class="ansi-red-fg">     </span><span class="ansi-blue-fg">'batch_size'</span><span class="ansi-blue-fg">:</span> <span class="ansi-cyan-fg">32</span>
<span class="ansi-green-intense-fg ansi-bold">      9</span> })

<span class="ansi-green-fg">/tmp/ipykernel_1785/823405744.py</span> in <span class="ansi-cyan-fg">meta_loss</span><span class="ansi-blue-fg">(config)</span>
<span class="ansi-green-intense-fg ansi-bold">     56</span>         tfkl<span class="ansi-blue-fg">.</span>Dense<span class="ansi-blue-fg">(</span>units<span class="ansi-blue-fg">,</span> activation<span class="ansi-blue-fg">=</span>dense_activation<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     57</span>         tfkl<span class="ansi-blue-fg">.</span>Dense<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">(</span>units<span class="ansi-blue-fg">+</span><span class="ansi-cyan-fg">10</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">//</span><span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">,</span> activation<span class="ansi-blue-fg">=</span>dense_activation<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">---&gt; 58</span><span class="ansi-red-fg">         </span>tfkl<span class="ansi-blue-fg">.</span>Dense<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">10</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     59</span>     ])
<span class="ansi-green-intense-fg ansi-bold">     60</span>     model.compile(

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py</span> in <span class="ansi-cyan-fg">_method_wrapper</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    528</span>     self<span class="ansi-blue-fg">.</span>_self_setattr_tracking <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">False</span>  <span class="ansi-red-fg"># pylint: disable=protected-access</span>
<span class="ansi-green-intense-fg ansi-bold">    529</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 530</span><span class="ansi-red-fg">       </span>result <span class="ansi-blue-fg">=</span> method<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    531</span>     <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    532</span>       self<span class="ansi-blue-fg">.</span>_self_setattr_tracking <span class="ansi-blue-fg">=</span> previous_value  <span class="ansi-red-fg"># pylint: disable=protected-access</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, layers, name)</span>
<span class="ansi-green-intense-fg ansi-bold">    106</span>     <span class="ansi-red-fg"># Skip the init in FunctionalModel since model doesn't have input/output yet</span>
<span class="ansi-green-intense-fg ansi-bold">    107</span>     super(functional.Functional, self).__init__(  # pylint: disable=bad-super-call
<span class="ansi-green-fg">--&gt; 108</span><span class="ansi-red-fg">         name=name, autocast=False)
</span><span class="ansi-green-intense-fg ansi-bold">    109</span>     base_layer<span class="ansi-blue-fg">.</span>keras_api_gauge<span class="ansi-blue-fg">.</span>get_cell<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">'Sequential'</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>set<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    110</span>     self<span class="ansi-blue-fg">.</span>supports_masking <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">True</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py</span> in <span class="ansi-cyan-fg">_method_wrapper</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    528</span>     self<span class="ansi-blue-fg">.</span>_self_setattr_tracking <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">False</span>  <span class="ansi-red-fg"># pylint: disable=protected-access</span>
<span class="ansi-green-intense-fg ansi-bold">    529</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 530</span><span class="ansi-red-fg">       </span>result <span class="ansi-blue-fg">=</span> method<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    531</span>     <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    532</span>       self<span class="ansi-blue-fg">.</span>_self_setattr_tracking <span class="ansi-blue-fg">=</span> previous_value  <span class="ansi-red-fg"># pylint: disable=protected-access</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/keras/engine/training.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    287</span>     self<span class="ansi-blue-fg">.</span>_steps_per_execution <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    288</span> 
<span class="ansi-green-fg">--&gt; 289</span><span class="ansi-red-fg">     </span>self<span class="ansi-blue-fg">.</span>_init_batch_counters<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    290</span>     self<span class="ansi-blue-fg">.</span>_base_model_initialized <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">True</span>
<span class="ansi-green-intense-fg ansi-bold">    291</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py</span> in <span class="ansi-cyan-fg">_method_wrapper</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    528</span>     self<span class="ansi-blue-fg">.</span>_self_setattr_tracking <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">False</span>  <span class="ansi-red-fg"># pylint: disable=protected-access</span>
<span class="ansi-green-intense-fg ansi-bold">    529</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 530</span><span class="ansi-red-fg">       </span>result <span class="ansi-blue-fg">=</span> method<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    531</span>     <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    532</span>       self<span class="ansi-blue-fg">.</span>_self_setattr_tracking <span class="ansi-blue-fg">=</span> previous_value  <span class="ansi-red-fg"># pylint: disable=protected-access</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/keras/engine/training.py</span> in <span class="ansi-cyan-fg">_init_batch_counters</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    295</span>     <span class="ansi-red-fg"># `evaluate`, and `predict`.</span>
<span class="ansi-green-intense-fg ansi-bold">    296</span>     agg <span class="ansi-blue-fg">=</span> tf<span class="ansi-blue-fg">.</span>VariableAggregation<span class="ansi-blue-fg">.</span>ONLY_FIRST_REPLICA
<span class="ansi-green-fg">--&gt; 297</span><span class="ansi-red-fg">     </span>self<span class="ansi-blue-fg">.</span>_train_counter <span class="ansi-blue-fg">=</span> tf<span class="ansi-blue-fg">.</span>Variable<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">'int64'</span><span class="ansi-blue-fg">,</span> aggregation<span class="ansi-blue-fg">=</span>agg<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    298</span>     self<span class="ansi-blue-fg">.</span>_test_counter <span class="ansi-blue-fg">=</span> tf<span class="ansi-blue-fg">.</span>Variable<span class="ansi-blue-fg">(</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">'int64'</span><span class="ansi-blue-fg">,</span> aggregation<span class="ansi-blue-fg">=</span>agg<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    299</span>     self._predict_counter = tf.Variable(

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(cls, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    266</span>       <span class="ansi-green-fg">return</span> cls<span class="ansi-blue-fg">.</span>_variable_v1_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    267</span>     <span class="ansi-green-fg">elif</span> cls <span class="ansi-green-fg">is</span> Variable<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 268</span><span class="ansi-red-fg">       </span><span class="ansi-green-fg">return</span> cls<span class="ansi-blue-fg">.</span>_variable_v2_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    269</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    270</span>       <span class="ansi-green-fg">return</span> super<span class="ansi-blue-fg">(</span>VariableMetaclass<span class="ansi-blue-fg">,</span> cls<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>__call__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py</span> in <span class="ansi-cyan-fg">_variable_v2_call</span><span class="ansi-blue-fg">(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)</span>
<span class="ansi-green-intense-fg ansi-bold">    260</span>         synchronization<span class="ansi-blue-fg">=</span>synchronization<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    261</span>         aggregation<span class="ansi-blue-fg">=</span>aggregation<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 262</span><span class="ansi-red-fg">         shape=shape)
</span><span class="ansi-green-intense-fg ansi-bold">    263</span> 
<span class="ansi-green-intense-fg ansi-bold">    264</span>   <span class="ansi-green-fg">def</span> __call__<span class="ansi-blue-fg">(</span>cls<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py</span> in <span class="ansi-cyan-fg">&lt;lambda&gt;</span><span class="ansi-blue-fg">(**kws)</span>
<span class="ansi-green-intense-fg ansi-bold">    241</span>                         shape=None):
<span class="ansi-green-intense-fg ansi-bold">    242</span>     <span class="ansi-blue-fg">"""Call on Variable class. Useful to force the signature."""</span>
<span class="ansi-green-fg">--&gt; 243</span><span class="ansi-red-fg">     </span>previous_getter <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">lambda</span> <span class="ansi-blue-fg">**</span>kws<span class="ansi-blue-fg">:</span> default_variable_creator_v2<span class="ansi-blue-fg">(</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kws<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    244</span>     <span class="ansi-green-fg">for</span> _<span class="ansi-blue-fg">,</span> getter <span class="ansi-green-fg">in</span> ops<span class="ansi-blue-fg">.</span>get_default_graph<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>_variable_creator_stack<span class="ansi-blue-fg">:</span>  <span class="ansi-red-fg"># pylint: disable=protected-access</span>
<span class="ansi-green-intense-fg ansi-bold">    245</span>       previous_getter <span class="ansi-blue-fg">=</span> _make_getter<span class="ansi-blue-fg">(</span>getter<span class="ansi-blue-fg">,</span> previous_getter<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py</span> in <span class="ansi-cyan-fg">default_variable_creator_v2</span><span class="ansi-blue-fg">(next_creator, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   2673</span>       synchronization<span class="ansi-blue-fg">=</span>synchronization<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   2674</span>       aggregation<span class="ansi-blue-fg">=</span>aggregation<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">-&gt; 2675</span><span class="ansi-red-fg">       shape=shape)
</span><span class="ansi-green-intense-fg ansi-bold">   2676</span> 
<span class="ansi-green-intense-fg ansi-bold">   2677</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(cls, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    268</span>       <span class="ansi-green-fg">return</span> cls<span class="ansi-blue-fg">.</span>_variable_v2_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    269</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 270</span><span class="ansi-red-fg">       </span><span class="ansi-green-fg">return</span> super<span class="ansi-blue-fg">(</span>VariableMetaclass<span class="ansi-blue-fg">,</span> cls<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>__call__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    271</span> 
<span class="ansi-green-intense-fg ansi-bold">    272</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)</span>
<span class="ansi-green-intense-fg ansi-bold">   1611</span>           aggregation<span class="ansi-blue-fg">=</span>aggregation<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1612</span>           shape<span class="ansi-blue-fg">=</span>shape<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">-&gt; 1613</span><span class="ansi-red-fg">           distribute_strategy=distribute_strategy)
</span><span class="ansi-green-intense-fg ansi-bold">   1614</span> 
<span class="ansi-green-intense-fg ansi-bold">   1615</span>   def _init_from_args(self,

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py</span> in <span class="ansi-cyan-fg">_init_from_args</span><span class="ansi-blue-fg">(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)</span>
<span class="ansi-green-intense-fg ansi-bold">   1745</span>             initial_value = ops.convert_to_tensor(initial_value,
<span class="ansi-green-intense-fg ansi-bold">   1746</span>                                                   name<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">"initial_value"</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">-&gt; 1747</span><span class="ansi-red-fg">                                                   dtype=dtype)
</span><span class="ansi-green-intense-fg ansi-bold">   1748</span>           <span class="ansi-green-fg">if</span> shape <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1749</span>             <span class="ansi-green-fg">if</span> <span class="ansi-green-fg">not</span> initial_value<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">.</span>is_compatible_with<span class="ansi-blue-fg">(</span>shape<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py</span> in <span class="ansi-cyan-fg">wrapped</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    161</span>         <span class="ansi-green-fg">with</span> Trace<span class="ansi-blue-fg">(</span>trace_name<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>trace_kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    162</span>           <span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 163</span><span class="ansi-red-fg">       </span><span class="ansi-green-fg">return</span> func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    164</span> 
<span class="ansi-green-intense-fg ansi-bold">    165</span>     <span class="ansi-green-fg">return</span> wrapped

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py</span> in <span class="ansi-cyan-fg">convert_to_tensor</span><span class="ansi-blue-fg">(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)</span>
<span class="ansi-green-intense-fg ansi-bold">   1564</span> 
<span class="ansi-green-intense-fg ansi-bold">   1565</span>     <span class="ansi-green-fg">if</span> ret <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">-&gt; 1566</span><span class="ansi-red-fg">       </span>ret <span class="ansi-blue-fg">=</span> conversion_func<span class="ansi-blue-fg">(</span>value<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">=</span>dtype<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">=</span>name<span class="ansi-blue-fg">,</span> as_ref<span class="ansi-blue-fg">=</span>as_ref<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1567</span> 
<span class="ansi-green-intense-fg ansi-bold">   1568</span>     <span class="ansi-green-fg">if</span> ret <span class="ansi-green-fg">is</span> NotImplemented<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py</span> in <span class="ansi-cyan-fg">_default_conversion_function</span><span class="ansi-blue-fg">(***failed resolving arguments***)</span>
<span class="ansi-green-intense-fg ansi-bold">     50</span> <span class="ansi-green-fg">def</span> _default_conversion_function<span class="ansi-blue-fg">(</span>value<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">,</span> as_ref<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     51</span>   <span class="ansi-green-fg">del</span> as_ref  <span class="ansi-red-fg"># Unused.</span>
<span class="ansi-green-fg">---&gt; 52</span><span class="ansi-red-fg">   </span><span class="ansi-green-fg">return</span> constant_op<span class="ansi-blue-fg">.</span>constant<span class="ansi-blue-fg">(</span>value<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">=</span>name<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     53</span> 
<span class="ansi-green-intense-fg ansi-bold">     54</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py</span> in <span class="ansi-cyan-fg">constant</span><span class="ansi-blue-fg">(value, dtype, shape, name)</span>
<span class="ansi-green-intense-fg ansi-bold">    270</span>   """
<span class="ansi-green-intense-fg ansi-bold">    271</span>   return _constant_impl(value, dtype, shape, name, verify_shape=False,
<span class="ansi-green-fg">--&gt; 272</span><span class="ansi-red-fg">                         allow_broadcast=True)
</span><span class="ansi-green-intense-fg ansi-bold">    273</span> 
<span class="ansi-green-intense-fg ansi-bold">    274</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py</span> in <span class="ansi-cyan-fg">_constant_impl</span><span class="ansi-blue-fg">(value, dtype, shape, name, verify_shape, allow_broadcast)</span>
<span class="ansi-green-intense-fg ansi-bold">    281</span>       <span class="ansi-green-fg">with</span> trace<span class="ansi-blue-fg">.</span>Trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"tf.constant"</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    282</span>         <span class="ansi-green-fg">return</span> _constant_eager_impl<span class="ansi-blue-fg">(</span>ctx<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">,</span> shape<span class="ansi-blue-fg">,</span> verify_shape<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 283</span><span class="ansi-red-fg">     </span><span class="ansi-green-fg">return</span> _constant_eager_impl<span class="ansi-blue-fg">(</span>ctx<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">,</span> shape<span class="ansi-blue-fg">,</span> verify_shape<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    284</span> 
<span class="ansi-green-intense-fg ansi-bold">    285</span>   g <span class="ansi-blue-fg">=</span> ops<span class="ansi-blue-fg">.</span>get_default_graph<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py</span> in <span class="ansi-cyan-fg">_constant_eager_impl</span><span class="ansi-blue-fg">(ctx, value, dtype, shape, verify_shape)</span>
<span class="ansi-green-intense-fg ansi-bold">    306</span> <span class="ansi-green-fg">def</span> _constant_eager_impl<span class="ansi-blue-fg">(</span>ctx<span class="ansi-blue-fg">,</span> value<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">,</span> shape<span class="ansi-blue-fg">,</span> verify_shape<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    307</span>   <span class="ansi-blue-fg">"""Creates a constant on the current device."""</span>
<span class="ansi-green-fg">--&gt; 308</span><span class="ansi-red-fg">   </span>t <span class="ansi-blue-fg">=</span> convert_to_eager_tensor<span class="ansi-blue-fg">(</span>value<span class="ansi-blue-fg">,</span> ctx<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    309</span>   <span class="ansi-green-fg">if</span> shape <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    310</span>     <span class="ansi-green-fg">return</span> t

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py</span> in <span class="ansi-cyan-fg">convert_to_eager_tensor</span><span class="ansi-blue-fg">(value, ctx, dtype)</span>
<span class="ansi-green-intense-fg ansi-bold">    103</span>     <span class="ansi-green-fg">except</span> AttributeError<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    104</span>       dtype <span class="ansi-blue-fg">=</span> dtypes<span class="ansi-blue-fg">.</span>as_dtype<span class="ansi-blue-fg">(</span>dtype<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>as_datatype_enum
<span class="ansi-green-fg">--&gt; 105</span><span class="ansi-red-fg">   </span>ctx<span class="ansi-blue-fg">.</span>ensure_initialized<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    106</span>   <span class="ansi-green-fg">return</span> ops<span class="ansi-blue-fg">.</span>EagerTensor<span class="ansi-blue-fg">(</span>value<span class="ansi-blue-fg">,</span> ctx<span class="ansi-blue-fg">.</span>device_name<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    107</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py</span> in <span class="ansi-cyan-fg">ensure_initialized</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    553</span>         pywrap_tfe.TFE_ContextOptionsSetRunEagerOpAsFunction(
<span class="ansi-green-intense-fg ansi-bold">    554</span>             opts, self._run_eager_op_as_function)
<span class="ansi-green-fg">--&gt; 555</span><span class="ansi-red-fg">         </span>context_handle <span class="ansi-blue-fg">=</span> pywrap_tfe<span class="ansi-blue-fg">.</span>TFE_NewContext<span class="ansi-blue-fg">(</span>opts<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    556</span>       <span class="ansi-green-fg">finally</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    557</span>         pywrap_tfe<span class="ansi-blue-fg">.</span>TFE_DeleteContextOptions<span class="ansi-blue-fg">(</span>opts<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">MemoryError</span>: std::bad_alloc</pre> </div> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">analysis</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">meta_loss</span><span class="p">,</span>
    <span class="n">resources_per_trial</span><span class="o">=</span><span class="p">{</span><span class="s1">'gpu'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">'cpu'</span><span class="p">:</span> <span class="mi">2</span><span class="p">},</span>
    <span class="n">config</span><span class="o">=</span><span class="n">small_config</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Best config: "</span><span class="p">,</span> <span class="n">analysis</span><span class="o">.</span><span class="n">get_best_config</span><span class="p">(</span>
    <span class="n">metric</span><span class="o">=</span><span class="s2">"val_loss"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"min"</span><span class="p">))</span>

<span class="c1"># Get a dataframe for analyzing trial results.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">analysis</span><span class="o">.</span><span class="n">results_df</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>2021-11-01 12:30:23,241	WARNING function_runner.py:559 -- Function checkpointing is disabled. This may result in unexpected behavior when using checkpointing features or certain schedulers. To enable, set the train function arguments to be `func(config, checkpoint_dir=None)`.
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.2/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-30-23<br/>Number of trials: 3/3 (3 PENDING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th>optimizer_name </th><th style="text-align: right;"> units</th></tr> </thead> <tbody> <tr><td>meta_loss_7c005_00000</td><td>PENDING </td><td> </td><td style="text-align: right;"> 32</td><td>relu </td><td>relu </td><td>SGD </td><td style="text-align: right;"> 8</td></tr> <tr><td>meta_loss_7c005_00001</td><td>PENDING </td><td> </td><td style="text-align: right;"> 16</td><td>relu </td><td>relu </td><td>Adam </td><td style="text-align: right;"> 16</td></tr> <tr><td>meta_loss_7c005_00002</td><td>PENDING </td><td> </td><td style="text-align: right;"> 32</td><td>relu </td><td>relu </td><td>SGD </td><td style="text-align: right;"> 32</td></tr> </tbody> </table><br/><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.9/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-30-23<br/>Number of trials: 3/3 (2 PENDING, 1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th>optimizer_name </th><th style="text-align: right;"> units</th></tr> </thead> <tbody> <tr><td>meta_loss_7c005_00000</td><td>RUNNING </td><td> </td><td style="text-align: right;"> 32</td><td>relu </td><td>relu </td><td>SGD </td><td style="text-align: right;"> 8</td></tr> <tr><td>meta_loss_7c005_00001</td><td>PENDING </td><td> </td><td style="text-align: right;"> 16</td><td>relu </td><td>relu </td><td>Adam </td><td style="text-align: right;"> 16</td></tr> <tr><td>meta_loss_7c005_00002</td><td>PENDING </td><td> </td><td style="text-align: right;"> 32</td><td>relu </td><td>relu </td><td>SGD </td><td style="text-align: right;"> 32</td></tr> </tbody> </table><br/><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre><span class="ansi-cyan-fg">(pid=1939)</span> 2021-11-01 12:30:29.807450: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
<span class="ansi-cyan-fg">(pid=1939)</span> 2021-11-01 12:30:29.807537: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: deeplearning-7-vm
<span class="ansi-cyan-fg">(pid=1939)</span> 2021-11-01 12:30:29.807554: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: deeplearning-7-vm
<span class="ansi-cyan-fg">(pid=1939)</span> 2021-11-01 12:30:29.807744: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.73.1
<span class="ansi-cyan-fg">(pid=1939)</span> 2021-11-01 12:30:29.807788: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.73.1
<span class="ansi-cyan-fg">(pid=1939)</span> 2021-11-01 12:30:29.807800: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.73.1
<span class="ansi-cyan-fg">(pid=1939)</span> 2021-11-01 12:30:29.808361: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
<span class="ansi-cyan-fg">(pid=1939)</span> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-01 12:30:30,147	ERROR trial_runner.py:846 -- Trial meta_loss_7c005_00000: Error processing event.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 812, in _process_trial
    results = self.trial_executor.fetch_result(trial)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 767, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/opt/conda/lib/python3.7/site-packages/ray/_private/client_mode_hook.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/ray/worker.py", line 1623, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
2021-11-01 12:30:30,152	WARNING worker.py:1227 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff8bb23fe5668d6d46702920b803000000 Worker ID: ae85aa106aa3d6af84167e08626e369bf854be3ac9d9b62787c6181d Node ID: de2fbc5360fb324acfae8b140ae1c049d7b7834725943bf2cdb2e73e Worker IP address: 10.138.0.10 Worker port: 10005 Worker PID: 1939
<span class="ansi-cyan-fg">(pid=1939)</span> *** SIGSEGV received at time=1635769830 on cpu 0 ***
<span class="ansi-cyan-fg">(pid=1939)</span> PC: @     0x56017b7d2a8e  (unknown)  PyErr_SetObject
<span class="ansi-cyan-fg">(pid=1939)</span>     @     0x7efca180d730  (unknown)  (unknown)
<span class="ansi-cyan-fg">(pid=1939)</span>     @     0x56017ba1f0e0  (unknown)  (unknown)
<span class="ansi-cyan-fg">(pid=1939)</span> [2021-11-01 12:30:30,119 E 1939 1964] logging.cc:315: *** SIGSEGV received at time=1635769830 on cpu 0 ***
<span class="ansi-cyan-fg">(pid=1939)</span> [2021-11-01 12:30:30,120 E 1939 1964] logging.cc:315: PC: @     0x56017b7d2a8e  (unknown)  PyErr_SetObject
<span class="ansi-cyan-fg">(pid=1939)</span> [2021-11-01 12:30:30,122 E 1939 1964] logging.cc:315:     @     0x7efca180d730  (unknown)  (unknown)
<span class="ansi-cyan-fg">(pid=1939)</span> [2021-11-01 12:30:30,125 E 1939 1964] logging.cc:315:     @     0x56017ba1f0e0  (unknown)  (unknown)
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Result for meta_loss_7c005_00000:
  {}
  
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.5/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-30-23<br/>Number of trials: 3/3 (1 ERROR, 1 PENDING, 1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th>optimizer_name </th><th style="text-align: right;"> units</th></tr> </thead> <tbody> <tr><td>meta_loss_7c005_00001</td><td>RUNNING </td><td> </td><td style="text-align: right;"> 16</td><td>relu </td><td>relu </td><td>Adam </td><td style="text-align: right;"> 16</td></tr> <tr><td>meta_loss_7c005_00002</td><td>PENDING </td><td> </td><td style="text-align: right;"> 32</td><td>relu </td><td>relu </td><td>SGD </td><td style="text-align: right;"> 32</td></tr> <tr><td>meta_loss_7c005_00000</td><td>ERROR </td><td> </td><td style="text-align: right;"> 32</td><td>relu </td><td>relu </td><td>SGD </td><td style="text-align: right;"> 8</td></tr> </tbody> </table><br/>Number of errored trials: 1<br/><table> <thead> <tr><th>Trial name </th><th style="text-align: right;"> # failures</th><th>error file </th></tr> </thead> <tbody> <tr><td>meta_loss_7c005_00000</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-30-23/meta_loss_7c005_00000_0_batch_size=32,conv_activation=relu,dense_activation=relu,optimizer_name=SGD,units=8_2021-11-01_12-30-23/error.txt</td></tr> </tbody> </table><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre><span class="ansi-cyan-fg">(pid=1977)</span> 2021-11-01 12:30:36.149869: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
<span class="ansi-cyan-fg">(pid=1977)</span> 2021-11-01 12:30:36.149961: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: deeplearning-7-vm
<span class="ansi-cyan-fg">(pid=1977)</span> 2021-11-01 12:30:36.149977: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: deeplearning-7-vm
<span class="ansi-cyan-fg">(pid=1977)</span> 2021-11-01 12:30:36.150150: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.73.1
<span class="ansi-cyan-fg">(pid=1977)</span> 2021-11-01 12:30:36.150192: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.73.1
<span class="ansi-cyan-fg">(pid=1977)</span> 2021-11-01 12:30:36.150204: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.73.1
<span class="ansi-cyan-fg">(pid=1977)</span> 2021-11-01 12:30:36.150687: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
<span class="ansi-cyan-fg">(pid=1977)</span> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
<span class="ansi-cyan-fg">(pid=1977)</span> *** SIGSEGV received at time=1635769836 on cpu 1 ***
<span class="ansi-cyan-fg">(pid=1977)</span> PC: @     0x5573b8b2ba8e  (unknown)  PyErr_SetObject
<span class="ansi-cyan-fg">(pid=1977)</span>     @     0x7f4d76ff4730  (unknown)  (unknown)
<span class="ansi-cyan-fg">(pid=1977)</span>     @     0x5573b8d780e0  (unknown)  (unknown)
<span class="ansi-cyan-fg">(pid=1977)</span> [2021-11-01 12:30:36,443 E 1977 2002] logging.cc:315: *** SIGSEGV received at time=1635769836 on cpu 1 ***
<span class="ansi-cyan-fg">(pid=1977)</span> [2021-11-01 12:30:36,443 E 1977 2002] logging.cc:315: PC: @     0x5573b8b2ba8e  (unknown)  PyErr_SetObject
<span class="ansi-cyan-fg">(pid=1977)</span> [2021-11-01 12:30:36,446 E 1977 2002] logging.cc:315:     @     0x7f4d76ff4730  (unknown)  (unknown)
<span class="ansi-cyan-fg">(pid=1977)</span> [2021-11-01 12:30:36,450 E 1977 2002] logging.cc:315:     @     0x5573b8d780e0  (unknown)  (unknown)
2021-11-01 12:30:36,476	ERROR trial_runner.py:846 -- Trial meta_loss_7c005_00001: Error processing event.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 812, in _process_trial
    results = self.trial_executor.fetch_result(trial)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 767, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/opt/conda/lib/python3.7/site-packages/ray/_private/client_mode_hook.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/ray/worker.py", line 1623, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
2021-11-01 12:30:36,477	WARNING worker.py:1227 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffd685dca337370d9be30994e603000000 Worker ID: dc32c63cf446d421627c3e8460cfa6fb17cc6aac0f09d251fa6193a7 Node ID: de2fbc5360fb324acfae8b140ae1c049d7b7834725943bf2cdb2e73e Worker IP address: 10.138.0.10 Worker port: 10006 Worker PID: 1977
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Result for meta_loss_7c005_00001:
  {}
  
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.5/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 2.0/2 CPUs, 0/1 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-30-23<br/>Number of trials: 3/3 (2 ERROR, 1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th>optimizer_name </th><th style="text-align: right;"> units</th></tr> </thead> <tbody> <tr><td>meta_loss_7c005_00002</td><td>RUNNING </td><td> </td><td style="text-align: right;"> 32</td><td>relu </td><td>relu </td><td>SGD </td><td style="text-align: right;"> 32</td></tr> <tr><td>meta_loss_7c005_00000</td><td>ERROR </td><td> </td><td style="text-align: right;"> 32</td><td>relu </td><td>relu </td><td>SGD </td><td style="text-align: right;"> 8</td></tr> <tr><td>meta_loss_7c005_00001</td><td>ERROR </td><td> </td><td style="text-align: right;"> 16</td><td>relu </td><td>relu </td><td>Adam </td><td style="text-align: right;"> 16</td></tr> </tbody> </table><br/>Number of errored trials: 2<br/><table> <thead> <tr><th>Trial name </th><th style="text-align: right;"> # failures</th><th>error file </th></tr> </thead> <tbody> <tr><td>meta_loss_7c005_00000</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-30-23/meta_loss_7c005_00000_0_batch_size=32,conv_activation=relu,dense_activation=relu,optimizer_name=SGD,units=8_2021-11-01_12-30-23/error.txt </td></tr> <tr><td>meta_loss_7c005_00001</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-30-23/meta_loss_7c005_00001_1_batch_size=16,conv_activation=relu,dense_activation=relu,optimizer_name=Adam,units=16_2021-11-01_12-30-24/error.txt</td></tr> </tbody> </table><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre><span class="ansi-cyan-fg">(pid=2015)</span> 2021-11-01 12:30:42.757520: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
<span class="ansi-cyan-fg">(pid=2015)</span> 2021-11-01 12:30:42.757606: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: deeplearning-7-vm
<span class="ansi-cyan-fg">(pid=2015)</span> 2021-11-01 12:30:42.757630: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: deeplearning-7-vm
<span class="ansi-cyan-fg">(pid=2015)</span> 2021-11-01 12:30:42.757796: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.73.1
<span class="ansi-cyan-fg">(pid=2015)</span> 2021-11-01 12:30:42.757837: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.73.1
<span class="ansi-cyan-fg">(pid=2015)</span> 2021-11-01 12:30:42.757848: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.73.1
<span class="ansi-cyan-fg">(pid=2015)</span> 2021-11-01 12:30:42.758400: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
<span class="ansi-cyan-fg">(pid=2015)</span> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-11-01 12:30:43,077	ERROR trial_runner.py:846 -- Trial meta_loss_7c005_00002: Error processing event.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 812, in _process_trial
    results = self.trial_executor.fetch_result(trial)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 767, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/opt/conda/lib/python3.7/site-packages/ray/_private/client_mode_hook.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/ray/worker.py", line 1623, in get
    raise value
ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.
2021-11-01 12:30:43,085	WARNING worker.py:1227 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffffe5361df5652c1dd93637d63803000000 Worker ID: e61b3c45187b164f348cd5f9432119b19d3c99d4f0b87f5075a51879 Node ID: de2fbc5360fb324acfae8b140ae1c049d7b7834725943bf2cdb2e73e Worker IP address: 10.138.0.10 Worker port: 10007 Worker PID: 2015
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Result for meta_loss_7c005_00002:
  {}
  
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.2/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 0/2 CPUs, 0/1 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/meta_loss_2021-11-01_12-30-23<br/>Number of trials: 3/3 (3 ERROR)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th style="text-align: right;"> batch_size</th><th>conv_activation </th><th>dense_activation </th><th>optimizer_name </th><th style="text-align: right;"> units</th></tr> </thead> <tbody> <tr><td>meta_loss_7c005_00000</td><td>ERROR </td><td> </td><td style="text-align: right;"> 32</td><td>relu </td><td>relu </td><td>SGD </td><td style="text-align: right;"> 8</td></tr> <tr><td>meta_loss_7c005_00001</td><td>ERROR </td><td> </td><td style="text-align: right;"> 16</td><td>relu </td><td>relu </td><td>Adam </td><td style="text-align: right;"> 16</td></tr> <tr><td>meta_loss_7c005_00002</td><td>ERROR </td><td> </td><td style="text-align: right;"> 32</td><td>relu </td><td>relu </td><td>SGD </td><td style="text-align: right;"> 32</td></tr> </tbody> </table><br/>Number of errored trials: 3<br/><table> <thead> <tr><th>Trial name </th><th style="text-align: right;"> # failures</th><th>error file </th></tr> </thead> <tbody> <tr><td>meta_loss_7c005_00000</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-30-23/meta_loss_7c005_00000_0_batch_size=32,conv_activation=relu,dense_activation=relu,optimizer_name=SGD,units=8_2021-11-01_12-30-23/error.txt </td></tr> <tr><td>meta_loss_7c005_00001</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-30-23/meta_loss_7c005_00001_1_batch_size=16,conv_activation=relu,dense_activation=relu,optimizer_name=Adam,units=16_2021-11-01_12-30-24/error.txt</td></tr> <tr><td>meta_loss_7c005_00002</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/meta_loss_2021-11-01_12-30-23/meta_loss_7c005_00002_2_batch_size=32,conv_activation=relu,dense_activation=relu,optimizer_name=SGD,units=32_2021-11-01_12-30-30/error.txt </td></tr> </tbody> </table><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre><span class="ansi-cyan-fg">(pid=2015)</span> *** SIGSEGV received at time=1635769843 on cpu 0 ***
<span class="ansi-cyan-fg">(pid=2015)</span> PC: @     0x55d94c62aa8e  (unknown)  PyErr_SetObject
<span class="ansi-cyan-fg">(pid=2015)</span>     @     0x7f72b39e2730  (unknown)  (unknown)
<span class="ansi-cyan-fg">(pid=2015)</span>     @     0x55d94c8770e0  (unknown)  (unknown)
<span class="ansi-cyan-fg">(pid=2015)</span> [2021-11-01 12:30:43,049 E 2015 2040] logging.cc:315: *** SIGSEGV received at time=1635769843 on cpu 0 ***
<span class="ansi-cyan-fg">(pid=2015)</span> [2021-11-01 12:30:43,049 E 2015 2040] logging.cc:315: PC: @     0x55d94c62aa8e  (unknown)  PyErr_SetObject
<span class="ansi-cyan-fg">(pid=2015)</span> [2021-11-01 12:30:43,052 E 2015 2040] logging.cc:315:     @     0x7f72b39e2730  (unknown)  (unknown)
<span class="ansi-cyan-fg">(pid=2015)</span> [2021-11-01 12:30:43,055 E 2015 2040] logging.cc:315:     @     0x55d94c8770e0  (unknown)  (unknown)
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">TuneError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipykernel_1868/3609324667.py</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span>     meta_loss<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span>     resources_per_trial<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">'gpu'</span><span class="ansi-blue-fg">:</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">'cpu'</span><span class="ansi-blue-fg">:</span> <span class="ansi-cyan-fg">2</span><span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">----&gt; 4</span><span class="ansi-red-fg">     config=small_config)
</span><span class="ansi-green-intense-fg ansi-bold">      5</span> 
<span class="ansi-green-intense-fg ansi-bold">      6</span> print("Best config: ", analysis.get_best_config(

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/ray/tune/tune.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)</span>
<span class="ansi-green-intense-fg ansi-bold">    609</span>     <span class="ansi-green-fg">if</span> incomplete_trials<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    610</span>         <span class="ansi-green-fg">if</span> raise_on_failed_trial <span class="ansi-green-fg">and</span> <span class="ansi-green-fg">not</span> state<span class="ansi-blue-fg">[</span>signal<span class="ansi-blue-fg">.</span>SIGINT<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 611</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> TuneError<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"Trials did not complete"</span><span class="ansi-blue-fg">,</span> incomplete_trials<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    612</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    613</span>             logger<span class="ansi-blue-fg">.</span>error<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"Trials did not complete: %s"</span><span class="ansi-blue-fg">,</span> incomplete_trials<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">TuneError</span>: ('Trials did not complete', [meta_loss_7c005_00000, meta_loss_7c005_00001, meta_loss_7c005_00002])</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>There were several outer loop iterations behind those code blocks above. It seems like the behavior of <code>meta_loss</code> changes during a tuning session causing bugs to be raised. I found a <a href="https://docs.ray.io/en/latest/tune/examples/tune_mnist_keras.html">keras native example</a> while debugging this issue and read the ray tune documentation. The above keras example did not actually work, so I probed into the training pipeline and found that the <code>model.fit</code> function raises tensorflow errors during ray worker execution time. To combat this, I wrote my own training loop using <code>tf.GradientTape</code> and further scaled down the hyperparameter space:</p> <h3 id="Iteration-3">Iteration 3<a class="anchor-link" href="#Iteration-3"></a></h3> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">trainable</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>

    <span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
    <span class="n">keras</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span>
    <span class="n">tfkl</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span>
    
    <span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">'hidden_units'</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"relu"</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">)</span>
    <span class="p">])</span>
    
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">train_batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s1">'train_batch_size'</span><span class="p">]</span>
    <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">SparseCategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="mf">0.005</span><span class="p">)</span>
    
    <span class="c1"># for some reason keras' model.fit functions raises have errors so I wrote my own training loop</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">minibatches</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># X_train.shape[0]//train_batch_size</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">minibatches</span><span class="p">):</span>
            <span class="n">Xmb_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">step</span><span class="o">*</span><span class="n">train_batch_size</span><span class="p">:(</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">train_batch_size</span><span class="p">]</span>
            <span class="n">Ymb_train</span> <span class="o">=</span> <span class="n">Y_train</span><span class="p">[</span><span class="n">step</span><span class="o">*</span><span class="n">train_batch_size</span><span class="p">:(</span><span class="n">step</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">train_batch_size</span><span class="p">]</span>
            
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
                <span class="n">probits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">Xmb_train</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">loss_value</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">Ymb_train</span><span class="p">,</span> <span class="n">probits</span><span class="p">)</span>
            
            <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss_value</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">))</span>
            
    
    <span class="sd">"""</span>
<span class="sd">    # evalutate model</span>
<span class="sd">    for step in range(X_train.shape[0]//batch_size):</span>
<span class="sd">        Xmb_train = X_train[step*batch_size:(step+1)*batch_size]</span>
<span class="sd">        Ymb_train = Y_train[step*batch_size:(step+1)*batch_size]</span>

<span class="sd">        with tf.GradientTape() as tape:</span>
<span class="sd">            probits = model(Xmb_test)</span>
<span class="sd">            loss_value = loss_fn(Ymb_test, probits)"""</span>
    <span class="sd">"""</span>
<span class="sd">    history = model.fit(</span>
<span class="sd">        X_train,</span>
<span class="sd">        Y_train,</span>
<span class="sd">        batch_size=config['train_batch_size'],</span>
<span class="sd">        epochs=10,</span>
<span class="sd">        verbose=0,</span>
<span class="sd">        validation_data=(X_test, Y_test),</span>
<span class="sd">        validation_batch_size=64,</span>
<span class="sd">    )"""</span>

    <span class="c1"># report validation loss</span>
    <span class="n">probits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:</span><span class="mi">16</span><span class="p">],</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">final_val_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">Y_test</span><span class="p">[:</span><span class="mi">16</span><span class="p">],</span> <span class="n">probits</span><span class="p">)</span>
    <span class="n">tune</span><span class="o">.</span><span class="n">report</span><span class="p">(</span><span class="n">val_loss</span><span class="o">=</span><span class="n">final_val_loss</span><span class="p">)</span>

<span class="n">analysis</span> <span class="o">=</span> <span class="n">tune</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">trainable</span><span class="p">,</span>
    <span class="n">config</span><span class="o">=</span><span class="p">{</span>
        <span class="s1">'train_batch_size'</span><span class="p">:</span> <span class="mi">16</span><span class="p">,</span>
        <span class="s1">'hidden_units'</span><span class="p">:</span> <span class="n">tune</span><span class="o">.</span><span class="n">choice</span><span class="p">([</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">])</span>
    <span class="p">},</span>
    <span class="n">resources_per_trial</span><span class="o">=</span><span class="p">{</span><span class="s1">'gpu'</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"best config: "</span><span class="p">,</span> <span class="n">analysis</span><span class="o">.</span><span class="n">get_best_config</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="s2">"val_loss"</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"max"</span><span class="p">))</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.2/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 0/1 CPUs, 0/1 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/trainable_2021-11-01_13-40-26<br/>Number of trials: 1/1 (1 PENDING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th style="text-align: right;"> hidden_units</th></tr> </thead> <tbody> <tr><td>trainable_45a03_00000</td><td>PENDING </td><td> </td><td style="text-align: right;"> 16</td></tr> </tbody> </table><br/><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.5/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 1.0/1 CPUs, 1.0/1 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/trainable_2021-11-01_13-40-26<br/>Number of trials: 1/1 (1 RUNNING)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th style="text-align: right;"> hidden_units</th></tr> </thead> <tbody> <tr><td>trainable_45a03_00000</td><td>RUNNING </td><td> </td><td style="text-align: right;"> 16</td></tr> </tbody> </table><br/><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre><span class="ansi-cyan-fg">(pid=7034)</span> 2021-11-01 13:40:34.073976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=7034)</span> 2021-11-01 13:40:34.085830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=7034)</span> 2021-11-01 13:40:34.086687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=7034)</span> 2021-11-01 13:40:34.087968: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
<span class="ansi-cyan-fg">(pid=7034)</span> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
<span class="ansi-cyan-fg">(pid=7034)</span> 2021-11-01 13:40:34.088281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=7034)</span> 2021-11-01 13:40:34.089149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=7034)</span> 2021-11-01 13:40:34.089986: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=7034)</span> 2021-11-01 13:40:34.541694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=7034)</span> 2021-11-01 13:40:34.542547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=7034)</span> 2021-11-01 13:40:34.543459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
<span class="ansi-cyan-fg">(pid=7034)</span> 2021-11-01 13:40:34,544	ERROR function_runner.py:266 -- Runner Thread raised error.
<span class="ansi-cyan-fg">(pid=7034)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=7034)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=7034)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=7034)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=7034)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/tmp/ipykernel_6823/3481960557.py", line 13, in trainable
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
<span class="ansi-cyan-fg">(pid=7034)</span>     result = method(self, *args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py", line 108, in __init__
<span class="ansi-cyan-fg">(pid=7034)</span>     name=name, autocast=False)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
<span class="ansi-cyan-fg">(pid=7034)</span>     result = method(self, *args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py", line 289, in __init__
<span class="ansi-cyan-fg">(pid=7034)</span>     self._init_batch_counters()
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
<span class="ansi-cyan-fg">(pid=7034)</span>     result = method(self, *args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py", line 297, in _init_batch_counters
<span class="ansi-cyan-fg">(pid=7034)</span>     self._train_counter = tf.Variable(0, dtype='int64', aggregation=agg)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 268, in __call__
<span class="ansi-cyan-fg">(pid=7034)</span>     return cls._variable_v2_call(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 262, in _variable_v2_call
<span class="ansi-cyan-fg">(pid=7034)</span>     shape=shape)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 243, in &lt;lambda&gt;
<span class="ansi-cyan-fg">(pid=7034)</span>     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py", line 2675, in default_variable_creator_v2
<span class="ansi-cyan-fg">(pid=7034)</span>     shape=shape)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 270, in __call__
<span class="ansi-cyan-fg">(pid=7034)</span>     return super(VariableMetaclass, cls).__call__(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py", line 1613, in __init__
<span class="ansi-cyan-fg">(pid=7034)</span>     distribute_strategy=distribute_strategy)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py", line 1747, in _init_from_args
<span class="ansi-cyan-fg">(pid=7034)</span>     dtype=dtype)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=7034)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=7034)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=7034)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=7034)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=7034)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=7034)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=7034)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=7034)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=7034)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=7034)</span> Exception in thread Thread-2:
<span class="ansi-cyan-fg">(pid=7034)</span> Traceback (most recent call last):
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/threading.py", line 926, in _bootstrap_inner
<span class="ansi-cyan-fg">(pid=7034)</span>     self.run()
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 279, in run
<span class="ansi-cyan-fg">(pid=7034)</span>     raise e
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
<span class="ansi-cyan-fg">(pid=7034)</span>     self._entrypoint()
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
<span class="ansi-cyan-fg">(pid=7034)</span>     self._status_reporter.get_checkpoint())
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/util/tracing/tracing_helper.py", line 449, in _resume_span
<span class="ansi-cyan-fg">(pid=7034)</span>     return method(self, *_args, **_kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
<span class="ansi-cyan-fg">(pid=7034)</span>     output = fn()
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/tmp/ipykernel_6823/3481960557.py", line 13, in trainable
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
<span class="ansi-cyan-fg">(pid=7034)</span>     result = method(self, *args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py", line 108, in __init__
<span class="ansi-cyan-fg">(pid=7034)</span>     name=name, autocast=False)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
<span class="ansi-cyan-fg">(pid=7034)</span>     result = method(self, *args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py", line 289, in __init__
<span class="ansi-cyan-fg">(pid=7034)</span>     self._init_batch_counters()
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
<span class="ansi-cyan-fg">(pid=7034)</span>     result = method(self, *args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py", line 297, in _init_batch_counters
<span class="ansi-cyan-fg">(pid=7034)</span>     self._train_counter = tf.Variable(0, dtype='int64', aggregation=agg)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 268, in __call__
<span class="ansi-cyan-fg">(pid=7034)</span>     return cls._variable_v2_call(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 262, in _variable_v2_call
<span class="ansi-cyan-fg">(pid=7034)</span>     shape=shape)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 243, in &lt;lambda&gt;
<span class="ansi-cyan-fg">(pid=7034)</span>     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py", line 2675, in default_variable_creator_v2
<span class="ansi-cyan-fg">(pid=7034)</span>     shape=shape)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 270, in __call__
<span class="ansi-cyan-fg">(pid=7034)</span>     return super(VariableMetaclass, cls).__call__(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py", line 1613, in __init__
<span class="ansi-cyan-fg">(pid=7034)</span>     distribute_strategy=distribute_strategy)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py", line 1747, in _init_from_args
<span class="ansi-cyan-fg">(pid=7034)</span>     dtype=dtype)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
<span class="ansi-cyan-fg">(pid=7034)</span>     return func(*args, **kwargs)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
<span class="ansi-cyan-fg">(pid=7034)</span>     ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
<span class="ansi-cyan-fg">(pid=7034)</span>     return constant_op.constant(value, dtype, name=name)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
<span class="ansi-cyan-fg">(pid=7034)</span>     allow_broadcast=True)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
<span class="ansi-cyan-fg">(pid=7034)</span>     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
<span class="ansi-cyan-fg">(pid=7034)</span>     t = convert_to_eager_tensor(value, ctx, dtype)
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
<span class="ansi-cyan-fg">(pid=7034)</span>     ctx.ensure_initialized()
<span class="ansi-cyan-fg">(pid=7034)</span>   File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
<span class="ansi-cyan-fg">(pid=7034)</span>     context_handle = pywrap_tfe.TFE_NewContext(opts)
<span class="ansi-cyan-fg">(pid=7034)</span> MemoryError: std::bad_alloc
<span class="ansi-cyan-fg">(pid=7034)</span> 
2021-11-01 13:40:34,747	ERROR trial_runner.py:846 -- Trial trainable_45a03_00000: Error processing event.
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 812, in _process_trial
    results = self.trial_executor.fetch_result(trial)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 767, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/opt/conda/lib/python3.7/site-packages/ray/_private/client_mode_hook.py", line 89, in wrapper
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/ray/worker.py", line 1621, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(TuneError): <span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=7034, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7f9637a4b150&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 189, in train_buffered
    result = self.train()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/trainable.py", line 248, in train
    result = self.step()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 379, in step
    self._report_thread_runner_error(block=True)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 527, in _report_thread_runner_error
    ("Trial raised an exception. Traceback:\n{}".format(err_tb_str)
ray.tune.error.TuneError: Trial raised an exception. Traceback:
<span class="ansi-cyan-fg">ray::ImplicitFunc.train_buffered()</span> (pid=7034, ip=10.138.0.10, repr=&lt;types.ImplicitFunc object at 0x7f9637a4b150&gt;)
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 260, in run
    self._entrypoint()
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 329, in entrypoint
    self._status_reporter.get_checkpoint())
  File "/opt/conda/lib/python3.7/site-packages/ray/tune/function_runner.py", line 594, in _trainable_func
    output = fn()
  File "/tmp/ipykernel_6823/3481960557.py", line 13, in trainable
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py", line 108, in __init__
    name=name, autocast=False)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py", line 289, in __init__
    self._init_batch_counters()
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py", line 530, in _method_wrapper
    result = method(self, *args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py", line 297, in _init_batch_counters
    self._train_counter = tf.Variable(0, dtype='int64', aggregation=agg)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 268, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 262, in _variable_v2_call
    shape=shape)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 243, in &lt;lambda&gt;
    previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py", line 2675, in default_variable_creator_v2
    shape=shape)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/variables.py", line 270, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py", line 1613, in __init__
    distribute_strategy=distribute_strategy)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py", line 1747, in _init_from_args
    dtype=dtype)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py", line 163, in wrapped
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py", line 1566, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py", line 52, in _default_conversion_function
    return constant_op.constant(value, dtype, name=name)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 272, in constant
    allow_broadcast=True)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 283, in _constant_impl
    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 308, in _constant_eager_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py", line 105, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File "/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/context.py", line 555, in ensure_initialized
    context_handle = pywrap_tfe.TFE_NewContext(opts)
MemoryError: std::bad_alloc
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Result for trainable_45a03_00000:
  {}
  
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedHTMLCommon jp-RenderedHTML jp-OutputArea-output" data-mime-type="text/html" tabindex="0"> == Status ==<br/>Memory usage on this node: 1.8/12.7 GiB<br/>Using FIFO scheduling algorithm.<br/>Resources requested: 0/1 CPUs, 0/1 GPUs, 0.0/7.2 GiB heap, 0.0/3.6 GiB objects (0.0/1.0 accelerator_type:K80)<br/>Result logdir: /home/jacobfv123/ray_results/trainable_2021-11-01_13-40-26<br/>Number of trials: 1/1 (1 ERROR)<br/><table> <thead> <tr><th>Trial name </th><th>status </th><th>loc </th><th style="text-align: right;"> hidden_units</th></tr> </thead> <tbody> <tr><td>trainable_45a03_00000</td><td>ERROR </td><td> </td><td style="text-align: right;"> 16</td></tr> </tbody> </table><br/>Number of errored trials: 1<br/><table> <thead> <tr><th>Trial name </th><th style="text-align: right;"> # failures</th><th>error file </th></tr> </thead> <tbody> <tr><td>trainable_45a03_00000</td><td style="text-align: right;"> 1</td><td>/home/jacobfv123/ray_results/trainable_2021-11-01_13-40-26/trainable_45a03_00000_0_hidden_units=16_2021-11-01_13-40-27/error.txt</td></tr> </tbody> </table><br/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">TuneError</span>                                 Traceback (most recent call last)
<span class="ansi-green-fg">/tmp/ipykernel_6823/3481960557.py</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">     65</span>         <span class="ansi-blue-fg">'hidden_units'</span><span class="ansi-blue-fg">:</span> tune<span class="ansi-blue-fg">.</span>choice<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">16</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">32</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">64</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     66</span>     },
<span class="ansi-green-fg">---&gt; 67</span><span class="ansi-red-fg">     </span>resources_per_trial<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">'gpu'</span><span class="ansi-blue-fg">:</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">}</span>
<span class="ansi-green-intense-fg ansi-bold">     68</span> )
<span class="ansi-green-intense-fg ansi-bold">     69</span> 

<span class="ansi-green-fg">/opt/conda/lib/python3.7/site-packages/ray/tune/tune.py</span> in <span class="ansi-cyan-fg">run</span><span class="ansi-blue-fg">(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, loggers, ray_auto_init, run_errored_only, global_checkpoint_period, with_server, upload_dir, sync_to_cloud, sync_to_driver, sync_on_checkpoint, _remote)</span>
<span class="ansi-green-intense-fg ansi-bold">    609</span>     <span class="ansi-green-fg">if</span> incomplete_trials<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    610</span>         <span class="ansi-green-fg">if</span> raise_on_failed_trial <span class="ansi-green-fg">and</span> <span class="ansi-green-fg">not</span> state<span class="ansi-blue-fg">[</span>signal<span class="ansi-blue-fg">.</span>SIGINT<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 611</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">raise</span> TuneError<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"Trials did not complete"</span><span class="ansi-blue-fg">,</span> incomplete_trials<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    612</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    613</span>             logger<span class="ansi-blue-fg">.</span>error<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"Trials did not complete: %s"</span><span class="ansi-blue-fg">,</span> incomplete_trials<span class="ansi-blue-fg">)</span>

<span class="ansi-red-fg">TuneError</span>: ('Trials did not complete', [trainable_45a03_00000])</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <h3 id="Iteration-4">Iteration 4<a class="anchor-link" href="#Iteration-4"></a></h3><p>At this point, I began to suspect serious issues with the way I am using <code>ray.tune</code>. I hope you found a solution. Maybe I have by now as well, since ray tune is such as flexible and useful tool. Along my search, I encountered a more narrow library <code>keras-tuner</code> that does what I want. Check out the <a href="https://www.tensorflow.org/tutorials/keras/keras_tuner">guide</a> for information on getting started. In my case, deploying <code>keras-tuner</code> was as simple as:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install -q -U keras-tuner
<span class="kn">import</span> <span class="nn">keras_tuner</span> <span class="k">as</span> <span class="nn">kt</span>
</pre></div> </div> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="n">keras</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span>
<span class="n">tfkl</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">layers</span>

<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">model_builder</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    
    <span class="n">hp_units</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'units'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">hp_units2</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'units2'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">hp_conv_activation</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_activation'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">])</span>
    <span class="n">hp_dense_activation</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dense_activation'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">])</span>
    <span class="n">hp_num_conv_layers</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'num_conv_layers'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hp_num_dense_layers</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'num_dense_layers'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hp_dropout_factor</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dropout_factor'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
    <span class="n">hp_optimizer</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'optimizer'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'SGD'</span><span class="p">,</span> <span class="s1">'Adam'</span><span class="p">,</span> <span class="s1">'Adadelta'</span><span class="p">])</span>
    <span class="c1">#hp_learning_rate = hp.choice('learning_rate', values=[0.0005, 0.001, 0.002, 0.005, 0.01])</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Reshape</span><span class="p">(</span><span class="n">target_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>  <span class="c1"># give each pixel a 1 dimensional channel</span>
        <span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">1</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">3</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="p">][:</span><span class="n">hp_num_conv_layers</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)),</span>
        <span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_dense_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp_units2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_dense_activation</span><span class="p">),</span>
        <span class="p">][:</span><span class="n">hp_num_dense_layers</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">hp_dropout_factor</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">)</span>
    <span class="p">])</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span> 
                  <span class="n">optimizer</span><span class="o">=</span><span class="n">hp_optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
</pre></div> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>The following code is directly copied from <a href="https://www.tensorflow.org/tutorials/keras/keras_tuner">https://www.tensorflow.org/tutorials/keras/keras_tuner</a></p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">kt</span><span class="o">.</span><span class="n">Hyperband</span><span class="p">(</span><span class="n">model_builder</span><span class="p">,</span>
                     <span class="n">objective</span><span class="o">=</span><span class="s1">'val_accuracy'</span><span class="p">,</span>
                     <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                     <span class="n">factor</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                     <span class="n">directory</span><span class="o">=</span><span class="s1">'my_dir'</span><span class="p">,</span>
                     <span class="n">project_name</span><span class="o">=</span><span class="s1">'intro_to_kt'</span><span class="p">)</span>
<span class="n">stop_early</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">'val_loss'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">stop_early</span><span class="p">])</span>

<span class="c1"># Get the optimal hyperparameters</span>
<span class="n">best_hps</span><span class="o">=</span><span class="n">tuner</span><span class="o">.</span><span class="n">get_best_hyperparameters</span><span class="p">(</span><span class="n">num_trials</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Hyperparameter search is complete. Best hyperparameters:'</span><span class="p">,</span> <span class="n">best_hps</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Trial 30 Complete [00h 00m 59s]
val_accuracy: 0.09950000047683716

Best val_accuracy So Far: 0.9877499938011169
Total elapsed time: 00h 21m 51s
INFO:tensorflow:Oracle triggered exit
Hyperparameter search is complete. Best hyperparameters: {'units': 480, 'units2': 160, 'conv_activation': 'tanh', 'dense_activation': 'relu', 'num_conv_layers': 1, 'num_dense_layers': 2, 'dropout_factor': 0.05, 'optimizer': 'SGD', 'tuner/epochs': 10, 'tuner/initial_epoch': 4, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '91393a31d51f30707bd93361fb509e4c'}
</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>I was surprised that the tuner chose <code>tanh</code> and the humble <code>SGD</code> optimizer. That's convenient since SGD is the fastest of the tested optimizers. Let's now test these hyperparameters to see if we can reach the <code>0.9877</code> validation accuracy that keras-tuner boasts:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tuner</span><span class="o">.</span><span class="n">hypermodel</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">best_hps</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">Y_train</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">),</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Epoch 1/10
1875/1875 - 8s - loss: 0.1581 - accuracy: 0.9518 - val_loss: 0.0658 - val_accuracy: 0.9798
Epoch 2/10
1875/1875 - 8s - loss: 0.0452 - accuracy: 0.9865 - val_loss: 0.0565 - val_accuracy: 0.9824
Epoch 3/10
1875/1875 - 8s - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.0425 - val_accuracy: 0.9863
Epoch 4/10
1875/1875 - 8s - loss: 0.0112 - accuracy: 0.9974 - val_loss: 0.0413 - val_accuracy: 0.9861
Epoch 5/10
1875/1875 - 8s - loss: 0.0048 - accuracy: 0.9994 - val_loss: 0.0438 - val_accuracy: 0.9871
Epoch 6/10
1875/1875 - 8s - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0450 - val_accuracy: 0.9869
Epoch 7/10
1875/1875 - 8s - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0400 - val_accuracy: 0.9879
Epoch 8/10
1875/1875 - 8s - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0401 - val_accuracy: 0.9884
Epoch 9/10
1875/1875 - 8s - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0406 - val_accuracy: 0.9876
Epoch 10/10
1875/1875 - 8s - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0395 - val_accuracy: 0.9877
</pre> </div> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'loss'</span><span class="p">,</span> <span class="s1">'val_loss'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="s1">'val_accuracy'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>Very nice performance! Almost 3 9's of validation accuracy. Let's play one more game with our model before concluding.</p> <h2 id="Fine-tuning-and-Transfer-Learning">Fine-tuning and Transfer Learning<a class="anchor-link" href="#Fine-tuning-and-Transfer-Learning"></a></h2><p>For <a href="https://arxiv.org/abs/1911.02685">transfer learning</a>, the idea is: pretrain in domain X, then train and test in domain Y. Transfer learning attempts to catch students who are only studying for the exam but not actually learning the content. A 'good' image model shouldn't have trouble retraining for <code>cifar10</code>. A narrow but useful application of transfer learning is fine-tuning a subset of the parameters to a new objective without major architectural changes. We're going to try fine-tuning our <code>model</code> for <code>cifar10</code> and see how representative its internal activations are of arbitrary images. This is an easy transfer to attempt since</p> <ul> <li>both are image classification problems and</li> <li>data is shaped the similarly in both datasets.</li> </ul> <p>We'll do this by freezing the parameters of all the layers except the final one and then retraining on a new dataset. Along the way, we'll evaluate (but not run gradient descent) on the model's loss in its origonal <code>mnist</code> classification task. Then we'll try to train a model that can classify images from either domain, and finally throw the inner optimizer into a hyperparameter tunning loop.</p> <p>Let's start by making our own training loop</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">mnist_test</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">cifar10_train</span><span class="p">,</span> <span class="n">cifar10_test</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># resize the cifar10 images to be (28,28)</span>
<span class="n">cifar10_train</span> <span class="o">=</span> <span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">cifar10_test</span> <span class="o">=</span> <span class="n">cifar10_test</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">cifar10_test</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">CustomEvaluation</span><span class="p">(</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">Callback</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">ds_name</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ds_name</span> <span class="o">=</span> <span class="n">ds_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ds_name</span><span class="si">}</span><span class="s1">_loss'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">acc_key</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">'</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">ds_name</span><span class="si">}</span><span class="s1">_acc'</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

    <span class="k">def</span> <span class="nf">on_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">logs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">logs</span><span class="p">:</span>
            <span class="n">logs</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

        <span class="n">loss</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">Y</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">logs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>
        <span class="n">logs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">acc_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">acc</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'%s: %0.5f - %s: %0.5f'</span> <span class="o">%</span> 
                  <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss_key</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">acc_key</span><span class="p">,</span> <span class="n">acc</span><span class="p">))</span>

<span class="n">mnist_eval_cb</span> <span class="o">=</span> <span class="n">CustomEvaluation</span><span class="p">(</span><span class="n">mnist_test</span><span class="p">,</span> <span class="s1">'mnist'</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cifar10_eval_cb</span> <span class="o">=</span> <span class="n">CustomEvaluation</span><span class="p">(</span><span class="n">cifar10_test</span><span class="p">,</span> <span class="s1">'cifar10'</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># only let the last layer learn</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div> </div> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">mnist_eval_cb</span><span class="p">,</span> <span class="n">cifar10_eval_cb</span><span class="p">]</span>
<span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Epoch 1/10
1563/1563 - 7s - loss: 2.7380 - accuracy: 0.0981
mnist_loss: 2.35357 - mnist_acc: 0.15990
cifar10_loss: 2.30254 - cifar10_acc: 0.10020
Epoch 2/10
1563/1563 - 6s - loss: 2.3028 - accuracy: 0.0961
mnist_loss: 2.30807 - mnist_acc: 0.17150
cifar10_loss: 2.30258 - cifar10_acc: 0.10000
Epoch 3/10
1563/1563 - 6s - loss: 2.3028 - accuracy: 0.0984
mnist_loss: 2.31940 - mnist_acc: 0.15170
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 4/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0986
mnist_loss: 2.32376 - mnist_acc: 0.14780
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 5/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0970
mnist_loss: 2.32900 - mnist_acc: 0.14830
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 6/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0981
mnist_loss: 2.32387 - mnist_acc: 0.15160
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 7/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0966
mnist_loss: 2.32490 - mnist_acc: 0.15050
cifar10_loss: 2.30257 - cifar10_acc: 0.10010
Epoch 8/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0976
mnist_loss: 2.33507 - mnist_acc: 0.14700
cifar10_loss: 2.30259 - cifar10_acc: 0.10000
Epoch 9/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0984
mnist_loss: 2.33530 - mnist_acc: 0.14980
cifar10_loss: 2.30258 - cifar10_acc: 0.10000
Epoch 10/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0981
mnist_loss: 2.31990 - mnist_acc: 0.15250
cifar10_loss: 2.30257 - cifar10_acc: 0.10010
</pre> </div> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'loss'</span><span class="p">,</span> <span class="s1">'cifar10_loss'</span><span class="p">,</span> <span class="s1">'mnist_acc'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="s1">'cifar10_acc'</span><span class="p">,</span> <span class="s1">'mnist_loss'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>This is not good. Amazingly, by forcing only the last layer to adapt to a new task, the model performed <em>worse</em> than random (1/10 = 0.1 &gt; 0.09...)! I'm going to help the model out by thawing out the rest of the layers. Let's see if that helps:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span><span class="o">=</span><span class="kc">True</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">mnist_eval_cb</span><span class="p">,</span> <span class="n">cifar10_eval_cb</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'loss'</span><span class="p">,</span> <span class="s1">'cifar10_loss'</span><span class="p">,</span> <span class="s1">'mnist_acc'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="s1">'cifar10_acc'</span><span class="p">,</span> <span class="s1">'mnist_loss'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Epoch 1/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0990
mnist_loss: 2.31927 - mnist_acc: 0.15290
cifar10_loss: 2.30257 - cifar10_acc: 0.10010
Epoch 2/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0978
mnist_loss: 2.31963 - mnist_acc: 0.15480
cifar10_loss: 2.30257 - cifar10_acc: 0.10000
Epoch 3/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0977
mnist_loss: 2.31968 - mnist_acc: 0.15230
cifar10_loss: 2.30256 - cifar10_acc: 0.09990
Epoch 4/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0981
mnist_loss: 2.32013 - mnist_acc: 0.15150
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 5/10
1563/1563 - 6s - loss: 2.3040 - accuracy: 0.0983
mnist_loss: 2.29998 - mnist_acc: 0.16470
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 6/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0964
mnist_loss: 2.30030 - mnist_acc: 0.16330
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 7/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0985
mnist_loss: 2.30038 - mnist_acc: 0.16020
cifar10_loss: 2.30257 - cifar10_acc: 0.09990
Epoch 8/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0992
mnist_loss: 2.29983 - mnist_acc: 0.16680
cifar10_loss: 2.30257 - cifar10_acc: 0.10000
Epoch 9/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0976
mnist_loss: 2.29999 - mnist_acc: 0.16140
cifar10_loss: 2.30257 - cifar10_acc: 0.10000
Epoch 10/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0999
mnist_loss: 2.29976 - mnist_acc: 0.16130
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>Sadly it does not. I think the problem is that I removed the RGB channels when I averaged over the last axis. I will modify the model to accept 3 channels instead of 1 and then tile the mnist dataset on a new last axis.</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">mnist_test</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">cifar10_train</span><span class="p">,</span> <span class="n">cifar10_test</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># resize the cifar10 images to be (28,28)</span>
<span class="n">cifar10_train</span> <span class="o">=</span> <span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">cifar10_test</span> <span class="o">=</span> <span class="n">cifar10_test</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">cifar10_test</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># insert and repeat 3 channels on greyscale mnist</span>
<span class="n">mnist_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">mnist_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">mnist_train</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">mnist_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">mnist_test</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">mnist_test</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">mnist_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mnist_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>

<span class="c1"># sanity check: make sure everything is shaped compatibly</span>
<span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="p">[</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">mnist_test</span><span class="p">,</span> <span class="n">cifar10_train</span><span class="p">,</span> <span class="n">cifar10_test</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">ds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>(60000, 28, 28, 3) (60000,)
(10000, 28, 28, 3) (10000,)
(50000, 28, 28, 3) (50000, 1)
(10000, 28, 28, 3) (10000, 1)
</pre> </div> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_builder</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    
    <span class="n">hp_units</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'units'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">hp_units2</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'units2'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">hp_conv_activation</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_activation'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">])</span>
    <span class="n">hp_dense_activation</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dense_activation'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">])</span>
    <span class="n">hp_num_conv_layers</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'num_conv_layers'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hp_num_dense_layers</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'num_dense_layers'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hp_dropout_factor</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dropout_factor'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
    <span class="n">hp_optimizer</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'optimizer'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'SGD'</span><span class="p">,</span> <span class="s1">'Adam'</span><span class="p">,</span> <span class="s1">'Adadelta'</span><span class="p">])</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
        <span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">1</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">3</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="p">][:</span><span class="n">hp_num_conv_layers</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_dense_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp_units2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_dense_activation</span><span class="p">),</span>
        <span class="p">][:</span><span class="n">hp_num_dense_layers</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">hp_dropout_factor</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">)</span>
    <span class="p">])</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span> 
                  <span class="n">optimizer</span><span class="o">=</span><span class="n">hp_optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">model_builder</span><span class="p">(</span><span class="n">best_hps</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">mnist_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">mnist_train</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">mnist_test</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'loss'</span><span class="p">,</span> <span class="s1">'val_loss'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="s1">'val_accuracy'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Epoch 1/10
1875/1875 - 8s - loss: 0.1521 - accuracy: 0.9533 - val_loss: 0.0689 - val_accuracy: 0.9784
Epoch 2/10
1875/1875 - 8s - loss: 0.0467 - accuracy: 0.9856 - val_loss: 0.0649 - val_accuracy: 0.9802
Epoch 3/10
1875/1875 - 8s - loss: 0.0236 - accuracy: 0.9930 - val_loss: 0.0500 - val_accuracy: 0.9837
Epoch 4/10
1875/1875 - 8s - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.0496 - val_accuracy: 0.9843
Epoch 5/10
1875/1875 - 8s - loss: 0.0067 - accuracy: 0.9985 - val_loss: 0.0420 - val_accuracy: 0.9880
Epoch 6/10
1875/1875 - 8s - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0434 - val_accuracy: 0.9874
Epoch 7/10
1875/1875 - 8s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0425 - val_accuracy: 0.9880
Epoch 8/10
1875/1875 - 8s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9886
Epoch 9/10
1875/1875 - 8s - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0447 - val_accuracy: 0.9880
Epoch 10/10
1875/1875 - 8s - loss: 8.9660e-04 - accuracy: 0.9999 - val_loss: 0.0444 - val_accuracy: 0.9882
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>Ok. The <code>mnist</code> classifier is back on its feet but now it can see in color. The model summary looks the same except the number of parameters for layer 1 have increased:</p> <pre><code>&gt; model.summary()

Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_6 (Conv2D)            (None, 26, 26, 120)       3360      
_________________________________________________________________
flatten_2 (Flatten)          (None, 81120)             0         
_________________________________________________________________
dense_6 (Dense)              (None, 480)               38938080  
_________________________________________________________________
dense_7 (Dense)              (None, 160)               76960     
_________________________________________________________________
dropout_2 (Dropout)          (None, 160)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 10)                1610      
=================================================================
Total params: 39,020,010
Trainable params: 39,020,010
Non-trainable params: 0
_________________________________________________________________
</code></pre> <p>Let's try fine tuning again, and this time, we'll learn the <em>first</em> and <em>last</em> layer (but not any intermediate layers):</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">mnist_eval_cb</span> <span class="o">=</span> <span class="n">CustomEvaluation</span><span class="p">(</span><span class="n">mnist_test</span><span class="p">,</span> <span class="s1">'mnist'</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cifar10_eval_cb</span> <span class="o">=</span> <span class="n">CustomEvaluation</span><span class="p">(</span><span class="n">cifar10_test</span><span class="p">,</span> <span class="s1">'cifar10'</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># only let the first and last layer learn</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">mnist_eval_cb</span><span class="p">,</span> <span class="n">cifar10_eval_cb</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'loss'</span><span class="p">,</span> <span class="s1">'cifar10_loss'</span><span class="p">,</span> <span class="s1">'mnist_acc'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="s1">'cifar10_acc'</span><span class="p">,</span> <span class="s1">'mnist_loss'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Epoch 1/10
1563/1563 - 7s - loss: 2.7930 - accuracy: 0.0993
mnist_loss: 2.23506 - mnist_acc: 0.27090
cifar10_loss: 2.30257 - cifar10_acc: 0.10010
Epoch 2/10
1563/1563 - 6s - loss: 2.3028 - accuracy: 0.0971
mnist_loss: 2.23064 - mnist_acc: 0.25680
cifar10_loss: 2.30257 - cifar10_acc: 0.10010
Epoch 3/10
1563/1563 - 6s - loss: 2.3030 - accuracy: 0.0968
mnist_loss: 2.22431 - mnist_acc: 0.29550
cifar10_loss: 2.30257 - cifar10_acc: 0.09990
Epoch 4/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0972
mnist_loss: 2.25326 - mnist_acc: 0.24510
cifar10_loss: 2.30258 - cifar10_acc: 0.10000
Epoch 5/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0971
mnist_loss: 2.26340 - mnist_acc: 0.24070
cifar10_loss: 2.30257 - cifar10_acc: 0.09990
Epoch 6/10
1563/1563 - 6s - loss: 2.3031 - accuracy: 0.0971
mnist_loss: 2.23891 - mnist_acc: 0.24970
cifar10_loss: 2.30259 - cifar10_acc: 0.09990
Epoch 7/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0973
mnist_loss: 2.26161 - mnist_acc: 0.22930
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 8/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0987
mnist_loss: 2.25460 - mnist_acc: 0.22980
cifar10_loss: 2.30259 - cifar10_acc: 0.10010
Epoch 9/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0972
mnist_loss: 2.24977 - mnist_acc: 0.23900
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 10/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0981
mnist_loss: 2.24748 - mnist_acc: 0.24250
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>It still looks like we'll have to train the whole model. You know the drill:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="c1"># unfreeze everything</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">mnist_eval_cb</span><span class="p">,</span> <span class="n">cifar10_eval_cb</span><span class="p">]</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'loss'</span><span class="p">,</span> <span class="s1">'cifar10_loss'</span><span class="p">,</span> <span class="s1">'mnist_acc'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="s1">'cifar10_acc'</span><span class="p">,</span> <span class="s1">'mnist_loss'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Epoch 1/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0981
mnist_loss: 2.25516 - mnist_acc: 0.23380
cifar10_loss: 2.30260 - cifar10_acc: 0.10020
Epoch 2/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0970
mnist_loss: 2.26369 - mnist_acc: 0.22390
cifar10_loss: 2.30261 - cifar10_acc: 0.10000
Epoch 3/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0944
mnist_loss: 2.24401 - mnist_acc: 0.24480
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 4/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0980
mnist_loss: 2.27201 - mnist_acc: 0.21970
cifar10_loss: 2.30258 - cifar10_acc: 0.09990
Epoch 5/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0979
mnist_loss: 2.27206 - mnist_acc: 0.22140
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 6/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0987
mnist_loss: 2.27167 - mnist_acc: 0.22160
cifar10_loss: 2.30259 - cifar10_acc: 0.10010
Epoch 7/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0978
mnist_loss: 2.27237 - mnist_acc: 0.22290
cifar10_loss: 2.30258 - cifar10_acc: 0.09990
Epoch 8/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0984
mnist_loss: 2.27085 - mnist_acc: 0.22390
cifar10_loss: 2.30259 - cifar10_acc: 0.10010
Epoch 9/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0977
mnist_loss: 2.27129 - mnist_acc: 0.22430
cifar10_loss: 2.30258 - cifar10_acc: 0.10010
Epoch 10/10
1563/1563 - 6s - loss: 2.3027 - accuracy: 0.0987
mnist_loss: 2.27180 - mnist_acc: 0.22000
cifar10_loss: 2.30259 - cifar10_acc: 0.10010
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>Still no improvement. Let's see if the hyperparameter tuner can help:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">kt</span><span class="o">.</span><span class="n">Hyperband</span><span class="p">(</span><span class="n">model_builder</span><span class="p">,</span>
                     <span class="n">objective</span><span class="o">=</span><span class="s1">'val_accuracy'</span><span class="p">,</span>
                     <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                     <span class="n">factor</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                     <span class="n">directory</span><span class="o">=</span><span class="s1">'cifar10'</span><span class="p">,</span>
                     <span class="n">project_name</span><span class="o">=</span><span class="s1">'intro_to_kt'</span><span class="p">)</span>
<span class="n">stop_early</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">'val_loss'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
             <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">stop_early</span><span class="p">])</span>

<span class="c1"># Get the optimal hyperparameters</span>
<span class="n">best_hps</span><span class="o">=</span><span class="n">tuner</span><span class="o">.</span><span class="n">get_best_hyperparameters</span><span class="p">(</span><span class="n">num_trials</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Hyperparameter search is complete. Best hyperparameters:'</span><span class="p">,</span> <span class="n">best_hps</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Trial 30 Complete [00h 01m 42s]
val_accuracy: 0.49459999799728394

Best val_accuracy So Far: 0.5548999905586243
Total elapsed time: 00h 19m 53s
INFO:tensorflow:Oracle triggered exit
Hyperparameter search is complete. Best hyperparameters: {'units': 480, 'units2': 480, 'conv_activation': 'tanh', 'dense_activation': 'tanh', 'num_conv_layers': 3, 'num_dense_layers': 1, 'dropout_factor': 0.0, 'optimizer': 'Adadelta', 'tuner/epochs': 10, 'tuner/initial_epoch': 4, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '7c00f5b4ad4a41a7e4469bf866adfe6d'}
</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>Still no improvement. Let's introduce some more <em>translation-invariance</em> priors. Math first, then code.</p> <p>Translation invariance refers to the fact that object representations may ideally be factored into separate part-object and object-scene representations where the former do not change as the object moves around the scene. (Side note: neuroscience commonly refers to the <em>dorsal</em> and <em>ventral</em> visual pathways as 'what and where' streams) A robust classifier should classify objects regardless of how they are framed within an image. To reach that lofty goal, machine learning researchers and engineers instill various translation invariant priors into their models. 2D convolution is an excellent example of a translation invariant operation. Others include:</p> <ul> <li>1x1 convolution (i.e.: a dense layer with weights shared applied on every pixel)</li> <li>MaxPooling</li> <li>MeanPooling</li> <li>GlobalMaxPooling</li> <li>Attention</li> <li>Normalization</li> </ul> <p>Networks like VGG, ResNet, and ViT also make extensive use of skip connections, highways, or residual connections. Basically those terms mean we're going to break out of the 'sequential' mode of thinking and build acyclic connection toplogies instead. There's too much to explain here but I have included seveal reference in the bottom of this notebook about the aforementioned topics. For now, we'll give our hyperparameter tuner the chance to explore all those priors.</p> <h3 id="The-Hyper-Resisudal-Attention-Network">The Hyper Resisudal Attention Network<a class="anchor-link" href="#The-Hyper-Resisudal-Attention-Network"></a></h3> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell jp-mod-noOutputs"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[1]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">IPython.display</span> <span class="k">as</span> <span class="nn">display</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras</span> <span class="k">as</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.layers</span> <span class="k">as</span> <span class="nn">tfkl</span>
<span class="kn">import</span> <span class="nn">tensorflow.keras.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>

<span class="o">!</span>pip install -q einops
<span class="kn">import</span> <span class="nn">einops</span>

<span class="o">!</span>pip install -q -U keras-tuner
<span class="kn">import</span> <span class="nn">keras_tuner</span> <span class="k">as</span> <span class="nn">kt</span>
</pre></div> </div> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[2]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="c1"># load data</span>
<span class="n">mnist_train</span><span class="p">,</span> <span class="n">mnist_test</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="n">cifar10_train</span><span class="p">,</span> <span class="n">cifar10_test</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">cifar10</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="n">mnist_train</span> <span class="o">=</span> <span class="n">mnist_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="n">mnist_train</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">mnist_test</span> <span class="o">=</span> <span class="n">mnist_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="n">mnist_test</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">cifar10_train</span> <span class="o">=</span> <span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">cifar10_test</span> <span class="o">=</span> <span class="n">cifar10_test</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span><span class="o">/</span><span class="mf">255.</span><span class="p">,</span> <span class="n">cifar10_test</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># insert and repeat 3 channels on greyscale mnist</span>
<span class="n">mnist_train</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">mnist_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">mnist_train</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">mnist_test</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">mnist_test</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="n">mnist_test</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># remove empty channel axis on cifar10</span>
<span class="n">cifar10_train</span> <span class="o">=</span> <span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">cifar10_test</span> <span class="o">=</span> <span class="n">cifar10_test</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cifar10_test</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

<span class="c1"># sanity check: make sure datasets are shaped similarly with different H's and W's</span>
<span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="p">[</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">mnist_test</span><span class="p">,</span> <span class="n">cifar10_train</span><span class="p">,</span> <span class="n">cifar10_test</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">ds</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>(60000, 28, 28, 3) (60000,)
(10000, 28, 28, 3) (10000,)
(50000, 32, 32, 3) (50000,)
(10000, 32, 32, 3) (10000,)
</pre> </div> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[16]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">hyper_resisudal_attention_model_builder</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    
    <span class="c1">### declare hyperparameters ###</span>

    <span class="c1"># input conv layer</span>
    <span class="n">hp_augment</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'augment'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>
    <span class="n">hp_conv_act_input</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_act_input'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">,</span> <span class="s1">'linear'</span><span class="p">,</span> <span class="s1">'sigmoid'</span><span class="p">])</span>

    <span class="c1"># residual depth</span>
    <span class="n">hp_res_units</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'res_units'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">hp_not_residual</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'not_residual'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">])</span>

    <span class="c1"># residual conv hparams</span>
    <span class="n">hp_conv_block_size</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_block_size'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
    <span class="n">hp_num_conv_blocks</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'num_conv_blocks'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="c1"># first layer</span>
    <span class="n">hp_conv_type0</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_type0'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'conv_1x1'</span><span class="p">,</span> <span class="s1">'conv_3x3'</span><span class="p">,</span> <span class="s1">'conv_5x5'</span><span class="p">,</span> <span class="s1">'conv_mixed'</span><span class="p">,</span> 
                                                    <span class="s1">'attention'</span><span class="p">])</span>
    <span class="n">hp_conv_units0</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'conv_units0'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">hp_conv_act0</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_act0'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">,</span> <span class="s1">'linear'</span><span class="p">,</span> <span class="s1">'sigmoid'</span><span class="p">])</span>
    <span class="c1"># second layer</span>
    <span class="n">hp_conv_type1</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_type1'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'conv_1x1'</span><span class="p">,</span> <span class="s1">'conv_3x3'</span><span class="p">,</span> <span class="s1">'conv_5x5'</span><span class="p">,</span> <span class="s1">'conv_mixed'</span><span class="p">,</span> 
                                                    <span class="s1">'max_pool'</span><span class="p">,</span> <span class="s1">'mean_pool'</span><span class="p">])</span>
    <span class="n">hp_conv_units1</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'conv_units1'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">hp_conv_act1</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_act1'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'linear'</span><span class="p">])</span>
    <span class="c1"># third layer</span>
    <span class="n">hp_conv_type2</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_type2'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'conv_1x1'</span><span class="p">,</span> <span class="s1">'conv_3x3'</span><span class="p">,</span> <span class="s1">'conv_5x5'</span><span class="p">,</span> <span class="s1">'conv_mixed'</span><span class="p">,</span> 
                                                    <span class="s1">'max_pool'</span><span class="p">,</span> <span class="s1">'mean_pool'</span><span class="p">])</span>
    <span class="n">hp_conv_units2</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'conv_units2'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">hp_conv_act2</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_act2'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'linear'</span><span class="p">])</span>
    <span class="c1"># forth layer</span>
    <span class="n">hp_conv_type3</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_type3'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'max_pool'</span><span class="p">,</span> <span class="s1">'mean_pool'</span><span class="p">])</span>
    <span class="n">hp_conv_units3</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'conv_units3'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">hp_conv_act3</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_act3'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'linear'</span><span class="p">])</span>
    <span class="c1"># final dense layer (1x1 conv)</span>
    <span class="n">hp_conv_act_final</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_act_final'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'linear'</span><span class="p">])</span>

    <span class="c1"># convert image shaped tensor to vector representation</span>
    <span class="n">hp_collapse_type</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'collapse_type'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'global_max_pool'</span><span class="p">,</span> <span class="s1">'global_mean_pool'</span><span class="p">,</span> <span class="s1">'flatten'</span><span class="p">])</span>

    <span class="c1"># residual dense hparams</span>
    <span class="n">hp_dense_block_size</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dense_block_size'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">hp_num_dense_blocks</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'num_dense_blocks'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

    <span class="n">hp_dense_units0</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'dense_units0'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">hp_dense_act0</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dense_act0'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">,</span> <span class="s1">'linear'</span><span class="p">,</span> <span class="s1">'sigmoid'</span><span class="p">])</span>
    <span class="n">hp_dense_units1</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'dense_units1'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">hp_dense_act1</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dense_act1'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'linear'</span><span class="p">])</span>
    <span class="n">hp_dense_units2</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'dense_units2'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">hp_dense_act2</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dense_act2'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'linear'</span><span class="p">])</span>
    <span class="n">hp_dense_units3</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'dense_units3'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">hp_dense_act3</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dense_act3'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'linear'</span><span class="p">])</span>
    <span class="n">hp_dense_act_final</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dense_act_final'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'linear'</span><span class="p">])</span>

    <span class="c1"># optimizer hparams</span>
    <span class="n">hp_optimizer</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'optimizer'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'SGD'</span><span class="p">,</span> <span class="s1">'Adam'</span><span class="p">])</span>
    <span class="n">hp_learning_rate</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'learning_rate'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0005</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.0025</span><span class="p">,</span> <span class="mf">0.005</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">])</span>
    
    <span class="k">if</span> <span class="n">hp_collapse_type</span> <span class="o">==</span> <span class="s1">'flatten'</span><span class="p">:</span>
        <span class="n">hp_not_residual</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1">### get helpers ready ###</span>

    <span class="c1"># activation functions</span>
    <span class="n">activations</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'sigmoid'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">,</span>
        <span class="s1">'relu'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
        <span class="s1">'tanh'</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span>
        <span class="s1">'linear'</span><span class="p">:</span> <span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">),</span>
    <span class="p">}</span>

    <span class="c1"># utility function for arbitrary image-tensor processing layers</span>
    <span class="k">def</span> <span class="nf">build_conv_layer</span><span class="p">(</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">layer_type</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s1">'conv_1x1'</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="s1">'same'</span><span class="p">,</span> 
                               <span class="n">activation</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">activation</span><span class="p">],</span>
                               <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">)(</span><span class="n">input_layer</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s1">'conv_3x3'</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="s1">'same'</span><span class="p">,</span> 
                               <span class="n">activation</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">activation</span><span class="p">],</span>
                               <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">)(</span><span class="n">input_layer</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s1">'conv_5x5'</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="s1">'same'</span><span class="p">,</span> 
                               <span class="n">activation</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">activation</span><span class="p">],</span>
                               <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">)(</span><span class="n">input_layer</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s1">'conv_mixed'</span><span class="p">:</span>
            <span class="c1"># not a precise implementation of vgg</span>
            <span class="n">conv1</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="s1">'same'</span><span class="p">,</span> 
                                <span class="n">activation</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">activation</span><span class="p">],</span>
                                <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">)(</span><span class="n">input_layer</span><span class="p">)</span>
            <span class="n">conv3</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="s1">'same'</span><span class="p">,</span> 
                                <span class="n">activation</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">activation</span><span class="p">],</span>
                                <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">)(</span><span class="n">input_layer</span><span class="p">)</span>
            <span class="n">conv5</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="s1">'same'</span><span class="p">,</span> 
                                <span class="n">activation</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">activation</span><span class="p">],</span>
                                <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">)(</span><span class="n">input_layer</span><span class="p">)</span>
            <span class="n">cat</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Maximum</span><span class="p">()([</span><span class="n">conv1</span><span class="p">,</span> <span class="n">conv3</span><span class="p">,</span> <span class="n">conv5</span><span class="p">])</span>
            <span class="k">return</span> <span class="n">cat</span>
        <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s1">'max_pool'</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">UpSampling2D</span><span class="p">()(</span><span class="n">tfkl</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">()(</span><span class="n">input_layer</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s1">'mean_pool'</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">UpSampling2D</span><span class="p">()(</span><span class="n">tfkl</span><span class="o">.</span><span class="n">AveragePooling2D</span><span class="p">()(</span><span class="n">input_layer</span><span class="p">))</span>
        <span class="k">elif</span> <span class="n">layer_type</span> <span class="o">==</span> <span class="s1">'attention'</span><span class="p">:</span>

            <span class="c1"># class Attn2D(tfkl.Layer):</span>
            <span class="c1">#     </span>
            <span class="c1">#     def __init__(self, patch_size=4, *args, **kwargs):</span>
            <span class="c1">#         super(Attn2D, self).__init__(*args, **kwargs)</span>
            <span class="c1">#         self.patch_size = patch_size</span>
            <span class="c1"># </span>
            <span class="c1">#     def build(self, input_shape):</span>
            <span class="c1">#         self.attn_layer = tfkl.MultiHeadAttention(num_heads=4, key_dim=units, attention_axes=(1,2))</span>
            <span class="c1">#         super(Attn2D, self).build(input_shape)</span>
            <span class="c1">#         print(input_shape)</span>
            <span class="c1">#         </span>
            <span class="c1">#     def call(self, inputs):</span>
            <span class="c1">#         x = inputs</span>
            <span class="c1">#         orig_shape = tf.shape(inputs)</span>
            <span class="c1">#         attn_shape = (orig_shape[0], </span>
            <span class="c1">#                       orig_shape[1]//self.patch_size, </span>
            <span class="c1">#                       orig_shape[2]//self.patch_size,</span>
            <span class="c1">#                       4*orig_shape[3])</span>
            <span class="c1">#         x = tf.reshape(inputs, attn_shape)</span>
            <span class="c1">#         x = self.attn_layer(x, x)</span>
            <span class="c1">#         x = tf.reshape(x, orig_shape)</span>
            <span class="c1"># attended = Attn2D(patch_size=4)(input_layer)</span>

            <span class="c1"># @tf.function</span>
            <span class="c1"># def upscale(x):</span>
            <span class="c1">#     tf.print('before', x.shape)</span>
            <span class="c1">#     x = einops.repeat(attended, f'b h w c -&gt; b (h Hrepeat) (w Wrepeat) c', </span>
            <span class="c1">#                       Hrepeat=attn_block_len, Wrepeat=attn_block_len)</span>
            <span class="c1">#     tf.print('after', x.shape)</span>
            <span class="c1">#     return x</span>
            <span class="c1"># upscaled = tfkl.Lambda(upscale)(attended)</span>

            <span class="c1"># upscaled = einops.repeat(attended, f'b h w c -&gt; b (h repeat) (w repeat) c', repeat=attn_block_len)</span>

            <span class="n">attn_block_len</span> <span class="o">=</span> <span class="mi">4</span>
            <span class="n">downscaled</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">AveragePooling2D</span><span class="p">((</span><span class="n">attn_block_len</span><span class="p">,</span> <span class="n">attn_block_len</span><span class="p">))(</span><span class="n">input_layer</span><span class="p">)</span>
            <span class="n">attended</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">MultiHeadAttention</span><span class="p">(</span><span class="n">num_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">key_dim</span><span class="o">=</span><span class="n">units</span><span class="p">,</span> <span class="n">attention_axes</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> \
                            <span class="p">(</span><span class="n">downscaled</span><span class="p">,</span> <span class="n">downscaled</span><span class="p">,</span> <span class="n">return_attention_scores</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># [B, H/s, W/s, N]</span>
            <span class="n">upscaled</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">UpSampling2D</span><span class="p">((</span><span class="n">attn_block_len</span><span class="p">,</span> <span class="n">attn_block_len</span><span class="p">))(</span><span class="n">attended</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">upscaled</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Layer type </span><span class="si">{</span><span class="n">layer_type</span><span class="si">}</span><span class="s1"> not supported'</span><span class="p">)</span>

    <span class="c1"># layers which turn [B, H, W, hp_res_units] into [B, hp_res_units]</span>
    <span class="n">collapse_layers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'global_max_pool'</span><span class="p">:</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">GlobalMaxPool2D</span><span class="p">(),</span>
        <span class="s1">'global_mean_pool'</span><span class="p">:</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">GlobalAveragePooling2D</span><span class="p">(),</span>
        <span class="s1">'flatten'</span><span class="p">:</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="p">}</span>

    <span class="n">optimizers</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">'SGD'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span>
        <span class="s1">'RMSProp'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">RMSprop</span><span class="p">,</span>
        <span class="s1">'Adam'</span><span class="p">:</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="k">def</span> <span class="nf">Tagger</span><span class="p">(</span><span class="n">tag</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">lambda_log</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="n">tag</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span><span class="n">lambda_log</span><span class="p">)</span>

    <span class="c1">### build model ###</span>

    <span class="n">any_input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>  <span class="c1"># accept input for arbitrarily sized images</span>
    <span class="n">fixed_input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>  <span class="c1"># sadly the flatten layer outperforms globalmaxpooling</span>

    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">fixed_input_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">hp_augment</span><span class="p">:</span>
        <span class="n">preprocessed</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
            <span class="n">tfkl</span><span class="o">.</span><span class="n">RandomTranslation</span><span class="p">(</span>
                <span class="n">height_factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
                <span class="n">width_factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">tfkl</span><span class="o">.</span><span class="n">RandomZoom</span><span class="p">(</span>
                <span class="n">height_factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
                <span class="n">width_factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">tfkl</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
            <span class="n">tfkl</span><span class="o">.</span><span class="n">RandomFlip</span><span class="p">(),</span>
        <span class="p">])(</span><span class="n">input_layer</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">preprocessed</span> <span class="o">=</span> <span class="n">input_layer</span>

    <span class="c1"># start 2D residual stream</span>
    <span class="n">res_stream</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">hp_res_units</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="s1">'same'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                             <span class="n">activation</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">hp_conv_act_input</span><span class="p">],</span>
                             <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">)(</span><span class="n">preprocessed</span><span class="p">)</span>

    <span class="c1"># make residual processing blocks</span>
    <span class="k">if</span> <span class="n">hp_conv_block_size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">hp_num_conv_blocks</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">block_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hp_num_conv_blocks</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="sa">f</span><span class="s1">'conv_block</span><span class="si">{</span><span class="n">block_num</span><span class="si">}</span><span class="s1">'</span><span class="p">):</span>
                <span class="c1"># normalize the input to handle deep residual networks</span>
                <span class="n">block_stream</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">()(</span><span class="n">res_stream</span><span class="p">)</span>
                <span class="c1"># include `hp_conv_block_size` number of layers with their own hyperparameters </span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer_type</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">activation</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">hp_conv_block_size</span><span class="p">)),</span>
                    <span class="p">[</span><span class="n">hp_conv_type0</span><span class="p">,</span> <span class="n">hp_conv_type1</span><span class="p">,</span> <span class="n">hp_conv_type2</span><span class="p">,</span> <span class="n">hp_conv_type3</span><span class="p">],</span>
                    <span class="p">[</span><span class="n">hp_conv_units0</span><span class="p">,</span> <span class="n">hp_conv_units1</span><span class="p">,</span> <span class="n">hp_conv_units2</span><span class="p">,</span> <span class="n">hp_conv_units3</span><span class="p">],</span>
                    <span class="p">[</span><span class="n">hp_conv_act0</span><span class="p">,</span> <span class="n">hp_conv_act1</span><span class="p">,</span> <span class="n">hp_conv_act2</span><span class="p">,</span> <span class="n">hp_conv_act3</span><span class="p">],</span>
                <span class="p">):</span>
                    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="sa">f</span><span class="s1">'layer</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">'</span><span class="p">):</span>
                        <span class="n">block_stream</span> <span class="o">=</span> <span class="n">build_conv_layer</span><span class="p">(</span><span class="n">block_stream</span><span class="p">,</span> <span class="n">layer_type</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="p">)</span>
                
                <span class="c1"># shortcircuit</span>
                <span class="k">if</span> <span class="n">hp_not_residual</span><span class="p">:</span>
                    <span class="n">res_stream</span> <span class="o">=</span> <span class="n">block_stream</span>
                    <span class="k">continue</span>

                <span class="c1"># fuse internal block stream into main residual stream</span>
                <span class="n">block_stream</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">hp_res_units</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="s1">'same'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                           <span class="n">activation</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">hp_conv_act_final</span><span class="p">],</span>
                                           <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">)(</span><span class="n">block_stream</span><span class="p">)</span>
                <span class="n">res_stream</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Add</span><span class="p">()([</span><span class="n">res_stream</span><span class="p">,</span> <span class="n">block_stream</span><span class="p">])</span>
                <span class="n">res_stream</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">))(</span><span class="n">res_stream</span><span class="p">)</span>

                <span class="c1"># boost residual depth with each block</span>
                <span class="n">hp_res_units</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">hp_res_units</span>  
                <span class="n">res_stream</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">hp_res_units</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="s1">'same'</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                         <span class="n">activation</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">hp_conv_act_final</span><span class="p">],</span>
                                         <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">'he_uniform'</span><span class="p">)(</span><span class="n">res_stream</span><span class="p">)</span>

    
    <span class="c1"># collapse 2D residual stream into a vector</span>
    <span class="n">res_stream</span> <span class="o">=</span> <span class="n">collapse_layers</span><span class="p">[</span><span class="n">hp_collapse_type</span><span class="p">](</span><span class="n">res_stream</span><span class="p">)</span>  <span class="c1"># [B, H, W, C] -&gt; [B, hp_res_units]</span>

    <span class="c1"># make residual processing blocks</span>
    <span class="k">if</span> <span class="n">hp_dense_block_size</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">hp_num_dense_blocks</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">block_num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hp_num_dense_blocks</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="sa">f</span><span class="s1">'dense_block</span><span class="si">{</span><span class="n">block_num</span><span class="si">}</span><span class="s1">'</span><span class="p">):</span>
                <span class="c1"># normalize the input to handle deep residual networks</span>
                <span class="nb">print</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">res_stream</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">block_stream</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">LayerNormalization</span><span class="p">()(</span><span class="n">res_stream</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">block_stream</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="c1"># include `hp_conv_block_size` number of layers with their own hyperparameters </span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">units</span><span class="p">,</span> <span class="n">activation</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                    <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">hp_conv_block_size</span><span class="p">)),</span>
                    <span class="p">[</span><span class="n">hp_dense_units0</span><span class="p">,</span> <span class="n">hp_dense_units1</span><span class="p">,</span> <span class="n">hp_dense_units2</span><span class="p">,</span> <span class="n">hp_dense_units3</span><span class="p">],</span>
                    <span class="p">[</span><span class="n">hp_dense_act0</span><span class="p">,</span> <span class="n">hp_dense_act1</span><span class="p">,</span> <span class="n">hp_dense_act2</span><span class="p">,</span> <span class="n">hp_dense_act3</span><span class="p">],</span>
                <span class="p">):</span>
                    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="sa">f</span><span class="s1">'layer</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">'</span><span class="p">):</span>
                        <span class="n">block_stream</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">activation</span><span class="p">])(</span><span class="n">block_stream</span><span class="p">)</span>

                <span class="c1"># shortcircuit</span>
                <span class="k">if</span> <span class="n">hp_not_residual</span><span class="p">:</span>
                    <span class="n">res_stream</span> <span class="o">=</span> <span class="n">block_stream</span>
                    <span class="k">continue</span>

                <span class="c1"># fuse internal block stream into main residual stream</span>
                <span class="n">block_stream</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp_res_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activations</span><span class="p">[</span><span class="n">hp_dense_act_final</span><span class="p">])(</span><span class="n">block_stream</span><span class="p">)</span>
                <span class="n">res_stream</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Add</span><span class="p">()([</span><span class="n">res_stream</span><span class="p">,</span> <span class="n">block_stream</span><span class="p">])</span>

    <span class="c1"># make linear classifier</span>
    <span class="n">classified</span> <span class="o">=</span> <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">)(</span><span class="n">res_stream</span><span class="p">)</span>

    <span class="c1"># build optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizers</span><span class="p">[</span><span class="n">hp_optimizer</span><span class="p">](</span><span class="n">hp_learning_rate</span><span class="p">)</span>

    <span class="c1"># make, compile, amd return model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">input_layer</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">classified</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span> 
                  <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">,</span> 
                           <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseTopKCategoricalAccuracy</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'top-5-accuracy'</span><span class="p">),</span>
                           <span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseTopKCategoricalAccuracy</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'top-2-accuracy'</span><span class="p">)</span>
                           <span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="c1"># test with arbitrary hyperparameters</span>
<span class="n">hparams</span> <span class="o">=</span> <span class="n">kt</span><span class="o">.</span><span class="n">HyperParameters</span><span class="p">()</span>
<span class="n">hparams</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'augment'</span><span class="p">:</span> <span class="kc">False</span><span class="p">,</span>
    <span class="s1">'conv_act_input'</span><span class="p">:</span> <span class="s1">'relu'</span><span class="p">,</span> 
    <span class="s1">'res_units'</span><span class="p">:</span> <span class="mi">40</span><span class="p">,</span>
    <span class="s1">'not_residual'</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s1">'conv_block_size'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s1">'num_conv_blocks'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">'conv_type0'</span><span class="p">:</span> <span class="s1">'conv_3x3'</span><span class="p">,</span>
    <span class="s1">'conv_units0'</span><span class="p">:</span> <span class="mi">40</span><span class="p">,</span>
    <span class="s1">'conv_act0'</span><span class="p">:</span> <span class="s1">'relu'</span><span class="p">,</span>
    <span class="s1">'conv_type1'</span><span class="p">:</span> <span class="s1">'max_pool'</span><span class="p">,</span>
    <span class="s1">'conv_units1'</span><span class="p">:</span> <span class="mi">40</span><span class="p">,</span>
    <span class="s1">'conv_act1'</span><span class="p">:</span> <span class="s1">'relu'</span><span class="p">,</span>
    <span class="s1">'conv_type2'</span><span class="p">:</span> <span class="s1">'max_pool'</span><span class="p">,</span>
    <span class="s1">'conv_units2'</span><span class="p">:</span> <span class="mi">40</span><span class="p">,</span>
    <span class="s1">'conv_act2'</span><span class="p">:</span> <span class="s1">'relu'</span><span class="p">,</span>
    <span class="s1">'conv_type3'</span><span class="p">:</span> <span class="s1">'max_pool'</span><span class="p">,</span>
    <span class="s1">'conv_units3'</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="s1">'conv_act3'</span><span class="p">:</span> <span class="s1">'relu'</span><span class="p">,</span>
    <span class="s1">'conv_act_final'</span><span class="p">:</span> <span class="s1">'relu'</span><span class="p">,</span>
    <span class="s1">'collapse_type'</span><span class="p">:</span> <span class="s1">'flatten'</span><span class="p">,</span>
    <span class="s1">'dense_block_size'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">'num_dense_blocks'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">'dense_units1'</span><span class="p">:</span> <span class="mi">128</span><span class="p">,</span>
    <span class="s1">'dense_act1'</span><span class="p">:</span> <span class="s1">'sigmoid'</span><span class="p">,</span>
    <span class="s1">'dense_units2'</span><span class="p">:</span> <span class="mi">256</span><span class="p">,</span>
    <span class="s1">'dense_act2'</span><span class="p">:</span> <span class="s1">'relu'</span><span class="p">,</span>
    <span class="s1">'dense_units3'</span><span class="p">:</span> <span class="mi">64</span><span class="p">,</span>
    <span class="s1">'dense_act3'</span><span class="p">:</span> <span class="s1">'linear'</span><span class="p">,</span>
    <span class="s1">'dense_act_final'</span><span class="p">:</span> <span class="s1">'relu'</span><span class="p">,</span>
    <span class="s1">'optimizer'</span><span class="p">:</span> <span class="s1">'SGD'</span><span class="p">,</span>
    <span class="s1">'learning_rate'</span><span class="p">:</span> <span class="mf">0.001</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">hyper_resisudal_attention_model_builder</span><span class="p">(</span><span class="n">hparams</span><span class="p">)</span>
<span class="c1">#model.summary(128)</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># visualize training</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'loss'</span><span class="p">,</span> <span class="s1">'val_loss'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="s1">'val_accuracy'</span><span class="p">,</span> 
                               <span class="s1">'top-2-accuracy'</span><span class="p">,</span> <span class="s1">'val_top-2-accuracy'</span><span class="p">,</span>
                               <span class="s1">'top-5-accuracy'</span><span class="p">,</span> <span class="s1">'val_top-5-accuracy'</span>  <span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1">#keras.utils.plot_model(model)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>1 (None, 40960)
2 (None, 40960)
Epoch 1/3
704/704 [==============================] - 5s 7ms/step - loss: 6.7000 - accuracy: 0.1003 - top-5-accuracy: 0.6132 - top-2-accuracy: 0.2427 - val_loss: 6.4022 - val_accuracy: 0.0970 - val_top-5-accuracy: 0.6470 - val_top-2-accuracy: 0.3164
Epoch 2/3
704/704 [==============================] - 5s 7ms/step - loss: 6.7141 - accuracy: 0.0977 - top-5-accuracy: 0.5434 - top-2-accuracy: 0.2246 - val_loss: 6.7187 - val_accuracy: 0.1058 - val_top-5-accuracy: 0.5118 - val_top-2-accuracy: 0.2096
Epoch 3/3
704/704 [==============================] - 5s 7ms/step - loss: 5.8834 - accuracy: 0.0994 - top-5-accuracy: 0.4992 - top-2-accuracy: 0.1989 - val_loss: 5.2743 - val_accuracy: 0.1058 - val_top-5-accuracy: 0.5124 - val_top-2-accuracy: 0.2096
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>After some manual experiments (none surpass 0.2 accuracy) I tried throwing the model on the hyperparameter optimizer. The results were not any better.</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">tuner</span> <span class="o">=</span> <span class="n">kt</span><span class="o">.</span><span class="n">Hyperband</span><span class="p">(</span><span class="n">hyper_resisudal_attention_model_builder</span><span class="p">,</span>
                     <span class="n">objective</span><span class="o">=</span><span class="s1">'val_accuracy'</span><span class="p">,</span>
                     <span class="n">max_epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                     <span class="n">factor</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                     <span class="n">directory</span><span class="o">=</span><span class="s1">'hyper_resisudal_attention_model-1'</span><span class="p">,</span>
                     <span class="n">project_name</span><span class="o">=</span><span class="s1">'hyper_resisudal_attention_model-1'</span><span class="p">)</span>
<span class="n">stop_early</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">'val_loss'</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> 
             <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">stop_early</span><span class="p">])</span>

<span class="c1"># Get the optimal hyperparameters</span>
<span class="n">best_hps</span><span class="o">=</span><span class="n">tuner</span><span class="o">.</span><span class="n">get_best_hyperparameters</span><span class="p">(</span><span class="n">num_trials</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Hyperparameter search is complete. Best hyperparameters:'</span><span class="p">,</span> <span class="n">best_hps</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Trial 3 Complete [00h 00m 33s]
val_accuracy: 0.11219999939203262

Best val_accuracy So Far: 0.1282999962568283
Total elapsed time: 00h 02m 08s

Search: Running Trial #4

Hyperparameter    |Value             |Best Value So Far 
conv_act_input    |linear            |sigmoid           
res_units         |32                |48                
conv_block_size   |1                 |3                 
num_conv_blocks   |1                 |2                 
conv_type0        |conv_1x1          |conv_1x1          
conv_units0       |24                |24                
conv_act0         |sigmoid           |sigmoid           
conv_type1        |max_pool          |conv_3x3          
conv_units1       |8                 |8                 
conv_act1         |tanh              |linear            
conv_type2        |max_pool          |conv_1x1          
conv_units2       |8                 |24                
conv_act2         |linear            |linear            
conv_type3        |conv_1x1          |conv_mixed        
conv_units3       |24                |24                
conv_act3         |relu              |tanh              
conv_act_final    |linear            |tanh              
collapse_type     |global_max_pool   |global_mean_pool  
dense_block_size  |3                 |3                 
num_dense_blocks  |5                 |4                 
dense_units0      |472               |408               
dense_act0        |sigmoid           |tanh              
dense_units1      |408               |168               
dense_act1        |relu              |linear            
dense_units2      |56                |456               
dense_act2        |linear            |tanh              
dense_units3      |40                |360               
dense_act3        |relu              |tanh              
dense_act_final   |relu              |relu              
optimizer         |RMSProp           |SGD               
learning_rate     |0.0025            |0.0025            
tuner/epochs      |4                 |2                 
tuner/initial_e...|2                 |0                 
tuner/bracket     |2                 |2                 
tuner/round       |1                 |0                 
tuner/trial_id    |29d19f098949c88...|None              

</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py", line 127, in build
    model = self.hypermodel.build(hp)
  File "&lt;ipython-input-214-aa31e6d19965&gt;", line 6, in hyper_resisudal_attention_model_builder
    hp_augment = hp.Choice('augment', values=[True, False])
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 798, in Choice
    return self._retrieve(hp)
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 707, in _retrieve
    return self.values[hp.name]
KeyError: 'augment'
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Invalid model 0/5
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py", line 127, in build
    model = self.hypermodel.build(hp)
  File "&lt;ipython-input-214-aa31e6d19965&gt;", line 6, in hyper_resisudal_attention_model_builder
    hp_augment = hp.Choice('augment', values=[True, False])
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 798, in Choice
    return self._retrieve(hp)
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 707, in _retrieve
    return self.values[hp.name]
KeyError: 'augment'
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Invalid model 1/5
Invalid model 2/5
Invalid model 3/5
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py", line 127, in build
    model = self.hypermodel.build(hp)
  File "&lt;ipython-input-214-aa31e6d19965&gt;", line 6, in hyper_resisudal_attention_model_builder
    hp_augment = hp.Choice('augment', values=[True, False])
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 798, in Choice
    return self._retrieve(hp)
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 707, in _retrieve
    return self.values[hp.name]
KeyError: 'augment'
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py", line 127, in build
    model = self.hypermodel.build(hp)
  File "&lt;ipython-input-214-aa31e6d19965&gt;", line 6, in hyper_resisudal_attention_model_builder
    hp_augment = hp.Choice('augment', values=[True, False])
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 798, in Choice
    return self._retrieve(hp)
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 707, in _retrieve
    return self.values[hp.name]
KeyError: 'augment'
Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py", line 127, in build
    model = self.hypermodel.build(hp)
  File "&lt;ipython-input-214-aa31e6d19965&gt;", line 6, in hyper_resisudal_attention_model_builder
    hp_augment = hp.Choice('augment', values=[True, False])
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 798, in Choice
    return self._retrieve(hp)
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 707, in _retrieve
    return self.values[hp.name]
KeyError: 'augment'
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Invalid model 4/5
Invalid model 5/5
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py", line 127, in build
    model = self.hypermodel.build(hp)
  File "&lt;ipython-input-214-aa31e6d19965&gt;", line 6, in hyper_resisudal_attention_model_builder
    hp_augment = hp.Choice('augment', values=[True, False])
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 798, in Choice
    return self._retrieve(hp)
  File "/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py", line 707, in _retrieve
    return self.values[hp.name]
KeyError: 'augment'
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyError</span>                                  Traceback (most recent call last)
<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py</span> in <span class="ansi-cyan-fg">build</span><span class="ansi-blue-fg">(self, hp)</span>
<span class="ansi-green-intense-fg ansi-bold">    126</span>                 <span class="ansi-green-fg">with</span> maybe_distribute<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>distribution_strategy<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 127</span><span class="ansi-red-fg">                     </span>model <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>hypermodel<span class="ansi-blue-fg">.</span>build<span class="ansi-blue-fg">(</span>hp<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    128</span>             <span class="ansi-green-fg">except</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">&lt;ipython-input-214-aa31e6d19965&gt;</span> in <span class="ansi-cyan-fg">hyper_resisudal_attention_model_builder</span><span class="ansi-blue-fg">(hp)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>     <span class="ansi-red-fg"># input conv layer</span>
<span class="ansi-green-fg">----&gt; 6</span><span class="ansi-red-fg">     </span>hp_augment <span class="ansi-blue-fg">=</span> hp<span class="ansi-blue-fg">.</span>Choice<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">'augment'</span><span class="ansi-blue-fg">,</span> values<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">[</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span> <span class="ansi-green-fg">False</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span>     hp_conv_act_input <span class="ansi-blue-fg">=</span> hp<span class="ansi-blue-fg">.</span>Choice<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">'conv_act_input'</span><span class="ansi-blue-fg">,</span> values<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">'relu'</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">'tanh'</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">'linear'</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">'sigmoid'</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py</span> in <span class="ansi-cyan-fg">Choice</span><span class="ansi-blue-fg">(self, name, values, ordered, default, parent_name, parent_values)</span>
<span class="ansi-green-intense-fg ansi-bold">    797</span>             )
<span class="ansi-green-fg">--&gt; 798</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_retrieve<span class="ansi-blue-fg">(</span>hp<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    799</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hyperparameters.py</span> in <span class="ansi-cyan-fg">_retrieve</span><span class="ansi-blue-fg">(self, hp)</span>
<span class="ansi-green-intense-fg ansi-bold">    706</span>             <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_conditions_are_active<span class="ansi-blue-fg">(</span>hp<span class="ansi-blue-fg">.</span>conditions<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 707</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">[</span>hp<span class="ansi-blue-fg">.</span>name<span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">    708</span>             <span class="ansi-green-fg">return</span> <span class="ansi-green-fg">None</span>  <span class="ansi-red-fg"># Ensures inactive values are not relied on by user.</span>

<span class="ansi-red-fg">KeyError</span>: 'augment'

During handling of the above exception, another exception occurred:

<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-215-ce793d92a41c&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      7</span> stop_early <span class="ansi-blue-fg">=</span> tf<span class="ansi-blue-fg">.</span>keras<span class="ansi-blue-fg">.</span>callbacks<span class="ansi-blue-fg">.</span>EarlyStopping<span class="ansi-blue-fg">(</span>monitor<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">'val_loss'</span><span class="ansi-blue-fg">,</span> patience<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">5</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      8</span> tuner.search(cifar10_train[0], cifar10_train[1], epochs=50, 
<span class="ansi-green-fg">----&gt; 9</span><span class="ansi-red-fg">              validation_split=0.2, callbacks=[stop_early])
</span><span class="ansi-green-intense-fg ansi-bold">     10</span> 
<span class="ansi-green-intense-fg ansi-bold">     11</span> <span class="ansi-red-fg"># Get the optimal hyperparameters</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py</span> in <span class="ansi-cyan-fg">search</span><span class="ansi-blue-fg">(self, *fit_args, **fit_kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    174</span> 
<span class="ansi-green-intense-fg ansi-bold">    175</span>             self<span class="ansi-blue-fg">.</span>on_trial_begin<span class="ansi-blue-fg">(</span>trial<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 176</span><span class="ansi-red-fg">             </span>self<span class="ansi-blue-fg">.</span>run_trial<span class="ansi-blue-fg">(</span>trial<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>fit_args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>fit_kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    177</span>             self<span class="ansi-blue-fg">.</span>on_trial_end<span class="ansi-blue-fg">(</span>trial<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    178</span>         self<span class="ansi-blue-fg">.</span>on_search_end<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras_tuner/tuners/hyperband.py</span> in <span class="ansi-cyan-fg">run_trial</span><span class="ansi-blue-fg">(self, trial, *fit_args, **fit_kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    368</span>             fit_kwargs<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">"epochs"</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> hp<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">"tuner/epochs"</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">    369</span>             fit_kwargs<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">"initial_epoch"</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> hp<span class="ansi-blue-fg">.</span>values<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">"tuner/initial_epoch"</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-fg">--&gt; 370</span><span class="ansi-red-fg">         </span>super<span class="ansi-blue-fg">(</span>Hyperband<span class="ansi-blue-fg">,</span> self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>run_trial<span class="ansi-blue-fg">(</span>trial<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>fit_args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>fit_kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    371</span> 
<span class="ansi-green-intense-fg ansi-bold">    372</span>     <span class="ansi-green-fg">def</span> _build_model<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> hp<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/multi_execution_tuner.py</span> in <span class="ansi-cyan-fg">run_trial</span><span class="ansi-blue-fg">(self, trial, *fit_args, **fit_kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     88</span>             copied_fit_kwargs<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">"callbacks"</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> callbacks
<span class="ansi-green-intense-fg ansi-bold">     89</span> 
<span class="ansi-green-fg">---&gt; 90</span><span class="ansi-red-fg">             </span>history <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_build_and_fit_model<span class="ansi-blue-fg">(</span>trial<span class="ansi-blue-fg">,</span> fit_args<span class="ansi-blue-fg">,</span> copied_fit_kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     91</span>             <span class="ansi-green-fg">for</span> metric<span class="ansi-blue-fg">,</span> epoch_values <span class="ansi-green-fg">in</span> history<span class="ansi-blue-fg">.</span>history<span class="ansi-blue-fg">.</span>items<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     92</span>                 <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>oracle<span class="ansi-blue-fg">.</span>objective<span class="ansi-blue-fg">.</span>direction <span class="ansi-blue-fg">==</span> <span class="ansi-blue-fg">"min"</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py</span> in <span class="ansi-cyan-fg">_build_and_fit_model</span><span class="ansi-blue-fg">(self, trial, fit_args, fit_kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    146</span>             The fit history<span class="ansi-blue-fg">.</span>
<span class="ansi-green-intense-fg ansi-bold">    147</span>         """
<span class="ansi-green-fg">--&gt; 148</span><span class="ansi-red-fg">         </span>model <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>hypermodel<span class="ansi-blue-fg">.</span>build<span class="ansi-blue-fg">(</span>trial<span class="ansi-blue-fg">.</span>hyperparameters<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    149</span>         <span class="ansi-green-fg">return</span> model<span class="ansi-blue-fg">.</span>fit<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>fit_args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>fit_kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    150</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py</span> in <span class="ansi-cyan-fg">_build_wrapper</span><span class="ansi-blue-fg">(self, hp, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     82</span>             <span class="ansi-red-fg"># to the search space.</span>
<span class="ansi-green-intense-fg ansi-bold">     83</span>             hp <span class="ansi-blue-fg">=</span> hp<span class="ansi-blue-fg">.</span>copy<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 84</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_build<span class="ansi-blue-fg">(</span>hp<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     85</span> 
<span class="ansi-green-intense-fg ansi-bold">     86</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py</span> in <span class="ansi-cyan-fg">build</span><span class="ansi-blue-fg">(self, hp)</span>
<span class="ansi-green-intense-fg ansi-bold">    133</span> 
<span class="ansi-green-intense-fg ansi-bold">    134</span>                 <span class="ansi-green-fg">if</span> i <span class="ansi-blue-fg">==</span> self<span class="ansi-blue-fg">.</span>_max_fail_streak<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 135</span><span class="ansi-red-fg">                     </span><span class="ansi-green-fg">raise</span> RuntimeError<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">"Too many failed attempts to build model."</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    136</span>                 <span class="ansi-green-fg">continue</span>
<span class="ansi-green-intense-fg ansi-bold">    137</span> 

<span class="ansi-red-fg">RuntimeError</span>: Too many failed attempts to build model.</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>It may be time to back out of this search track and fall back on the older model. I'm gonig to run it with a little more training and call that final:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[18]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_builder</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    
    <span class="n">hp_units</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'units'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">hp_units2</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'units2'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">hp_conv_activation</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_activation'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">])</span>
    <span class="n">hp_dense_activation</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dense_activation'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">])</span>
    <span class="n">hp_num_conv_layers</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'num_conv_layers'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hp_num_dense_layers</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'num_dense_layers'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hp_dropout_factor</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dropout_factor'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
    <span class="n">hp_optimizer</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'optimizer'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'SGD'</span><span class="p">,</span> <span class="s1">'Adam'</span><span class="p">,</span> <span class="s1">'Adadelta'</span><span class="p">])</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">1</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">3</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_dense_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">)</span>
    <span class="p">])</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span> 
                  <span class="n">optimizer</span><span class="o">=</span><span class="n">hp_optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">best_hps</span> <span class="o">=</span> <span class="n">kt</span><span class="o">.</span><span class="n">HyperParameters</span><span class="p">()</span>
<span class="n">best_hps</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'units'</span><span class="p">:</span> <span class="mi">480</span><span class="p">,</span> 
    <span class="s1">'units2'</span><span class="p">:</span> <span class="mi">480</span><span class="p">,</span> 
    <span class="s1">'conv_activation'</span><span class="p">:</span> <span class="s1">'tanh'</span><span class="p">,</span> 
    <span class="s1">'dense_activation'</span><span class="p">:</span> <span class="s1">'tanh'</span><span class="p">,</span>
    <span class="s1">'optimizer'</span><span class="p">:</span> <span class="s1">'Adadelta'</span><span class="p">,</span>
<span class="p">}</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">model_builder</span><span class="p">(</span><span class="n">best_hps</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">cifar10_test</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'loss'</span><span class="p">,</span> <span class="s1">'val_loss'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="s1">'val_accuracy'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Epoch 1/50
782/782 [==============================] - 16s 20ms/step - loss: 1.7817 - accuracy: 0.3760 - val_loss: 1.6082 - val_accuracy: 0.4456
Epoch 2/50
782/782 [==============================] - 15s 20ms/step - loss: 1.5368 - accuracy: 0.4723 - val_loss: 1.4981 - val_accuracy: 0.4827
Epoch 3/50
782/782 [==============================] - 15s 20ms/step - loss: 1.4296 - accuracy: 0.5137 - val_loss: 1.4211 - val_accuracy: 0.5062
Epoch 4/50
782/782 [==============================] - 16s 20ms/step - loss: 1.3418 - accuracy: 0.5455 - val_loss: 1.3625 - val_accuracy: 0.5282
Epoch 5/50
782/782 [==============================] - 15s 20ms/step - loss: 1.2695 - accuracy: 0.5748 - val_loss: 1.3039 - val_accuracy: 0.5524
Epoch 6/50
782/782 [==============================] - 15s 20ms/step - loss: 1.2059 - accuracy: 0.5953 - val_loss: 1.2565 - val_accuracy: 0.5671
Epoch 7/50
782/782 [==============================] - 15s 20ms/step - loss: 1.1523 - accuracy: 0.6147 - val_loss: 1.2173 - val_accuracy: 0.5795
Epoch 8/50
782/782 [==============================] - 16s 20ms/step - loss: 1.1067 - accuracy: 0.6332 - val_loss: 1.1889 - val_accuracy: 0.5882
Epoch 9/50
782/782 [==============================] - 16s 20ms/step - loss: 1.0673 - accuracy: 0.6456 - val_loss: 1.1591 - val_accuracy: 0.6015
Epoch 10/50
782/782 [==============================] - 15s 20ms/step - loss: 1.0296 - accuracy: 0.6598 - val_loss: 1.1365 - val_accuracy: 0.6074
Epoch 11/50
782/782 [==============================] - 16s 20ms/step - loss: 0.9985 - accuracy: 0.6713 - val_loss: 1.1185 - val_accuracy: 0.6140
Epoch 12/50
782/782 [==============================] - 15s 20ms/step - loss: 0.9713 - accuracy: 0.6800 - val_loss: 1.0963 - val_accuracy: 0.6204
Epoch 13/50
782/782 [==============================] - 15s 20ms/step - loss: 0.9424 - accuracy: 0.6936 - val_loss: 1.0849 - val_accuracy: 0.6206
Epoch 14/50
782/782 [==============================] - 15s 20ms/step - loss: 0.9197 - accuracy: 0.7005 - val_loss: 1.0683 - val_accuracy: 0.6316
Epoch 15/50
781/782 [============================&gt;.] - ETA: 0s - loss: 0.8968 - accuracy: 0.7096</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="application/vnd.jupyter.stderr" tabindex="0"> <pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-18-1bcff8f4ef3c&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     45</span>     verbose<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     46</span>     validation_data<span class="ansi-blue-fg">=</span>cifar10_test<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">---&gt; 47</span><span class="ansi-red-fg">     </span>validation_batch_size<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">64</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     48</span> )
<span class="ansi-green-intense-fg ansi-bold">     49</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras/engine/training.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="ansi-green-intense-fg ansi-bold">   1224</span>               use_multiprocessing<span class="ansi-blue-fg">=</span>use_multiprocessing<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">   1225</span>               return_dict<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">-&gt; 1226</span><span class="ansi-red-fg">               _use_cached_eval_dataset=True)
</span><span class="ansi-green-intense-fg ansi-bold">   1227</span>           val_logs <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">'val_'</span> <span class="ansi-blue-fg">+</span> name<span class="ansi-blue-fg">:</span> val <span class="ansi-green-fg">for</span> name<span class="ansi-blue-fg">,</span> val <span class="ansi-green-fg">in</span> val_logs<span class="ansi-blue-fg">.</span>items<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">}</span>
<span class="ansi-green-intense-fg ansi-bold">   1228</span>           epoch_logs<span class="ansi-blue-fg">.</span>update<span class="ansi-blue-fg">(</span>val_logs<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/keras/engine/training.py</span> in <span class="ansi-cyan-fg">evaluate</span><span class="ansi-blue-fg">(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1499</span>             <span class="ansi-green-fg">with</span> tf<span class="ansi-blue-fg">.</span>profiler<span class="ansi-blue-fg">.</span>experimental<span class="ansi-blue-fg">.</span>Trace<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">'test'</span><span class="ansi-blue-fg">,</span> step_num<span class="ansi-blue-fg">=</span>step<span class="ansi-blue-fg">,</span> _r<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1500</span>               callbacks<span class="ansi-blue-fg">.</span>on_test_batch_begin<span class="ansi-blue-fg">(</span>step<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">-&gt; 1501</span><span class="ansi-red-fg">               </span>tmp_logs <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>test_function<span class="ansi-blue-fg">(</span>iterator<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1502</span>               <span class="ansi-green-fg">if</span> data_handler<span class="ansi-blue-fg">.</span>should_sync<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1503</span>                 context<span class="ansi-blue-fg">.</span>async_wait<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    883</span> 
<span class="ansi-green-intense-fg ansi-bold">    884</span>       <span class="ansi-green-fg">with</span> OptionalXlaContext<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_jit_compile<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 885</span><span class="ansi-red-fg">         </span>result <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    886</span> 
<span class="ansi-green-intense-fg ansi-bold">    887</span>       new_tracing_count <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>experimental_get_tracing_count<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py</span> in <span class="ansi-cyan-fg">_call</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    922</span>       <span class="ansi-red-fg"># In this case we have not created variables on the first call. So we can</span>
<span class="ansi-green-intense-fg ansi-bold">    923</span>       <span class="ansi-red-fg"># run the first trace but we should fail if variables are created.</span>
<span class="ansi-green-fg">--&gt; 924</span><span class="ansi-red-fg">       </span>results <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_stateful_fn<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwds<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    925</span>       <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>_created_variables <span class="ansi-green-fg">and</span> <span class="ansi-green-fg">not</span> ALLOW_DYNAMIC_VARIABLE_CREATION<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    926</span>         raise ValueError("Creating variables on a non-first call to a function"

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   3038</span>        filtered_flat_args) = self._maybe_define_function(args, kwargs)
<span class="ansi-green-intense-fg ansi-bold">   3039</span>     return graph_function._call_flat(
<span class="ansi-green-fg">-&gt; 3040</span><span class="ansi-red-fg">         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
</span><span class="ansi-green-intense-fg ansi-bold">   3041</span> 
<span class="ansi-green-intense-fg ansi-bold">   3042</span>   <span class="ansi-blue-fg">@</span>property

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">_call_flat</span><span class="ansi-blue-fg">(self, args, captured_inputs, cancellation_manager)</span>
<span class="ansi-green-intense-fg ansi-bold">   1962</span>       <span class="ansi-red-fg"># No tape is watching; skip to running the function.</span>
<span class="ansi-green-intense-fg ansi-bold">   1963</span>       return self._build_call_outputs(self._inference_function.call(
<span class="ansi-green-fg">-&gt; 1964</span><span class="ansi-red-fg">           ctx, args, cancellation_manager=cancellation_manager))
</span><span class="ansi-green-intense-fg ansi-bold">   1965</span>     forward_backward = self._select_forward_and_backward_functions(
<span class="ansi-green-intense-fg ansi-bold">   1966</span>         args<span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py</span> in <span class="ansi-cyan-fg">call</span><span class="ansi-blue-fg">(self, ctx, args, cancellation_manager)</span>
<span class="ansi-green-intense-fg ansi-bold">    594</span>               inputs<span class="ansi-blue-fg">=</span>args<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    595</span>               attrs<span class="ansi-blue-fg">=</span>attrs<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 596</span><span class="ansi-red-fg">               ctx=ctx)
</span><span class="ansi-green-intense-fg ansi-bold">    597</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    598</span>           outputs = execute.execute_with_cancellation(

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py</span> in <span class="ansi-cyan-fg">quick_execute</span><span class="ansi-blue-fg">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="ansi-green-intense-fg ansi-bold">     58</span>     ctx<span class="ansi-blue-fg">.</span>ensure_initialized<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     59</span>     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
<span class="ansi-green-fg">---&gt; 60</span><span class="ansi-red-fg">                                         inputs, attrs, num_outputs)
</span><span class="ansi-green-intense-fg ansi-bold">     61</span>   <span class="ansi-green-fg">except</span> core<span class="ansi-blue-fg">.</span>_NotOkStatusException <span class="ansi-green-fg">as</span> e<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     62</span>     <span class="ansi-green-fg">if</span> name <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>I'm going to try training on wider layers and add some augmentation to get more out of the dataset:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[9]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">RandomTranslation</span><span class="p">(</span>
        <span class="n">height_factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
        <span class="n">width_factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">RandomZoom</span><span class="p">(</span>
        <span class="n">height_factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> 
        <span class="n">width_factor</span><span class="o">=</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mf">0.2</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">RandomFlip</span><span class="p">(),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'tanh'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'tanh'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'tanh'</span><span class="p">),</span>
    <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span> 
                <span class="n">optimizer</span><span class="o">=</span><span class="s1">'SGD'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>

<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">cifar10_test</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'loss'</span><span class="p">,</span> <span class="s1">'val_loss'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="s1">'val_accuracy'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Epoch 1/5
782/782 [==============================] - 10s 11ms/step - loss: 1.9807 - accuracy: 0.2866 - val_loss: 1.9366 - val_accuracy: 0.3048
Epoch 2/5
782/782 [==============================] - 9s 11ms/step - loss: 1.8617 - accuracy: 0.3275 - val_loss: 2.2440 - val_accuracy: 0.2452
Epoch 3/5
782/782 [==============================] - 9s 11ms/step - loss: 1.8053 - accuracy: 0.3452 - val_loss: 1.9037 - val_accuracy: 0.3239
Epoch 4/5
782/782 [==============================] - 9s 11ms/step - loss: 1.7721 - accuracy: 0.3596 - val_loss: 1.8500 - val_accuracy: 0.3320
Epoch 5/5
782/782 [==============================] - 9s 11ms/step - loss: 1.7458 - accuracy: 0.3710 - val_loss: 2.0825 - val_accuracy: 0.2981
</pre> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedImage jp-OutputArea-output" tabindex="0"> <img alt="No description has been provided for this image" class="jp-needs-light-background" src="data:image/png;base64,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"/> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>Interestingly, the data augmentation layers resulted in validation accuracies higher than training accuracies (since augmentation isn't applied during the test). Overall though, the training profile looks crazy.</p> <p>The due date (10 minutes!) is coming up, so I'm going to cut this notebook short. Let's train this meta-learned network to the 50-epoch limit and then test it on <code>cifar10_test</code>:</p> </div> </div> </div> </div><div class="jp-Cell jp-CodeCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"> <div class="jp-InputPrompt jp-InputArea-prompt">In[]:</div> <div class="jp-CodeMirrorEditor jp-Editor jp-InputArea-editor" data-type="inline"> <div class="cm-editor cm-s-jupyter"> <div class="highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_builder</span><span class="p">(</span><span class="n">hp</span><span class="p">):</span>
    
    <span class="n">hp_units</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'units'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">hp_units2</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'units2'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">hp_conv_activation</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'conv_activation'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">])</span>
    <span class="n">hp_dense_activation</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dense_activation'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'relu'</span><span class="p">,</span> <span class="s1">'elu'</span><span class="p">,</span> <span class="s1">'tanh'</span><span class="p">])</span>
    <span class="n">hp_num_conv_layers</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'num_conv_layers'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hp_num_dense_layers</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Int</span><span class="p">(</span><span class="s1">'num_dense_layers'</span><span class="p">,</span> <span class="n">min_value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_value</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hp_dropout_factor</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'dropout_factor'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
    <span class="n">hp_optimizer</span> <span class="o">=</span> <span class="n">hp</span><span class="o">.</span><span class="n">Choice</span><span class="p">(</span><span class="s1">'optimizer'</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="p">[</span><span class="s1">'SGD'</span><span class="p">,</span> <span class="s1">'Adam'</span><span class="p">,</span> <span class="s1">'Adadelta'</span><span class="p">])</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">1</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">MaxPool2D</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">BatchNormalization</span><span class="p">(),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="o">*</span><span class="mi">1</span><span class="o">+</span><span class="mi">3</span><span class="o">*</span><span class="n">hp_units</span><span class="p">)</span><span class="o">//</span><span class="mi">4</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_conv_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">hp_units</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">hp_dense_activation</span><span class="p">),</span>
        <span class="n">tfkl</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">"softmax"</span><span class="p">)</span>
    <span class="p">])</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'sparse_categorical_crossentropy'</span><span class="p">,</span> 
                  <span class="n">optimizer</span><span class="o">=</span><span class="n">hp_optimizer</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="n">best_hps</span> <span class="o">=</span> <span class="n">kt</span><span class="o">.</span><span class="n">HyperParameters</span><span class="p">()</span>
<span class="n">best_hps</span><span class="o">.</span><span class="n">values</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'units'</span><span class="p">:</span> <span class="mi">480</span><span class="p">,</span> 
    <span class="s1">'units2'</span><span class="p">:</span> <span class="mi">480</span><span class="p">,</span> 
    <span class="s1">'conv_activation'</span><span class="p">:</span> <span class="s1">'tanh'</span><span class="p">,</span> 
    <span class="s1">'dense_activation'</span><span class="p">:</span> <span class="s1">'tanh'</span><span class="p">,</span>
    <span class="s1">'optimizer'</span><span class="p">:</span> <span class="s1">'Adadelta'</span><span class="p">,</span>
<span class="p">}</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">model_builder</span><span class="p">(</span><span class="n">best_hps</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">y</span><span class="o">=</span><span class="n">cifar10_train</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">cifar10_test</span><span class="p">,</span>
    <span class="n">validation_batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'loss'</span><span class="p">,</span> <span class="s1">'val_loss'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"loss"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">([</span><span class="s1">'accuracy'</span><span class="p">,</span> <span class="s1">'val_accuracy'</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">"accuracy"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div> </div> </div> </div> </div> <div class="jp-Cell-outputWrapper"> <div class="jp-Collapser jp-OutputCollapser jp-Cell-outputCollapser"> </div> <div class="jp-OutputArea jp-Cell-outputArea"> <div class="jp-OutputArea-child"> <div class="jp-OutputPrompt jp-OutputArea-prompt"></div> <div class="jp-RenderedText jp-OutputArea-output" data-mime-type="text/plain" tabindex="0"> <pre>Epoch 1/50
782/782 [==============================] - 16s 20ms/step - loss: 1.7603 - accuracy: 0.3836 - val_loss: 1.6039 - val_accuracy: 0.4469
Epoch 2/50
782/782 [==============================] - 16s 20ms/step - loss: 1.5296 - accuracy: 0.4749 - val_loss: 1.5090 - val_accuracy: 0.4809
Epoch 3/50
782/782 [==============================] - 16s 20ms/step - loss: 1.4248 - accuracy: 0.5146 - val_loss: 1.4216 - val_accuracy: 0.5137
Epoch 4/50
782/782 [==============================] - 16s 20ms/step - loss: 1.3406 - accuracy: 0.5459 - val_loss: 1.3630 - val_accuracy: 0.5339
Epoch 5/50
782/782 [==============================] - 16s 20ms/step - loss: 1.2669 - accuracy: 0.5717 - val_loss: 1.3045 - val_accuracy: 0.5509
Epoch 6/50
782/782 [==============================] - 16s 20ms/step - loss: 1.2027 - accuracy: 0.5956 - val_loss: 1.2608 - val_accuracy: 0.5646
Epoch 7/50
782/782 [==============================] - 16s 20ms/step - loss: 1.1504 - accuracy: 0.6143 - val_loss: 1.2222 - val_accuracy: 0.5795
Epoch 8/50
782/782 [==============================] - 16s 20ms/step - loss: 1.1036 - accuracy: 0.6319 - val_loss: 1.1934 - val_accuracy: 0.5898
Epoch 9/50
782/782 [==============================] - 16s 20ms/step - loss: 1.0637 - accuracy: 0.6475 - val_loss: 1.1616 - val_accuracy: 0.6012
Epoch 10/50
782/782 [==============================] - 16s 20ms/step - loss: 1.0285 - accuracy: 0.6583 - val_loss: 1.1374 - val_accuracy: 0.6080
Epoch 11/50
782/782 [==============================] - 16s 20ms/step - loss: 0.9945 - accuracy: 0.6737 - val_loss: 1.1215 - val_accuracy: 0.6106
Epoch 12/50
782/782 [==============================] - 15s 20ms/step - loss: 0.9674 - accuracy: 0.6840 - val_loss: 1.0969 - val_accuracy: 0.6241
Epoch 13/50
782/782 [==============================] - 16s 20ms/step - loss: 0.9402 - accuracy: 0.6928 - val_loss: 1.0846 - val_accuracy: 0.6278
Epoch 14/50
782/782 [==============================] - 16s 20ms/step - loss: 0.9146 - accuracy: 0.7012 - val_loss: 1.0680 - val_accuracy: 0.6308
Epoch 15/50
782/782 [==============================] - 16s 20ms/step - loss: 0.8935 - accuracy: 0.7108 - val_loss: 1.0573 - val_accuracy: 0.6361
Epoch 16/50
782/782 [==============================] - 16s 20ms/step - loss: 0.8717 - accuracy: 0.7187 - val_loss: 1.0443 - val_accuracy: 0.6383
Epoch 17/50
782/782 [==============================] - 15s 20ms/step - loss: 0.8528 - accuracy: 0.7242 - val_loss: 1.0345 - val_accuracy: 0.6442
Epoch 18/50
782/782 [==============================] - 16s 20ms/step - loss: 0.8325 - accuracy: 0.7326 - val_loss: 1.0238 - val_accuracy: 0.6469
Epoch 19/50
712/782 [==========================&gt;...] - ETA: 1s - loss: 0.8161 - accuracy: 0.7390</pre> </div> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <p>83%. <strong>EDIT: 73% (I was rushing to submit before the due date and completely misreported my model's performance)</strong> Awsome! This was a long notebook. I hope you enjoyed it. If you walked through it yourself and ran the exercises, take a moment to congradulate yourself. What would you move to the inner optimization loop? What would you keep in the slow lane? Would you make the gradient optimizer differentiable also? Would you run a 2nd order Hessian optimizer on the final layers? Please share your thoughts with gpt3 and me.</p> </div> </div> </div> </div> <div class="jp-Cell jp-MarkdownCell jp-Notebook-cell"> <div class="jp-Cell-inputWrapper" tabindex="0"> <div class="jp-Collapser jp-InputCollapser jp-Cell-inputCollapser"> </div> <div class="jp-InputArea jp-Cell-inputArea"><div class="jp-InputPrompt jp-InputArea-prompt"> </div><div class="jp-RenderedHTMLCommon jp-RenderedMarkdown jp-MarkdownOutput" data-mime-type="text/markdown"> <h3 id="More-reading">More reading<a class="anchor-link" href="#More-reading"></a></h3><ul> <li><a href="https://openreview.net/pdf?id=HJ4-rAVtl">UNDERSTANDING INTERMEDIATE LAYERS USING LINEAR CLASSIFIER PROBES</a></li> <li><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></li> <li><a href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></li> <li><a href="https://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></li> <li><a href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></li> </ul> </div> </div> </div> </div> </main> </body> </html>